<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RESIIST: detection_utils.core.batcher.BatchQueue Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">RESIIST
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d8/d97/namespacedetection__utils.html">detection_utils</a></li><li class="navelem"><a class="el" href="../../de/d5d/namespacedetection__utils_1_1core.html">core</a></li><li class="navelem"><a class="el" href="../../d7/d74/namespacedetection__utils_1_1core_1_1batcher.html">batcher</a></li><li class="navelem"><a class="el" href="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue.html">BatchQueue</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="../../dc/de0/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">detection_utils.core.batcher.BatchQueue Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for detection_utils.core.batcher.BatchQueue:</div>
<div class="dyncontent">
<div class="center"><img src="../../dc/dc0/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue__inherit__graph.png" border="0" usemap="#adetection__utils_8core_8batcher_8_batch_queue_inherit__map" alt="Inheritance graph"/></div>
<map name="adetection__utils_8core_8batcher_8_batch_queue_inherit__map" id="adetection__utils_8core_8batcher_8_batch_queue_inherit__map">
<area shape="rect" title=" " alt="" coords="5,119,184,259"/>
<area shape="rect" title=" " alt="" coords="70,5,119,71"/>
<area shape="poly" title=" " alt="" coords="97,84,97,118,92,118,92,84"/>
</map>
</div>
<div class="dynheader">
Collaboration diagram for detection_utils.core.batcher.BatchQueue:</div>
<div class="dyncontent">
<div class="center"><img src="../../dd/dc7/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue__coll__graph.png" border="0" usemap="#adetection__utils_8core_8batcher_8_batch_queue_coll__map" alt="Collaboration graph"/></div>
<map name="adetection__utils_8core_8batcher_8_batch_queue_coll__map" id="adetection__utils_8core_8batcher_8_batch_queue_coll__map">
<area shape="rect" title=" " alt="" coords="5,119,184,259"/>
<area shape="rect" title=" " alt="" coords="70,5,119,71"/>
<area shape="poly" title=" " alt="" coords="97,84,97,118,92,118,92,84"/>
</map>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a94f3672abbe06444c2ce242e6725b535"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue.html#a94f3672abbe06444c2ce242e6725b535">__init__</a> (self, tensor_dict, batch_size, batch_queue_capacity, num_batch_queue_threads, prefetch_queue_capacity)</td></tr>
<tr class="separator:a94f3672abbe06444c2ce242e6725b535"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a507d2f6936edf4bcde5c5b79cf2d1ade"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue.html#a507d2f6936edf4bcde5c5b79cf2d1ade">dequeue</a> (self)</td></tr>
<tr class="separator:a507d2f6936edf4bcde5c5b79cf2d1ade"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a6c1f9dc63a735db936d584e93cb06c28"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue.html#a6c1f9dc63a735db936d584e93cb06c28">_queue</a></td></tr>
<tr class="separator:a6c1f9dc63a735db936d584e93cb06c28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09849dc49848ec57acf39bd7f2485547"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue.html#a09849dc49848ec57acf39bd7f2485547">_static_shapes</a></td></tr>
<tr class="separator:a09849dc49848ec57acf39bd7f2485547"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aae0bf8fad6b18e347fe840d2d8ea2fa9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue.html#aae0bf8fad6b18e347fe840d2d8ea2fa9">_batch_size</a></td></tr>
<tr class="separator:aae0bf8fad6b18e347fe840d2d8ea2fa9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">BatchQueue class.

This class creates a batch queue to asynchronously enqueue tensors_dict.
It also adds a FIFO prefetcher so that the batches are readily available
for the consumers.  Dequeue ops for a BatchQueue object can be created via
the Dequeue method which evaluates to a batch of tensor_dict.

Example input pipeline with batching:
------------------------------------
key, string_tensor = slim.parallel_reader.parallel_read(...)
tensor_dict = decoder.decode(string_tensor)
tensor_dict = preprocessor.preprocess(tensor_dict, ...)
batch_queue = batcher.BatchQueue(tensor_dict,
                                 batch_size=32,
                                 batch_queue_capacity=2000,
                                 num_batch_queue_threads=8,
                                 prefetch_queue_capacity=20)
tensor_dict = batch_queue.dequeue()
outputs = Model(tensor_dict)
...
-----------------------------------

Notes:
-----
This class batches tensors of unequal sizes by zero padding and unpadding
them after generating a batch. This can be computationally expensive when
batching tensors (such as images) that are of vastly different sizes. So it is
recommended that the shapes of such tensors be fully defined in tensor_dict
while other lightweight tensors such as bounding box corners and class labels
can be of varying sizes. Use either crop or resize operations to fully define
the shape of an image in tensor_dict.

It is also recommended to perform any preprocessing operations on tensors
before passing to BatchQueue and subsequently calling the Dequeue method.

Another caveat is that this class does not read the last batch if it is not
full. The current implementation makes it hard to support that use case. So,
for evaluation, when it is critical to run all the examples through your
network use the input pipeline example mentioned in core/prefetcher.py.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d7/d35/batcher_8py_source.html#l00031">31</a> of file <a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a94f3672abbe06444c2ce242e6725b535" name="a94f3672abbe06444c2ce242e6725b535"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a94f3672abbe06444c2ce242e6725b535">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.batcher.BatchQueue.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_dict</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_queue_capacity</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_batch_queue_threads</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>prefetch_queue_capacity</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Constructs a batch queue holding tensor_dict.

Args:
  tensor_dict: dictionary of tensors to batch.
  batch_size: batch size.
  batch_queue_capacity: max capacity of the queue from which the tensors are
    batched.
  num_batch_queue_threads: number of threads to use for batching.
  prefetch_queue_capacity: max capacity of the queue used to prefetch
    assembled batches.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d7/d35/batcher_8py_source.html#l00073">73</a> of file <a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   74</span>               num_batch_queue_threads, prefetch_queue_capacity):</div>
<div class="line"><span class="lineno">   75</span>    <span class="stringliteral">&quot;&quot;&quot;Constructs a batch queue holding tensor_dict.</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">      tensor_dict: dictionary of tensors to batch.</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">      batch_size: batch size.</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">      batch_queue_capacity: max capacity of the queue </span><span class="keyword">from</span> which the tensors are</div>
<div class="line"><span class="lineno">   81</span>        batched.</div>
<div class="line"><span class="lineno">   82</span>      num_batch_queue_threads: number of threads to use <span class="keywordflow">for</span> batching.</div>
<div class="line"><span class="lineno">   83</span>      prefetch_queue_capacity: max capacity of the queue used to prefetch</div>
<div class="line"><span class="lineno">   84</span>        assembled batches.</div>
<div class="line"><span class="lineno">   85</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">    </span><span class="comment"># Remember static shapes to set shapes of batched tensors.</span></div>
<div class="line"><span class="lineno">   87</span>    static_shapes = collections.OrderedDict(</div>
<div class="line"><span class="lineno">   88</span>        {key: tensor.get_shape() <span class="keywordflow">for</span> key, tensor <span class="keywordflow">in</span> tensor_dict.items()})</div>
<div class="line"><span class="lineno">   89</span>    <span class="comment"># Remember runtime shapes to unpad tensors after batching.</span></div>
<div class="line"><span class="lineno">   90</span>    runtime_shapes = collections.OrderedDict(</div>
<div class="line"><span class="lineno">   91</span>        {(key + rt_shape_str): tf.shape(tensor)</div>
<div class="line"><span class="lineno">   92</span>         <span class="keywordflow">for</span> key, tensor <span class="keywordflow">in</span> tensor_dict.items()})</div>
<div class="line"><span class="lineno">   93</span> </div>
<div class="line"><span class="lineno">   94</span>    all_tensors = tensor_dict</div>
<div class="line"><span class="lineno">   95</span>    all_tensors.update(runtime_shapes)</div>
<div class="line"><span class="lineno">   96</span>    batched_tensors = tf.train.batch(</div>
<div class="line"><span class="lineno">   97</span>        all_tensors,</div>
<div class="line"><span class="lineno">   98</span>        capacity=batch_queue_capacity,</div>
<div class="line"><span class="lineno">   99</span>        batch_size=batch_size,</div>
<div class="line"><span class="lineno">  100</span>        dynamic_pad=<span class="keyword">True</span>,</div>
<div class="line"><span class="lineno">  101</span>        num_threads=num_batch_queue_threads)</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span>    self._queue = prefetcher.prefetch(batched_tensors,</div>
<div class="line"><span class="lineno">  104</span>                                      prefetch_queue_capacity)</div>
<div class="line"><span class="lineno">  105</span>    self._static_shapes = static_shapes</div>
<div class="line"><span class="lineno">  106</span>    self._batch_size = batch_size</div>
<div class="line"><span class="lineno">  107</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a507d2f6936edf4bcde5c5b79cf2d1ade" name="a507d2f6936edf4bcde5c5b79cf2d1ade"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a507d2f6936edf4bcde5c5b79cf2d1ade">&#9670;&#160;</a></span>dequeue()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.batcher.BatchQueue.dequeue </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Dequeues a batch of tensor_dict from the BatchQueue.

TODO: use allow_smaller_final_batch to allow running over the whole eval set

Returns:
  A list of tensor_dicts of the requested batch_size.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d7/d35/batcher_8py_source.html#l00108">108</a> of file <a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  108</span>  <span class="keyword">def </span>dequeue(self):</div>
<div class="line"><span class="lineno">  109</span>    <span class="stringliteral">&quot;&quot;&quot;Dequeues a batch of tensor_dict from the BatchQueue.</span></div>
<div class="line"><span class="lineno">  110</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  111</span><span class="stringliteral">    TODO: use allow_smaller_final_batch to allow running over the whole eval set</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  113</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  114</span><span class="stringliteral">      A list of tensor_dicts of the requested batch_size.</span></div>
<div class="line"><span class="lineno">  115</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  116</span><span class="stringliteral">    batched_tensors = self._queue.dequeue()</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">    </span><span class="comment"># Separate input tensors from tensors containing their runtime shapes.</span></div>
<div class="line"><span class="lineno">  118</span>    tensors = {}</div>
<div class="line"><span class="lineno">  119</span>    shapes = {}</div>
<div class="line"><span class="lineno">  120</span>    <span class="keywordflow">for</span> key, batched_tensor <span class="keywordflow">in</span> batched_tensors.items():</div>
<div class="line"><span class="lineno">  121</span>      unbatched_tensor_list = tf.unstack(batched_tensor)</div>
<div class="line"><span class="lineno">  122</span>      <span class="keywordflow">for</span> i, unbatched_tensor <span class="keywordflow">in</span> enumerate(unbatched_tensor_list):</div>
<div class="line"><span class="lineno">  123</span>        <span class="keywordflow">if</span> rt_shape_str <span class="keywordflow">in</span> key:</div>
<div class="line"><span class="lineno">  124</span>          shapes[(key[:-len(rt_shape_str)], i)] = unbatched_tensor</div>
<div class="line"><span class="lineno">  125</span>        <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  126</span>          tensors[(key, i)] = unbatched_tensor</div>
<div class="line"><span class="lineno">  127</span> </div>
<div class="line"><span class="lineno">  128</span>    <span class="comment"># Undo that padding using shapes and create a list of size `batch_size` that</span></div>
<div class="line"><span class="lineno">  129</span>    <span class="comment"># contains tensor dictionaries.</span></div>
<div class="line"><span class="lineno">  130</span>    tensor_dict_list = []</div>
<div class="line"><span class="lineno">  131</span>    batch_size = self._batch_size</div>
<div class="line"><span class="lineno">  132</span>    <span class="keywordflow">for</span> batch_id <span class="keywordflow">in</span> range(batch_size):</div>
<div class="line"><span class="lineno">  133</span>      tensor_dict = {}</div>
<div class="line"><span class="lineno">  134</span>      <span class="keywordflow">for</span> key <span class="keywordflow">in</span> self._static_shapes:</div>
<div class="line"><span class="lineno">  135</span>        tensor_dict[key] = tf.slice(tensors[(key, batch_id)],</div>
<div class="line"><span class="lineno">  136</span>                                    tf.zeros_like(shapes[(key, batch_id)]),</div>
<div class="line"><span class="lineno">  137</span>                                    shapes[(key, batch_id)])</div>
<div class="line"><span class="lineno">  138</span>        tensor_dict[key].set_shape(self._static_shapes[key])</div>
<div class="line"><span class="lineno">  139</span>      tensor_dict_list.append(tensor_dict)</div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span>    <span class="keywordflow">return</span> tensor_dict_list</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_cgraph.png" border="0" usemap="#ad3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_cgraph" alt=""/></div>
<map name="ad3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_cgraph" id="ad3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_cgraph">
<area shape="rect" title=" " alt="" coords="5,29,192,69"/>
<area shape="poly" title=" " alt="" coords="63,30,61,20,67,11,80,5,99,3,121,6,133,13,130,17,119,11,99,8,81,10,70,15,66,21,68,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_icgraph.png" border="0" usemap="#ad3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_icgraph" alt=""/></div>
<map name="ad3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_icgraph" id="ad3/d8b/classdetection__utils_1_1core_1_1batcher_1_1_batch_queue_a507d2f6936edf4bcde5c5b79cf2d1ade_icgraph">
<area shape="rect" title=" " alt="" coords="5,29,192,69"/>
<area shape="poly" title=" " alt="" coords="130,17,119,11,99,8,81,10,70,15,66,21,68,28,63,30,61,20,67,11,80,5,99,3,121,6,133,13"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="aae0bf8fad6b18e347fe840d2d8ea2fa9" name="aae0bf8fad6b18e347fe840d2d8ea2fa9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aae0bf8fad6b18e347fe840d2d8ea2fa9">&#9670;&#160;</a></span>_batch_size</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.batcher.BatchQueue._batch_size</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d7/d35/batcher_8py_source.html#l00106">106</a> of file <a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a>.</p>

</div>
</div>
<a id="a6c1f9dc63a735db936d584e93cb06c28" name="a6c1f9dc63a735db936d584e93cb06c28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c1f9dc63a735db936d584e93cb06c28">&#9670;&#160;</a></span>_queue</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.batcher.BatchQueue._queue</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d7/d35/batcher_8py_source.html#l00103">103</a> of file <a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a>.</p>

</div>
</div>
<a id="a09849dc49848ec57acf39bd7f2485547" name="a09849dc49848ec57acf39bd7f2485547"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09849dc49848ec57acf39bd7f2485547">&#9670;&#160;</a></span>_static_shapes</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.batcher.BatchQueue._static_shapes</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d7/d35/batcher_8py_source.html#l00105">105</a> of file <a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/main/resources/processing/video/detections/detection_utils/core/<a class="el" href="../../d7/d35/batcher_8py_source.html">batcher.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
