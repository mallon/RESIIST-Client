<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RESIIST: src/main/resources/processing/video/detections/detection_utils/core/losses.py Source File</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">RESIIST
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../dir_68267d1309a1af8e8297ef4c3efbcdba.html">src</a></li><li class="navelem"><a class="el" href="../../dir_5eb159725f84c66aafd839904a4acdd0.html">main</a></li><li class="navelem"><a class="el" href="../../dir_6bfaacbfa58826360c75a979f1bd52ac.html">resources</a></li><li class="navelem"><a class="el" href="../../dir_5f7788aad5dde86125b1bc0a78ab9869.html">processing</a></li><li class="navelem"><a class="el" href="../../dir_8a632635c319e4eedf777c94267ebcd4.html">video</a></li><li class="navelem"><a class="el" href="../../dir_f0d6e3d1e185b11d812fcfa0d483d6ea.html">detections</a></li><li class="navelem"><a class="el" href="../../dir_f9a850ec5672703aeb0d0e683d1d4180.html">detection_utils</a></li><li class="navelem"><a class="el" href="../../dir_bd19141a3393da11b5642ce3ac180018.html">core</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle"><div class="title">losses.py</div></div>
</div><!--header-->
<div class="contents">
<a href="../../dc/db7/losses_8py.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno"><a class="line" href="../../d5/d10/namespacedetection__utils_1_1core_1_1losses.html">    1</a></span><span class="comment"># Copyright 2017 The TensorFlow Authors. All Rights Reserved.</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="comment">#</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="comment"># you may not use this file except in compliance with the License.</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="comment"># You may obtain a copy of the License at</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="comment">#</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="comment">#</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="comment"># See the License for the specific language governing permissions and</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="comment"># limitations under the License.</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="comment"># ==============================================================================</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span> </div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="stringliteral">&quot;&quot;&quot;Classification and regression loss functions for object detection.</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="stringliteral">Localization losses:</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="stringliteral"> * WeightedL2LocalizationLoss</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span><span class="stringliteral"> * WeightedSmoothL1LocalizationLoss</span></div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="stringliteral"> * WeightedIOULocalizationLoss</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="stringliteral">Classification losses:</span></div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span><span class="stringliteral"> * WeightedSigmoidClassificationLoss</span></div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span><span class="stringliteral"> * WeightedSoftmaxClassificationLoss</span></div>
<div class="line"><a id="l00026" name="l00026"></a><span class="lineno">   26</span><span class="stringliteral"> * WeightedSoftmaxClassificationAgainstLogitsLoss</span></div>
<div class="line"><a id="l00027" name="l00027"></a><span class="lineno">   27</span><span class="stringliteral"> * BootstrappedSigmoidClassificationLoss</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno">   29</span><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span> </div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno">   33</span><span class="keyword">import</span> abc</div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span><span class="keyword">import</span> six</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div>
<div class="line"><a id="l00036" name="l00036"></a><span class="lineno">   36</span> </div>
<div class="line"><a id="l00037" name="l00037"></a><span class="lineno">   37</span><span class="keyword">from</span> object_detection.core <span class="keyword">import</span> box_list</div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno">   38</span><span class="keyword">from</span> object_detection.core <span class="keyword">import</span> box_list_ops</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> ops</div>
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno">   40</span> </div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno"><a class="line" href="../../d5/d10/namespacedetection__utils_1_1core_1_1losses.html#afe2746c0d27ec9406c33d4596bacef9d">   41</a></span>slim = tf.contrib.slim</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno">   42</span> </div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span> </div>
<div class="line"><a id="l00044" name="l00044"></a><span class="lineno"><a class="line" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">   44</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>(six.with_metaclass(abc.ABCMeta, object)):</div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno">   45</span>  <span class="stringliteral">&quot;&quot;&quot;Abstract base class for loss functions.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span> </div>
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno"><a class="line" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#a8555bca99fcc03e1fd78e25e3b2e8843">   47</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#a8555bca99fcc03e1fd78e25e3b2e8843">__call__</a>(self,</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>               prediction_tensor,</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>               target_tensor,</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>               ignore_nan_targets=False,</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>               losses_mask=None,</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>               scope=None,</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>               **params):</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>    <span class="stringliteral">&quot;&quot;&quot;Call the loss function.</span></div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno">   56</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span><span class="stringliteral">      prediction_tensor: an N-d tensor of shape [batch, anchors, ...]</span></div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span><span class="stringliteral">        representing predicted quantities.</span></div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span><span class="stringliteral">      target_tensor: an N-d tensor of shape [batch, anchors, ...] representing</span></div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span><span class="stringliteral">        regression </span><span class="keywordflow">or</span> classification targets.</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>      ignore_nan_targets: whether to ignore nan targets <span class="keywordflow">in</span> the loss computation.</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>        E.g. can be used <span class="keywordflow">if</span> the target tensor <span class="keywordflow">is</span> missing groundtruth data that</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>        shouldn<span class="stringliteral">&#39;t be factored into the loss.</span></div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span><span class="stringliteral">      losses_mask: A [batch] boolean tensor that indicates whether losses should</span></div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span><span class="stringliteral">        be applied to individual images </span><span class="keywordflow">in</span> the batch. For elements that</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>        are <span class="keyword">False</span>, corresponding prediction, target, <span class="keywordflow">and</span> weight tensors will <span class="keywordflow">not</span></div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>        contribute to loss computation. If <span class="keywordtype">None</span>, no filtering will take place</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>        prior to loss computation.</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>      scope: Op scope name. Defaults to <span class="stringliteral">&#39;Loss&#39;</span> <span class="keywordflow">if</span> <span class="keywordtype">None</span>.</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>      **params: Additional keyword arguments <span class="keywordflow">for</span> specific implementations of</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span>              the Loss.</div>
<div class="line"><a id="l00072" name="l00072"></a><span class="lineno">   72</span> </div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span>    Returns:</div>
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno">   74</span>      loss: a tensor representing the value of the loss function.</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span><span class="stringliteral">    </span><span class="keyword">with</span> tf.name_scope(scope, <span class="stringliteral">&#39;Loss&#39;</span>,</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>                       [prediction_tensor, target_tensor, params]) <span class="keyword">as</span> scope:</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>      <span class="keywordflow">if</span> ignore_nan_targets:</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span>        target_tensor = tf.where(tf.is_nan(target_tensor),</div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span>                                 prediction_tensor,</div>
<div class="line"><a id="l00081" name="l00081"></a><span class="lineno">   81</span>                                 target_tensor)</div>
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno">   82</span>      <span class="keywordflow">if</span> losses_mask <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>        tensor_multiplier = self.<a class="code hl_function" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#aadcefe6d066fd31b3b5a2542d3fef144">_get_loss_multiplier_for_tensor</a>(</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>            prediction_tensor,</div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>            losses_mask)</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>        prediction_tensor *= tensor_multiplier</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>        target_tensor *= tensor_multiplier</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span> </div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>        <span class="keywordflow">if</span> <span class="stringliteral">&#39;weights&#39;</span> <span class="keywordflow">in</span> params:</div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>          params[<span class="stringliteral">&#39;weights&#39;</span>] = tf.convert_to_tensor(params[<span class="stringliteral">&#39;weights&#39;</span>])</div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>          weights_multiplier = self.<a class="code hl_function" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#aadcefe6d066fd31b3b5a2542d3fef144">_get_loss_multiplier_for_tensor</a>(</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>              params[<span class="stringliteral">&#39;weights&#39;</span>],</div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>              losses_mask)</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>          params[<span class="stringliteral">&#39;weights&#39;</span>] *= weights_multiplier</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>      <span class="keywordflow">return</span> self.<a class="code hl_function" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#ae772289a8be37a802e11150c81e7ece7">_compute_loss</a>(prediction_tensor, target_tensor, **params)</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span> </div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno"><a class="line" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#aadcefe6d066fd31b3b5a2542d3fef144">   97</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#aadcefe6d066fd31b3b5a2542d3fef144">_get_loss_multiplier_for_tensor</a>(self, tensor, losses_mask):</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>    loss_multiplier_shape = tf.stack([-1] + [1] * (len(tensor.shape) - 1))</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>    <span class="keywordflow">return</span> tf.cast(tf.reshape(losses_mask, loss_multiplier_shape), tf.float32)</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span> </div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>  <span class="preprocessor">@abc.abstractmethod</span></div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno"><a class="line" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#ae772289a8be37a802e11150c81e7ece7">  102</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#ae772289a8be37a802e11150c81e7ece7">_compute_loss</a>(self, prediction_tensor, target_tensor, **params):</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>    <span class="stringliteral">&quot;&quot;&quot;Method to be overridden by implementations.</span></div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span><span class="stringliteral">      prediction_tensor: a tensor representing predicted quantities</span></div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span><span class="stringliteral">      target_tensor: a tensor representing regression </span><span class="keywordflow">or</span> classification targets</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span>      **params: Additional keyword arguments <span class="keywordflow">for</span> specific implementations of</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>              the Loss.</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span> </div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>    Returns:</div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>      loss: an N-d tensor of shape [batch, anchors, ...] containing the loss per</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>        anchor</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span> </div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span> </div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno"><a class="line" href="../../dc/dbe/classdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss.html">  118</a></span><span class="keyword">class </span><a class="code hl_class" href="../../dc/dbe/classdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss.html">WeightedL2LocalizationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>  <span class="stringliteral">&quot;&quot;&quot;L2 localization loss function with anchorwise output support.</span></div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span><span class="stringliteral">  Loss[b,a] = .5 * ||weights[b,a] * (prediction[b,a,:] - target[b,a,:])||^2</span></div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span><span class="stringliteral">  &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno"><a class="line" href="../../dc/dbe/classdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss.html#aaee905ead7ab9ffd710cdcfee0ffed81">  124</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../dc/dbe/classdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss.html#aaee905ead7ab9ffd710cdcfee0ffed81">_compute_loss</a>(self, prediction_tensor, target_tensor, weights):</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span><span class="stringliteral">        code_size] representing the (encoded) predicted locations of objects.</span></div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span><span class="stringliteral">      target_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span><span class="stringliteral">        code_size] representing the regression targets</span></div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span><span class="stringliteral">      weights: a float tensor of shape [batch_size, num_anchors]</span></div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span><span class="stringliteral">      loss: a float tensor of shape [batch_size, num_anchors] tensor</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span><span class="stringliteral">        representing the value of the loss function.</span></div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span><span class="stringliteral">    weighted_diff = (prediction_tensor - target_tensor) * tf.expand_dims(</span></div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span><span class="stringliteral">        weights, 2)</span></div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span><span class="stringliteral">    square_diff = 0.5 * tf.square(weighted_diff)</span></div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span><span class="stringliteral">    </span><span class="keywordflow">return</span> tf.reduce_sum(square_diff, 2)</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span> </div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span> </div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno"><a class="line" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html">  144</a></span><span class="keyword">class </span><a class="code hl_class" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html">WeightedSmoothL1LocalizationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>  <span class="stringliteral">&quot;&quot;&quot;Smooth L1 localization loss function aka Huber Loss..</span></div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span><span class="stringliteral">  The smooth L1_loss </span><span class="keywordflow">is</span> defined elementwise <span class="keyword">as</span> .5 x^2 <span class="keywordflow">if</span> |x| &lt;= delta <span class="keywordflow">and</span></div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>  delta * (|x|- 0.5*delta) otherwise, where x <span class="keywordflow">is</span> the difference between</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>  predictions <span class="keywordflow">and</span> target.</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span> </div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>  See also Equation (3) <span class="keywordflow">in</span> the Fast R-CNN paper by Ross Girshick (ICCV 2015)</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno"><a class="line" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#abc0b28eb08b090611695730272fac82d">  154</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#abc0b28eb08b090611695730272fac82d">__init__</a>(self, delta=1.0):</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span><span class="stringliteral">      delta: delta </span><span class="keywordflow">for</span> smooth L1 loss.</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span><span class="stringliteral">    super(WeightedSmoothL1LocalizationLoss, self).<a class="code hl_function" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#abc0b28eb08b090611695730272fac82d">__init__</a>()</span></div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno"><a class="line" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#a5d030db122ef9b27011d28659e4538d0">  161</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#a5d030db122ef9b27011d28659e4538d0">_delta</a> = delta</span></div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno"><a class="line" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#ac0d45f835b9f05f34490955109ec1432">  163</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#ac0d45f835b9f05f34490955109ec1432">_compute_loss</a>(self, prediction_tensor, target_tensor, weights):</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span><span class="stringliteral">        code_size] representing the (encoded) predicted locations of objects.</span></div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span><span class="stringliteral">      target_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno">  170</span><span class="stringliteral">        code_size] representing the regression targets</span></div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span><span class="stringliteral">      weights: a float tensor of shape [batch_size, num_anchors]</span></div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno">  172</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno">  173</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span><span class="stringliteral">      loss: a float tensor of shape [batch_size, num_anchors] tensor</span></div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span><span class="stringliteral">        representing the value of the loss function.</span></div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span><span class="stringliteral">    </span><span class="keywordflow">return</span> tf.reduce_sum(tf.losses.huber_loss(</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>        target_tensor,</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>        prediction_tensor,</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>        delta=self.<a class="code hl_variable" href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#a5d030db122ef9b27011d28659e4538d0">_delta</a>,</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>        weights=tf.expand_dims(weights, axis=2),</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>        loss_collection=<span class="keywordtype">None</span>,</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>        reduction=tf.losses.Reduction.NONE</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>    ), axis=2)</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span> </div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span> </div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno"><a class="line" href="../../dc/d60/classdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss.html">  187</a></span><span class="keyword">class </span><a class="code hl_class" href="../../dc/d60/classdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss.html">WeightedIOULocalizationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>  <span class="stringliteral">&quot;&quot;&quot;IOU localization loss function.</span></div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span><span class="stringliteral">  Sums the IOU </span><span class="keywordflow">for</span> corresponding pairs of predicted/groundtruth boxes</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>  <span class="keywordflow">and</span> <span class="keywordflow">for</span> each pair assign a loss of 1 - IOU.  We then compute a weighted</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>  sum over all pairs which <span class="keywordflow">is</span> returned <span class="keyword">as</span> the total loss.</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno"><a class="line" href="../../dc/d60/classdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss.html#ab954132a3ba751ba0d64828ebb3c18d3">  195</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../dc/d60/classdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss.html#ab954132a3ba751ba0d64828ebb3c18d3">_compute_loss</a>(self, prediction_tensor, target_tensor, weights):</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors, 4]</span></div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span><span class="stringliteral">        representing the decoded predicted boxes</span></div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span><span class="stringliteral">      target_tensor: A float tensor of shape [batch_size, num_anchors, 4]</span></div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span><span class="stringliteral">        representing the decoded target boxes</span></div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span><span class="stringliteral">      weights: a float tensor of shape [batch_size, num_anchors]</span></div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span><span class="stringliteral">      loss: a float tensor of shape [batch_size, num_anchors] tensor</span></div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span><span class="stringliteral">        representing the value of the loss function.</span></div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span><span class="stringliteral">    predicted_boxes = <a class="code hl_class" href="../../df/de3/classdetection__utils_1_1core_1_1box__list_1_1_box_list.html">box_list.BoxList</a>(tf.reshape(prediction_tensor, [-1, 4]))</span></div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span><span class="stringliteral">    target_boxes = <a class="code hl_class" href="../../df/de3/classdetection__utils_1_1core_1_1box__list_1_1_box_list.html">box_list.BoxList</a>(tf.reshape(target_tensor, [-1, 4]))</span></div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span><span class="stringliteral">    per_anchor_iou_loss = 1.0 - box_list_ops.matched_iou(predicted_boxes,</span></div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span><span class="stringliteral">                                                         target_boxes)</span></div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span><span class="stringliteral">    </span><span class="keywordflow">return</span> tf.reshape(weights, [-1]) * per_anchor_iou_loss</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span> </div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span> </div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno"><a class="line" href="../../d2/de5/classdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss.html">  216</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d2/de5/classdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss.html">WeightedSigmoidClassificationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>  <span class="stringliteral">&quot;&quot;&quot;Sigmoid cross entropy classification loss function.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span> </div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno"><a class="line" href="../../d2/de5/classdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss.html#ac42b20743e94260a6d6d838f654f2ddb">  219</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d2/de5/classdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss.html#ac42b20743e94260a6d6d838f654f2ddb">_compute_loss</a>(self,</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>                    prediction_tensor,</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>                    target_tensor,</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>                    weights,</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>                    class_indices=None):</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span><span class="stringliteral">        num_classes] representing the predicted logits </span><span class="keywordflow">for</span> each <span class="keyword">class</span></div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>      target_tensor: A float tensor of shape [batch_size, num_anchors,</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>        num_classes] representing one-hot encoded classification targets</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>      weights: a float tensor of shape, either [batch_size, num_anchors,</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>        num_classes] <span class="keywordflow">or</span> [batch_size, num_anchors, 1]. If the shape <span class="keywordflow">is</span></div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>        [batch_size, num_anchors, 1], all the classses are equally weighted.</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>      class_indices: (Optional) A 1-D integer tensor of <span class="keyword">class </span>indices.</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>        If provided, computes loss only <span class="keywordflow">for</span> the specified <span class="keyword">class </span>indices.</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span> </div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>    Returns:</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>      loss: a float tensor of shape [batch_size, num_anchors, num_classes]</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span>        representing the value of the loss function.</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span><span class="stringliteral">    </span><span class="keywordflow">if</span> class_indices <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>      weights *= tf.reshape(</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>          ops.indices_to_dense_vector(class_indices,</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>                                      tf.shape(prediction_tensor)[2]),</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>          [1, 1, -1])</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>    per_entry_cross_ent = (tf.nn.sigmoid_cross_entropy_with_logits(</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>        labels=target_tensor, logits=prediction_tensor))</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>    <span class="keywordflow">return</span> per_entry_cross_ent * weights</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span> </div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span> </div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno"><a class="line" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html">  251</a></span><span class="keyword">class </span><a class="code hl_class" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html">SigmoidFocalClassificationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>  <span class="stringliteral">&quot;&quot;&quot;Sigmoid focal cross entropy loss.</span></div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span><span class="stringliteral">  Focal loss down-weights well classified examples </span><span class="keywordflow">and</span> focusses on the hard</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>  examples. See https://arxiv.org/pdf/1708.02002.pdf <span class="keywordflow">for</span> the loss definition.</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno"><a class="line" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#acc5e74c93eb3c34dd4370bc1c6a7b23f">  258</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#acc5e74c93eb3c34dd4370bc1c6a7b23f">__init__</a>(self, gamma=2.0, alpha=0.25):</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span><span class="stringliteral">      gamma: exponent of the modulating factor (1 - p_t) ^ gamma.</span></div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span><span class="stringliteral">      alpha: optional alpha weighting factor to balance positives vs negatives.</span></div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span><span class="stringliteral">    super(SigmoidFocalClassificationLoss, self).<a class="code hl_function" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#acc5e74c93eb3c34dd4370bc1c6a7b23f">__init__</a>()</span></div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno"><a class="line" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#ae7a2f9c1c0913c37e806e7ad3487d0a4">  266</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#ae7a2f9c1c0913c37e806e7ad3487d0a4">_alpha</a> = alpha</span></div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno"><a class="line" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#a8fabfd8883d2be73deb91513ac7ab456">  267</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#a8fabfd8883d2be73deb91513ac7ab456">_gamma</a> = gamma</span></div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno"><a class="line" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#abd4817631560e14e14c853c01c069732">  269</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#abd4817631560e14e14c853c01c069732">_compute_loss</a>(self,</div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span>                    prediction_tensor,</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno">  271</span>                    target_tensor,</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>                    weights,</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span>                    class_indices=None):</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span><span class="stringliteral">        num_classes] representing the predicted logits </span><span class="keywordflow">for</span> each <span class="keyword">class</span></div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>      target_tensor: A float tensor of shape [batch_size, num_anchors,</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>        num_classes] representing one-hot encoded classification targets</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>      weights: a float tensor of shape, either [batch_size, num_anchors,</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>        num_classes] <span class="keywordflow">or</span> [batch_size, num_anchors, 1]. If the shape <span class="keywordflow">is</span></div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>        [batch_size, num_anchors, 1], all the classses are equally weighted.</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>      class_indices: (Optional) A 1-D integer tensor of <span class="keyword">class </span>indices.</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>        If provided, computes loss only <span class="keywordflow">for</span> the specified <span class="keyword">class </span>indices.</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span> </div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>    Returns:</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>      loss: a float tensor of shape [batch_size, num_anchors, num_classes]</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>        representing the value of the loss function.</div>
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno">  290</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span><span class="stringliteral">    </span><span class="keywordflow">if</span> class_indices <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>      weights *= tf.reshape(</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>          ops.indices_to_dense_vector(class_indices,</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>                                      tf.shape(prediction_tensor)[2]),</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>          [1, 1, -1])</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>    per_entry_cross_ent = (tf.nn.sigmoid_cross_entropy_with_logits(</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>        labels=target_tensor, logits=prediction_tensor))</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>    prediction_probabilities = tf.sigmoid(prediction_tensor)</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>    p_t = ((target_tensor * prediction_probabilities) +</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>           ((1 - target_tensor) * (1 - prediction_probabilities)))</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>    modulating_factor = 1.0</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>    <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#a8fabfd8883d2be73deb91513ac7ab456">_gamma</a>:</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>      modulating_factor = tf.pow(1.0 - p_t, self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#a8fabfd8883d2be73deb91513ac7ab456">_gamma</a>)</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>    alpha_weight_factor = 1.0</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>    <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#ae7a2f9c1c0913c37e806e7ad3487d0a4">_alpha</a> <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>      alpha_weight_factor = (target_tensor * self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#ae7a2f9c1c0913c37e806e7ad3487d0a4">_alpha</a> +</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                             (1 - target_tensor) * (1 - self.<a class="code hl_variable" href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#ae7a2f9c1c0913c37e806e7ad3487d0a4">_alpha</a>))</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>    focal_cross_entropy_loss = (modulating_factor * alpha_weight_factor *</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                                per_entry_cross_ent)</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>    <span class="keywordflow">return</span> focal_cross_entropy_loss * weights</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span> </div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span> </div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno"><a class="line" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html">  313</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html">WeightedSoftmaxClassificationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>  <span class="stringliteral">&quot;&quot;&quot;Softmax loss function.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span> </div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno"><a class="line" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a24408057d3ced7f7f55949e8da83a047">  316</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a24408057d3ced7f7f55949e8da83a047">__init__</a>(self, logit_scale=1.0):</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span><span class="stringliteral">      logit_scale: When this value </span><span class="keywordflow">is</span> high, the prediction <span class="keywordflow">is</span> <span class="stringliteral">&quot;diffused&quot;</span> <span class="keywordflow">and</span></div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>                   when this value <span class="keywordflow">is</span> low, the prediction <span class="keywordflow">is</span> made peakier.</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>                   (default 1.0)</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span> </div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span><span class="stringliteral">    super(WeightedSoftmaxClassificationLoss, self).<a class="code hl_function" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a24408057d3ced7f7f55949e8da83a047">__init__</a>()</span></div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno"><a class="line" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a404314a3aab27fc9dcb2dbc25851b56c">  326</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a404314a3aab27fc9dcb2dbc25851b56c">_logit_scale</a> = logit_scale</span></div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno"><a class="line" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a15a0162c97856f7ba8a5c1121017d853">  328</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a15a0162c97856f7ba8a5c1121017d853">_compute_loss</a>(self, prediction_tensor, target_tensor, weights):</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span><span class="stringliteral">        num_classes] representing the predicted logits </span><span class="keywordflow">for</span> each <span class="keyword">class</span></div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>      target_tensor: A float tensor of shape [batch_size, num_anchors,</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span>        num_classes] representing one-hot encoded classification targets</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>      weights: a float tensor of shape, either [batch_size, num_anchors,</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>        num_classes] <span class="keywordflow">or</span> [batch_size, num_anchors, 1]. If the shape <span class="keywordflow">is</span></div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>        [batch_size, num_anchors, 1], all the classses are equally weighted.</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span> </div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span>    Returns:</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span>      loss: a float tensor of shape [batch_size, num_anchors]</div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>        representing the value of the loss function.</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span><span class="stringliteral">    weights = tf.reduce_mean(weights, axis=2)</span></div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span><span class="stringliteral">    num_classes = prediction_tensor.get_shape().as_list()[-1]</span></div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span><span class="stringliteral">    prediction_tensor = tf.divide(</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span><span class="stringliteral">        prediction_tensor, self.<a class="code hl_variable" href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a404314a3aab27fc9dcb2dbc25851b56c">_logit_scale</a>, name=&#39;scale_logit&#39;</span>)</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>    per_row_cross_ent = (tf.nn.softmax_cross_entropy_with_logits(</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>        labels=tf.reshape(target_tensor, [-1, num_classes]),</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>        logits=tf.reshape(prediction_tensor, [-1, num_classes])))</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>    <span class="keywordflow">return</span> tf.reshape(per_row_cross_ent, tf.shape(weights)) * weights</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span> </div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span> </div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno"><a class="line" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html">  354</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html">WeightedSoftmaxClassificationAgainstLogitsLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>  <span class="stringliteral">&quot;&quot;&quot;Softmax loss function against logits.</span></div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span><span class="stringliteral">   Targets are expected to be provided </span><span class="keywordflow">in</span> logits space instead of <span class="stringliteral">&quot;one hot&quot;</span> <span class="keywordflow">or</span></div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>   <span class="stringliteral">&quot;probability distribution&quot;</span> space.</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno"><a class="line" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a8b44b227d04e7dd1b8e6079342a535fa">  361</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a8b44b227d04e7dd1b8e6079342a535fa">__init__</a>(self, logit_scale=1.0):</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span><span class="stringliteral">      logit_scale: When this value </span><span class="keywordflow">is</span> high, the target <span class="keywordflow">is</span> <span class="stringliteral">&quot;diffused&quot;</span> <span class="keywordflow">and</span></div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>                   when this value <span class="keywordflow">is</span> low, the target <span class="keywordflow">is</span> made peakier.</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>                   (default 1.0)</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span> </div>
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno">  369</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span><span class="stringliteral">    super(WeightedSoftmaxClassificationAgainstLogitsLoss, self).<a class="code hl_function" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a8b44b227d04e7dd1b8e6079342a535fa">__init__</a>()</span></div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno"><a class="line" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a90b59234980cf95e5139fc5e2f00843e">  371</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a90b59234980cf95e5139fc5e2f00843e">_logit_scale</a> = logit_scale</span></div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno"><a class="line" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a7fb6902c62d6a331ae8dd5521b6a1089">  373</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a7fb6902c62d6a331ae8dd5521b6a1089">_scale_and_softmax_logits</a>(self, logits):</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>    <span class="stringliteral">&quot;&quot;&quot;Scale logits then apply softmax.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>    scaled_logits = tf.divide(logits, self.<a class="code hl_variable" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a90b59234980cf95e5139fc5e2f00843e">_logit_scale</a>, name=<span class="stringliteral">&#39;scale_logits&#39;</span>)</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>    <span class="keywordflow">return</span> tf.nn.softmax(scaled_logits, name=<span class="stringliteral">&#39;convert_scores&#39;</span>)</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span> </div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno"><a class="line" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a34c03e1dffb28a11c360679afedec8e4">  378</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a34c03e1dffb28a11c360679afedec8e4">_compute_loss</a>(self, prediction_tensor, target_tensor, weights):</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span><span class="stringliteral">        num_classes] representing the predicted logits </span><span class="keywordflow">for</span> each <span class="keyword">class</span></div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>      target_tensor: A float tensor of shape [batch_size, num_anchors,</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>        num_classes] representing logit classification targets</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>      weights: a float tensor of shape, either [batch_size, num_anchors,</div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>        num_classes] <span class="keywordflow">or</span> [batch_size, num_anchors, 1]. If the shape <span class="keywordflow">is</span></div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>        [batch_size, num_anchors, 1], all the classses are equally weighted.</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span> </div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>    Returns:</div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>      loss: a float tensor of shape [batch_size, num_anchors]</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>        representing the value of the loss function.</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span><span class="stringliteral">    weights = tf.reduce_mean(weights, axis=2)</span></div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span><span class="stringliteral">    num_classes = prediction_tensor.get_shape().as_list()[-1]</span></div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span><span class="stringliteral">    target_tensor = self.<a class="code hl_function" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a7fb6902c62d6a331ae8dd5521b6a1089">_scale_and_softmax_logits</a>(target_tensor)</span></div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span><span class="stringliteral">    prediction_tensor = tf.divide(prediction_tensor, self.<a class="code hl_variable" href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a90b59234980cf95e5139fc5e2f00843e">_logit_scale</a>,</span></div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span><span class="stringliteral">                                  name=&#39;scale_logits&#39;</span>)</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span> </div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>    per_row_cross_ent = (tf.nn.softmax_cross_entropy_with_logits(</div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>        labels=tf.reshape(target_tensor, [-1, num_classes]),</div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>        logits=tf.reshape(prediction_tensor, [-1, num_classes])))</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>    <span class="keywordflow">return</span> tf.reshape(per_row_cross_ent, tf.shape(weights)) * weights</div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span> </div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span> </div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno"><a class="line" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html">  406</a></span><span class="keyword">class </span><a class="code hl_class" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html">BootstrappedSigmoidClassificationLoss</a>(<a class="code hl_class" href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">Loss</a>):</div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>  <span class="stringliteral">&quot;&quot;&quot;Bootstrapped sigmoid cross entropy classification loss function.</span></div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span><span class="stringliteral">  This loss uses a convex combination of training labels </span><span class="keywordflow">and</span> the current model<span class="stringliteral">&#39;s</span></div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span><span class="stringliteral">  predictions </span><span class="keyword">as</span> training targets <span class="keywordflow">in</span> the classification loss. The idea <span class="keywordflow">is</span> that</div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>  <span class="keyword">as</span> the model improves over time, its predictions can be trusted more <span class="keywordflow">and</span> we</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>  can use these predictions to mitigate the damage of noisy/incorrect labels,</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>  because incorrect labels are likely to be eventually highly inconsistent <span class="keyword">with</span></div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>  other stimuli predicted to have the same label by the model.</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span> </div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>  In <span class="stringliteral">&quot;soft&quot;</span> bootstrapping, we use all predicted <span class="keyword">class </span>probabilities, whereas in</div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>  <span class="stringliteral">&quot;hard&quot;</span> bootstrapping, we use the single <span class="keyword">class </span>favored by the model.</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span> </div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>  See also Training Deep Neural Networks On Noisy Labels <span class="keyword">with</span> Bootstrapping by</div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>  Reed et al. (ICLR 2015).</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno"><a class="line" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a07130d0c2c29c2757f72059da3dbe79f">  423</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a07130d0c2c29c2757f72059da3dbe79f">__init__</a>(self, alpha, bootstrap_type=&#39;soft&#39;):</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span><span class="stringliteral">      alpha: a float32 scalar tensor between 0 </span><span class="keywordflow">and</span> 1 representing interpolation</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>        weight</div>
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno">  429</span>      bootstrap_type: set to either <span class="stringliteral">&#39;hard&#39;</span> <span class="keywordflow">or</span> <span class="stringliteral">&#39;soft&#39;</span> (default)</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span> </div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>    Raises:</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>      ValueError: <span class="keywordflow">if</span> bootstrap_type <span class="keywordflow">is</span> <span class="keywordflow">not</span> either <span class="stringliteral">&#39;hard&#39;</span> <span class="keywordflow">or</span> <span class="stringliteral">&#39;soft&#39;</span></div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span><span class="stringliteral">    super(BootstrappedSigmoidClassificationLoss, self).<a class="code hl_function" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a07130d0c2c29c2757f72059da3dbe79f">__init__</a>()</span></div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span><span class="stringliteral">    </span><span class="keywordflow">if</span> bootstrap_type != <span class="stringliteral">&#39;hard&#39;</span> <span class="keywordflow">and</span> bootstrap_type != <span class="stringliteral">&#39;soft&#39;</span>:</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;Unrecognized bootstrap_type: must be one of &#39;</span></div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>                       <span class="stringliteral">&#39;\&#39;hard\&#39; or \&#39;soft.\&#39;&#39;</span>)</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno"><a class="line" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">  438</a></span>    self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">_alpha</a> = alpha</div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno"><a class="line" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a20a73b254e0341b61ddb91b7e54e7543">  439</a></span>    self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a20a73b254e0341b61ddb91b7e54e7543">_bootstrap_type</a> = bootstrap_type</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span> </div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno"><a class="line" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a4587575bad0c453943b4faf57527853c">  441</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a4587575bad0c453943b4faf57527853c">_compute_loss</a>(self, prediction_tensor, target_tensor, weights):</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>    <span class="stringliteral">&quot;&quot;&quot;Compute loss function.</span></div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span><span class="stringliteral">      prediction_tensor: A float tensor of shape [batch_size, num_anchors,</span></div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span><span class="stringliteral">        num_classes] representing the predicted logits </span><span class="keywordflow">for</span> each <span class="keyword">class</span></div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>      target_tensor: A float tensor of shape [batch_size, num_anchors,</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>        num_classes] representing one-hot encoded classification targets</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>      weights: a float tensor of shape, either [batch_size, num_anchors,</div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>        num_classes] <span class="keywordflow">or</span> [batch_size, num_anchors, 1]. If the shape <span class="keywordflow">is</span></div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>        [batch_size, num_anchors, 1], all the classses are equally weighted.</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span> </div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>    Returns:</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>      loss: a float tensor of shape [batch_size, num_anchors, num_classes]</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>        representing the value of the loss function.</div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span><span class="stringliteral">    </span><span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a20a73b254e0341b61ddb91b7e54e7543">_bootstrap_type</a> == <span class="stringliteral">&#39;soft&#39;</span>:</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>      bootstrap_target_tensor = self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">_alpha</a> * target_tensor + (</div>
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno">  459</span>          1.0 - self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">_alpha</a>) * tf.sigmoid(prediction_tensor)</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>      bootstrap_target_tensor = self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">_alpha</a> * target_tensor + (</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>          1.0 - self.<a class="code hl_variable" href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">_alpha</a>) * tf.cast(</div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span>              tf.sigmoid(prediction_tensor) &gt; 0.5, tf.float32)</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno">  464</span>    per_entry_cross_ent = (tf.nn.sigmoid_cross_entropy_with_logits(</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno">  465</span>        labels=bootstrap_target_tensor, logits=prediction_tensor))</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno">  466</span>    <span class="keywordflow">return</span> per_entry_cross_ent * weights</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span> </div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno">  468</span> </div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html">  469</a></span><span class="keyword">class </span><a class="code hl_class" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html">HardExampleMiner</a>(object):</div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno">  470</span>  <span class="stringliteral">&quot;&quot;&quot;Hard example mining for regions in a list of images.</span></div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno">  471</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno">  472</span><span class="stringliteral">  Implements hard example mining to select a subset of regions to be</span></div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno">  473</span><span class="stringliteral">  back-propagated. For each image, selects the regions </span><span class="keyword">with</span> highest losses,</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno">  474</span>  subject to the condition that a newly selected region cannot have</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno">  475</span>  an IOU &gt; iou_threshold <span class="keyword">with</span> any of the previously selected regions.</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno">  476</span>  This can be achieved by re-using a greedy non-maximum suppression algorithm.</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno">  477</span>  A constraint on the number of negatives mined per positive region can also be</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>  enforced.</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span> </div>
<div class="line"><a id="l00480" name="l00480"></a><span class="lineno">  480</span>  Reference papers: <span class="stringliteral">&quot;Training Region-based Object Detectors with Online</span></div>
<div class="line"><a id="l00481" name="l00481"></a><span class="lineno">  481</span><span class="stringliteral">  Hard Example Mining&quot; (CVPR 2016) by Srivastava et al., and</span></div>
<div class="line"><a id="l00482" name="l00482"></a><span class="lineno">  482</span><span class="stringliteral">  &quot;SSD: Single Shot MultiBox Detector&quot;</span> (ECCV 2016) by Liu et al.</div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno">  484</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a4714a733ae4075fe0201c4ae524c893b">  485</a></span><span class="stringliteral">  </span><span class="keyword">def </span><a class="code hl_function" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a4714a733ae4075fe0201c4ae524c893b">__init__</a>(self,</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno">  486</span>               num_hard_examples=64,</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>               iou_threshold=0.7,</div>
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno">  488</span>               loss_type=&#39;both&#39;,</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>               cls_loss_weight=0.05,</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>               loc_loss_weight=0.06,</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>               max_negatives_per_positive=None,</div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>               min_negatives_per_image=0):</div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span><span class="stringliteral">    The hard example mining implemented by this </span><span class="keyword">class </span>can replicate the behavior</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>    <span class="keywordflow">in</span> the two aforementioned papers (Srivastava et al., <span class="keywordflow">and</span> Liu et al).</div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>    To replicate the A2 paper (Srivastava et al), num_hard_examples <span class="keywordflow">is</span> set</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>    to a fixed parameter (64 by default) <span class="keywordflow">and</span> iou_threshold <span class="keywordflow">is</span> set to .7 <span class="keywordflow">for</span></div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>    running non-max-suppression the predicted boxes prior to hard mining.</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>    In order to replicate the SSD paper (Liu et al), num_hard_examples should</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>    be set to <span class="keywordtype">None</span>, max_negatives_per_positive should be 3 <span class="keywordflow">and</span> iou_threshold</div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>    should be 1.0 (<span class="keywordflow">in</span> order to effectively turn off NMS).</div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span> </div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>    Args:</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>      num_hard_examples: maximum number of hard examples to be</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>        selected per image (prior to enforcing max negative to positive ratio</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>        constraint).  If set to <span class="keywordtype">None</span>, all examples obtained after NMS are</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>        considered.</div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>      iou_threshold: minimum intersection over union <span class="keywordflow">for</span> an example</div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>        to be discarded during NMS.</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>      loss_type: use only classification losses (<span class="stringliteral">&#39;cls&#39;</span>, default),</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>        localization losses (<span class="stringliteral">&#39;loc&#39;</span>) <span class="keywordflow">or</span> both losses (<span class="stringliteral">&#39;both&#39;</span>).</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>        In the last case, cls_loss_weight <span class="keywordflow">and</span> loc_loss_weight are used to</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>        compute weighted sum of the two losses.</div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>      cls_loss_weight: weight <span class="keywordflow">for</span> classification loss.</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>      loc_loss_weight: weight <span class="keywordflow">for</span> location loss.</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>      max_negatives_per_positive: maximum number of negatives to retain <span class="keywordflow">for</span></div>
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno">  518</span>        each positive anchor. By default, num_negatives_per_positive <span class="keywordflow">is</span> <span class="keywordtype">None</span>,</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>        which means that we do <span class="keywordflow">not</span> enforce a prespecified negative:positive</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>        ratio.  Note also that num_negatives_per_positives can be a float</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>        (<span class="keywordflow">and</span> will be converted to be a float even <span class="keywordflow">if</span> it <span class="keywordflow">is</span> passed <span class="keywordflow">in</span> otherwise).</div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>      min_negatives_per_image: minimum number of negative anchors to sample <span class="keywordflow">for</span></div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>        a given image. Setting this to a positive number allows sampling</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>        negatives <span class="keywordflow">in</span> an image without any positive anchors <span class="keywordflow">and</span> thus <span class="keywordflow">not</span> biased</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>        towards at least one detection per image.</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a9050aefac710d08563f24a578253c5ea">  527</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a9050aefac710d08563f24a578253c5ea">_num_hard_examples</a> = num_hard_examples</span></div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#acf91868a8598f087df796a515012f05b">  528</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#acf91868a8598f087df796a515012f05b">_iou_threshold</a> = iou_threshold</span></div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a6e62eb86f10ebdf80850f4490719f292">  529</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a6e62eb86f10ebdf80850f4490719f292">_loss_type</a> = loss_type</span></div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#aada46a2de44d7810ebc15e830599004a">  530</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#aada46a2de44d7810ebc15e830599004a">_cls_loss_weight</a> = cls_loss_weight</span></div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a53dea51ec308ccfdb6517195b24e3a57">  531</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a53dea51ec308ccfdb6517195b24e3a57">_loc_loss_weight</a> = loc_loss_weight</span></div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">  532</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a> = max_negatives_per_positive</span></div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad7dc2027cdc13b61de9ba1daab9779af">  533</a></span><span class="stringliteral">    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad7dc2027cdc13b61de9ba1daab9779af">_min_negatives_per_image</a> = min_negatives_per_image</span></div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span><span class="stringliteral">    </span><span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a> <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>      self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a> = float(self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a>)</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad9f01903634e61d36c7ebfefed1edc4e">  536</a></span>    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad9f01903634e61d36c7ebfefed1edc4e">_num_positives_list</a> = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a04a79ab082067e7db546cdbe01f734f8">  537</a></span>    self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a04a79ab082067e7db546cdbe01f734f8">_num_negatives_list</a> = <span class="keywordtype">None</span></div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno">  538</span> </div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a7f13fd5f8f6e0f1fbe3297cad7cebd0f">  539</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a7f13fd5f8f6e0f1fbe3297cad7cebd0f">__call__</a>(self,</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span>               location_losses,</div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span>               cls_losses,</div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno">  542</span>               decoded_boxlist_list,</div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno">  543</span>               match_list=None):</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno">  544</span>    <span class="stringliteral">&quot;&quot;&quot;Computes localization and classification losses after hard mining.</span></div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno">  545</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno">  546</span><span class="stringliteral">    Args:</span></div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno">  547</span><span class="stringliteral">      location_losses: a float tensor of shape [num_images, num_anchors]</span></div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno">  548</span><span class="stringliteral">        representing anchorwise localization losses.</span></div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno">  549</span><span class="stringliteral">      cls_losses: a float tensor of shape [num_images, num_anchors]</span></div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno">  550</span><span class="stringliteral">        representing anchorwise classification losses.</span></div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno">  551</span><span class="stringliteral">      decoded_boxlist_list: a list of decoded BoxList representing location</span></div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno">  552</span><span class="stringliteral">        predictions </span><span class="keywordflow">for</span> each image.</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno">  553</span>      match_list: an optional list of <a class="code hl_class" href="../../db/d24/classdetection__utils_1_1core_1_1matcher_1_1_match.html">matcher.Match</a> objects encoding the match</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno">  554</span>        between anchors <span class="keywordflow">and</span> groundtruth boxes <span class="keywordflow">for</span> each image of the batch,</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno">  555</span>        <span class="keyword">with</span> rows of the Match objects corresponding to groundtruth boxes</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span>        <span class="keywordflow">and</span> columns corresponding to anchors.  Match objects <span class="keywordflow">in</span> match_list are</div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>        used to reference which anchors are positive, negative <span class="keywordflow">or</span> ignored.  If</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>        self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a> exists, these are then used to enforce</div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span>        a prespecified negative to positive ratio.</div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span> </div>
<div class="line"><a id="l00561" name="l00561"></a><span class="lineno">  561</span>    Returns:</div>
<div class="line"><a id="l00562" name="l00562"></a><span class="lineno">  562</span>      mined_location_loss: a float scalar <span class="keyword">with</span> sum of localization losses <span class="keyword">from</span></div>
<div class="line"><a id="l00563" name="l00563"></a><span class="lineno">  563</span>        selected hard examples.</div>
<div class="line"><a id="l00564" name="l00564"></a><span class="lineno">  564</span>      mined_cls_loss: a float scalar <span class="keyword">with</span> sum of classification losses <span class="keyword">from</span></div>
<div class="line"><a id="l00565" name="l00565"></a><span class="lineno">  565</span>        selected hard examples.</div>
<div class="line"><a id="l00566" name="l00566"></a><span class="lineno">  566</span>    Raises:</div>
<div class="line"><a id="l00567" name="l00567"></a><span class="lineno">  567</span>      ValueError: <span class="keywordflow">if</span> location_losses, cls_losses <span class="keywordflow">and</span> decoded_boxlist_list do</div>
<div class="line"><a id="l00568" name="l00568"></a><span class="lineno">  568</span>        <span class="keywordflow">not</span> have compatible shapes (i.e., they must correspond to the same</div>
<div class="line"><a id="l00569" name="l00569"></a><span class="lineno">  569</span>        number of images).</div>
<div class="line"><a id="l00570" name="l00570"></a><span class="lineno">  570</span>      ValueError: <span class="keywordflow">if</span> match_list <span class="keywordflow">is</span> specified but its length does <span class="keywordflow">not</span> match</div>
<div class="line"><a id="l00571" name="l00571"></a><span class="lineno">  571</span>        len(decoded_boxlist_list).</div>
<div class="line"><a id="l00572" name="l00572"></a><span class="lineno">  572</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00573" name="l00573"></a><span class="lineno">  573</span><span class="stringliteral">    mined_location_losses = []</span></div>
<div class="line"><a id="l00574" name="l00574"></a><span class="lineno">  574</span><span class="stringliteral">    mined_cls_losses = []</span></div>
<div class="line"><a id="l00575" name="l00575"></a><span class="lineno">  575</span><span class="stringliteral">    location_losses = tf.unstack(location_losses)</span></div>
<div class="line"><a id="l00576" name="l00576"></a><span class="lineno">  576</span><span class="stringliteral">    cls_losses = tf.unstack(cls_losses)</span></div>
<div class="line"><a id="l00577" name="l00577"></a><span class="lineno">  577</span><span class="stringliteral">    num_images = len(decoded_boxlist_list)</span></div>
<div class="line"><a id="l00578" name="l00578"></a><span class="lineno">  578</span><span class="stringliteral">    </span><span class="keywordflow">if</span> <span class="keywordflow">not</span> match_list:</div>
<div class="line"><a id="l00579" name="l00579"></a><span class="lineno">  579</span>      match_list = num_images * [<span class="keywordtype">None</span>]</div>
<div class="line"><a id="l00580" name="l00580"></a><span class="lineno">  580</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> len(location_losses) == len(decoded_boxlist_list) == len(cls_losses):</div>
<div class="line"><a id="l00581" name="l00581"></a><span class="lineno">  581</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;location_losses, cls_losses and decoded_boxlist_list &#39;</span></div>
<div class="line"><a id="l00582" name="l00582"></a><span class="lineno">  582</span>                       <span class="stringliteral">&#39;do not have compatible shapes.&#39;</span>)</div>
<div class="line"><a id="l00583" name="l00583"></a><span class="lineno">  583</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(match_list, list):</div>
<div class="line"><a id="l00584" name="l00584"></a><span class="lineno">  584</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;match_list must be a list.&#39;</span>)</div>
<div class="line"><a id="l00585" name="l00585"></a><span class="lineno">  585</span>    <span class="keywordflow">if</span> len(match_list) != len(decoded_boxlist_list):</div>
<div class="line"><a id="l00586" name="l00586"></a><span class="lineno">  586</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;match_list must either be None or have &#39;</span></div>
<div class="line"><a id="l00587" name="l00587"></a><span class="lineno">  587</span>                       <span class="stringliteral">&#39;length=len(decoded_boxlist_list).&#39;</span>)</div>
<div class="line"><a id="l00588" name="l00588"></a><span class="lineno">  588</span>    num_positives_list = []</div>
<div class="line"><a id="l00589" name="l00589"></a><span class="lineno">  589</span>    num_negatives_list = []</div>
<div class="line"><a id="l00590" name="l00590"></a><span class="lineno">  590</span>    <span class="keywordflow">for</span> ind, detection_boxlist <span class="keywordflow">in</span> enumerate(decoded_boxlist_list):</div>
<div class="line"><a id="l00591" name="l00591"></a><span class="lineno">  591</span>      box_locations = detection_boxlist.get()</div>
<div class="line"><a id="l00592" name="l00592"></a><span class="lineno">  592</span>      match = match_list[ind]</div>
<div class="line"><a id="l00593" name="l00593"></a><span class="lineno">  593</span>      image_losses = cls_losses[ind]</div>
<div class="line"><a id="l00594" name="l00594"></a><span class="lineno">  594</span>      <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a6e62eb86f10ebdf80850f4490719f292">_loss_type</a> == <span class="stringliteral">&#39;loc&#39;</span>:</div>
<div class="line"><a id="l00595" name="l00595"></a><span class="lineno">  595</span>        image_losses = location_losses[ind]</div>
<div class="line"><a id="l00596" name="l00596"></a><span class="lineno">  596</span>      <span class="keywordflow">elif</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a6e62eb86f10ebdf80850f4490719f292">_loss_type</a> == <span class="stringliteral">&#39;both&#39;</span>:</div>
<div class="line"><a id="l00597" name="l00597"></a><span class="lineno">  597</span>        image_losses *= self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#aada46a2de44d7810ebc15e830599004a">_cls_loss_weight</a></div>
<div class="line"><a id="l00598" name="l00598"></a><span class="lineno">  598</span>        image_losses += location_losses[ind] * self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a53dea51ec308ccfdb6517195b24e3a57">_loc_loss_weight</a></div>
<div class="line"><a id="l00599" name="l00599"></a><span class="lineno">  599</span>      <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a9050aefac710d08563f24a578253c5ea">_num_hard_examples</a> <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><a id="l00600" name="l00600"></a><span class="lineno">  600</span>        num_hard_examples = self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a9050aefac710d08563f24a578253c5ea">_num_hard_examples</a></div>
<div class="line"><a id="l00601" name="l00601"></a><span class="lineno">  601</span>      <span class="keywordflow">else</span>:</div>
<div class="line"><a id="l00602" name="l00602"></a><span class="lineno">  602</span>        num_hard_examples = detection_boxlist.num_boxes()</div>
<div class="line"><a id="l00603" name="l00603"></a><span class="lineno">  603</span>      selected_indices = tf.image.non_max_suppression(</div>
<div class="line"><a id="l00604" name="l00604"></a><span class="lineno">  604</span>          box_locations, image_losses, num_hard_examples, self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#acf91868a8598f087df796a515012f05b">_iou_threshold</a>)</div>
<div class="line"><a id="l00605" name="l00605"></a><span class="lineno">  605</span>      <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a> <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">and</span> match:</div>
<div class="line"><a id="l00606" name="l00606"></a><span class="lineno">  606</span>        (selected_indices, num_positives,</div>
<div class="line"><a id="l00607" name="l00607"></a><span class="lineno">  607</span>         num_negatives) = self.<a class="code hl_function" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad1541128616ed73e7e7d669330909b48">_subsample_selection_to_desired_neg_pos_ratio</a>(</div>
<div class="line"><a id="l00608" name="l00608"></a><span class="lineno">  608</span>             selected_indices, match, self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a>,</div>
<div class="line"><a id="l00609" name="l00609"></a><span class="lineno">  609</span>             self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad7dc2027cdc13b61de9ba1daab9779af">_min_negatives_per_image</a>)</div>
<div class="line"><a id="l00610" name="l00610"></a><span class="lineno">  610</span>        num_positives_list.append(num_positives)</div>
<div class="line"><a id="l00611" name="l00611"></a><span class="lineno">  611</span>        num_negatives_list.append(num_negatives)</div>
<div class="line"><a id="l00612" name="l00612"></a><span class="lineno">  612</span>      mined_location_losses.append(</div>
<div class="line"><a id="l00613" name="l00613"></a><span class="lineno">  613</span>          tf.reduce_sum(tf.gather(location_losses[ind], selected_indices)))</div>
<div class="line"><a id="l00614" name="l00614"></a><span class="lineno">  614</span>      mined_cls_losses.append(</div>
<div class="line"><a id="l00615" name="l00615"></a><span class="lineno">  615</span>          tf.reduce_sum(tf.gather(cls_losses[ind], selected_indices)))</div>
<div class="line"><a id="l00616" name="l00616"></a><span class="lineno">  616</span>    location_loss = tf.reduce_sum(tf.stack(mined_location_losses))</div>
<div class="line"><a id="l00617" name="l00617"></a><span class="lineno">  617</span>    cls_loss = tf.reduce_sum(tf.stack(mined_cls_losses))</div>
<div class="line"><a id="l00618" name="l00618"></a><span class="lineno">  618</span>    <span class="keywordflow">if</span> match <span class="keywordflow">and</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">_max_negatives_per_positive</a>:</div>
<div class="line"><a id="l00619" name="l00619"></a><span class="lineno">  619</span>      self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad9f01903634e61d36c7ebfefed1edc4e">_num_positives_list</a> = num_positives_list</div>
<div class="line"><a id="l00620" name="l00620"></a><span class="lineno">  620</span>      self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a04a79ab082067e7db546cdbe01f734f8">_num_negatives_list</a> = num_negatives_list</div>
<div class="line"><a id="l00621" name="l00621"></a><span class="lineno">  621</span>    <span class="keywordflow">return</span> (location_loss, cls_loss)</div>
<div class="line"><a id="l00622" name="l00622"></a><span class="lineno">  622</span> </div>
<div class="line"><a id="l00623" name="l00623"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a5102f1118d6088014302904479ff3f81">  623</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a5102f1118d6088014302904479ff3f81">summarize</a>(self):</div>
<div class="line"><a id="l00624" name="l00624"></a><span class="lineno">  624</span>    <span class="stringliteral">&quot;&quot;&quot;Summarize the number of positives and negatives after mining.&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00625" name="l00625"></a><span class="lineno">  625</span>    <span class="keywordflow">if</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad9f01903634e61d36c7ebfefed1edc4e">_num_positives_list</a> <span class="keywordflow">and</span> self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a04a79ab082067e7db546cdbe01f734f8">_num_negatives_list</a>:</div>
<div class="line"><a id="l00626" name="l00626"></a><span class="lineno">  626</span>      avg_num_positives = tf.reduce_mean(</div>
<div class="line"><a id="l00627" name="l00627"></a><span class="lineno">  627</span>          tf.cast(self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad9f01903634e61d36c7ebfefed1edc4e">_num_positives_list</a>, dtype=tf.float32))</div>
<div class="line"><a id="l00628" name="l00628"></a><span class="lineno">  628</span>      avg_num_negatives = tf.reduce_mean(</div>
<div class="line"><a id="l00629" name="l00629"></a><span class="lineno">  629</span>          tf.cast(self.<a class="code hl_variable" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a04a79ab082067e7db546cdbe01f734f8">_num_negatives_list</a>, dtype=tf.float32))</div>
<div class="line"><a id="l00630" name="l00630"></a><span class="lineno">  630</span>      tf.summary.scalar(<span class="stringliteral">&#39;HardExampleMiner/NumPositives&#39;</span>, avg_num_positives)</div>
<div class="line"><a id="l00631" name="l00631"></a><span class="lineno">  631</span>      tf.summary.scalar(<span class="stringliteral">&#39;HardExampleMiner/NumNegatives&#39;</span>, avg_num_negatives)</div>
<div class="line"><a id="l00632" name="l00632"></a><span class="lineno">  632</span> </div>
<div class="line"><a id="l00633" name="l00633"></a><span class="lineno"><a class="line" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad1541128616ed73e7e7d669330909b48">  633</a></span>  <span class="keyword">def </span><a class="code hl_function" href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad1541128616ed73e7e7d669330909b48">_subsample_selection_to_desired_neg_pos_ratio</a>(self,</div>
<div class="line"><a id="l00634" name="l00634"></a><span class="lineno">  634</span>                                                    indices,</div>
<div class="line"><a id="l00635" name="l00635"></a><span class="lineno">  635</span>                                                    match,</div>
<div class="line"><a id="l00636" name="l00636"></a><span class="lineno">  636</span>                                                    max_negatives_per_positive,</div>
<div class="line"><a id="l00637" name="l00637"></a><span class="lineno">  637</span>                                                    min_negatives_per_image=0):</div>
<div class="line"><a id="l00638" name="l00638"></a><span class="lineno">  638</span>    <span class="stringliteral">&quot;&quot;&quot;Subsample a collection of selected indices to a desired neg:pos ratio.</span></div>
<div class="line"><a id="l00639" name="l00639"></a><span class="lineno">  639</span><span class="stringliteral"></span> </div>
<div class="line"><a id="l00640" name="l00640"></a><span class="lineno">  640</span><span class="stringliteral">    This function takes a subset of M indices (indexing into a large anchor</span></div>
<div class="line"><a id="l00641" name="l00641"></a><span class="lineno">  641</span><span class="stringliteral">    collection of N anchors where M&lt;N) which are labeled </span><span class="keyword">as</span> positive/negative</div>
<div class="line"><a id="l00642" name="l00642"></a><span class="lineno">  642</span>    via a Match object (matched indices are positive, unmatched indices</div>
<div class="line"><a id="l00643" name="l00643"></a><span class="lineno">  643</span>    are negative).  It returns a subset of the provided indices retaining all</div>
<div class="line"><a id="l00644" name="l00644"></a><span class="lineno">  644</span>    positives <span class="keyword">as</span> well <span class="keyword">as</span> up to the first K negatives, where:</div>
<div class="line"><a id="l00645" name="l00645"></a><span class="lineno">  645</span>      K=floor(num_negative_per_positive * num_positives).</div>
<div class="line"><a id="l00646" name="l00646"></a><span class="lineno">  646</span> </div>
<div class="line"><a id="l00647" name="l00647"></a><span class="lineno">  647</span>    For example, <span class="keywordflow">if</span> indices=[2, 4, 5, 7, 9, 10] (indexing into 12 anchors),</div>
<div class="line"><a id="l00648" name="l00648"></a><span class="lineno">  648</span>    <span class="keyword">with</span> positives=[2, 5] <span class="keywordflow">and</span> negatives=[4, 7, 9, 10] <span class="keywordflow">and</span></div>
<div class="line"><a id="l00649" name="l00649"></a><span class="lineno">  649</span>    num_negatives_per_positive=1, then the returned subset of indices</div>
<div class="line"><a id="l00650" name="l00650"></a><span class="lineno">  650</span>    <span class="keywordflow">is</span> [2, 4, 5, 7].</div>
<div class="line"><a id="l00651" name="l00651"></a><span class="lineno">  651</span> </div>
<div class="line"><a id="l00652" name="l00652"></a><span class="lineno">  652</span>    Args:</div>
<div class="line"><a id="l00653" name="l00653"></a><span class="lineno">  653</span>      indices: An integer tensor of shape [M] representing a collection</div>
<div class="line"><a id="l00654" name="l00654"></a><span class="lineno">  654</span>        of selected anchor indices</div>
<div class="line"><a id="l00655" name="l00655"></a><span class="lineno">  655</span>      match: A <a class="code hl_class" href="../../db/d24/classdetection__utils_1_1core_1_1matcher_1_1_match.html">matcher.Match</a> object encoding the match between anchors <span class="keywordflow">and</span></div>
<div class="line"><a id="l00656" name="l00656"></a><span class="lineno">  656</span>        groundtruth boxes <span class="keywordflow">for</span> a given image, <span class="keyword">with</span> rows of the Match objects</div>
<div class="line"><a id="l00657" name="l00657"></a><span class="lineno">  657</span>        corresponding to groundtruth boxes <span class="keywordflow">and</span> columns corresponding to anchors.</div>
<div class="line"><a id="l00658" name="l00658"></a><span class="lineno">  658</span>      max_negatives_per_positive: (float) maximum number of negatives <span class="keywordflow">for</span></div>
<div class="line"><a id="l00659" name="l00659"></a><span class="lineno">  659</span>        each positive anchor.</div>
<div class="line"><a id="l00660" name="l00660"></a><span class="lineno">  660</span>      min_negatives_per_image: minimum number of negative anchors <span class="keywordflow">for</span> a given</div>
<div class="line"><a id="l00661" name="l00661"></a><span class="lineno">  661</span>        image. Allow sampling negatives <span class="keywordflow">in</span> image without any positive anchors.</div>
<div class="line"><a id="l00662" name="l00662"></a><span class="lineno">  662</span> </div>
<div class="line"><a id="l00663" name="l00663"></a><span class="lineno">  663</span>    Returns:</div>
<div class="line"><a id="l00664" name="l00664"></a><span class="lineno">  664</span>      selected_indices: An integer tensor of shape [M<span class="stringliteral">&#39;] representing a</span></div>
<div class="line"><a id="l00665" name="l00665"></a><span class="lineno">  665</span><span class="stringliteral">        collection of selected anchor indices </span><span class="keyword">with</span> M<span class="stringliteral">&#39; &lt;= M.</span></div>
<div class="line"><a id="l00666" name="l00666"></a><span class="lineno">  666</span><span class="stringliteral">      num_positives: An integer tensor representing the number of positive</span></div>
<div class="line"><a id="l00667" name="l00667"></a><span class="lineno">  667</span><span class="stringliteral">        examples </span><span class="keywordflow">in</span> selected set of indices.</div>
<div class="line"><a id="l00668" name="l00668"></a><span class="lineno">  668</span>      num_negatives: An integer tensor representing the number of negative</div>
<div class="line"><a id="l00669" name="l00669"></a><span class="lineno">  669</span>        examples <span class="keywordflow">in</span> selected set of indices.</div>
<div class="line"><a id="l00670" name="l00670"></a><span class="lineno">  670</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><a id="l00671" name="l00671"></a><span class="lineno">  671</span><span class="stringliteral">    positives_indicator = tf.gather(match.matched_column_indicator(), indices)</span></div>
<div class="line"><a id="l00672" name="l00672"></a><span class="lineno">  672</span><span class="stringliteral">    negatives_indicator = tf.gather(match.unmatched_column_indicator(), indices)</span></div>
<div class="line"><a id="l00673" name="l00673"></a><span class="lineno">  673</span><span class="stringliteral">    num_positives = tf.reduce_sum(tf.cast(positives_indicator, dtype=tf.int32))</span></div>
<div class="line"><a id="l00674" name="l00674"></a><span class="lineno">  674</span><span class="stringliteral">    max_negatives = tf.maximum(</span></div>
<div class="line"><a id="l00675" name="l00675"></a><span class="lineno">  675</span><span class="stringliteral">        min_negatives_per_image,</span></div>
<div class="line"><a id="l00676" name="l00676"></a><span class="lineno">  676</span><span class="stringliteral">        tf.cast(max_negatives_per_positive *</span></div>
<div class="line"><a id="l00677" name="l00677"></a><span class="lineno">  677</span><span class="stringliteral">                tf.cast(num_positives, dtype=tf.float32), dtype=tf.int32))</span></div>
<div class="line"><a id="l00678" name="l00678"></a><span class="lineno">  678</span><span class="stringliteral">    topk_negatives_indicator = tf.less_equal(</span></div>
<div class="line"><a id="l00679" name="l00679"></a><span class="lineno">  679</span><span class="stringliteral">        tf.cumsum(tf.cast(negatives_indicator, dtype=tf.int32)), max_negatives)</span></div>
<div class="line"><a id="l00680" name="l00680"></a><span class="lineno">  680</span><span class="stringliteral">    subsampled_selection_indices = tf.where(</span></div>
<div class="line"><a id="l00681" name="l00681"></a><span class="lineno">  681</span><span class="stringliteral">        tf.logical_or(positives_indicator, topk_negatives_indicator))</span></div>
<div class="line"><a id="l00682" name="l00682"></a><span class="lineno">  682</span><span class="stringliteral">    num_negatives = tf.size(subsampled_selection_indices) - num_positives</span></div>
<div class="line"><a id="l00683" name="l00683"></a><span class="lineno">  683</span><span class="stringliteral">    </span><span class="keywordflow">return</span> (tf.reshape(tf.gather(indices, subsampled_selection_indices), [-1]),</div>
<div class="line"><a id="l00684" name="l00684"></a><span class="lineno">  684</span>            num_positives, num_negatives)</div>
<div class="line"><a id="l00685" name="l00685"></a><span class="lineno">  685</span> </div>
<div class="line"><a id="l00686" name="l00686"></a><span class="lineno">  686</span> </div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1box__list_1_1_box_list_html"><div class="ttname"><a href="../../df/de3/classdetection__utils_1_1core_1_1box__list_1_1_box_list.html">detection_utils.core.box_list.BoxList</a></div><div class="ttdef"><b>Definition</b> <a href="../../d5/dc2/box__list_8py_source.html#l00042">box_list.py:42</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss_html"><div class="ttname"><a href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html">detection_utils.core.losses.BootstrappedSigmoidClassificationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00406">losses.py:406</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss_html_a0176f38c8a3245ef2dcc783c780f02a8"><div class="ttname"><a href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a0176f38c8a3245ef2dcc783c780f02a8">detection_utils.core.losses.BootstrappedSigmoidClassificationLoss._alpha</a></div><div class="ttdeci">_alpha</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00438">losses.py:438</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss_html_a07130d0c2c29c2757f72059da3dbe79f"><div class="ttname"><a href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a07130d0c2c29c2757f72059da3dbe79f">detection_utils.core.losses.BootstrappedSigmoidClassificationLoss.__init__</a></div><div class="ttdeci">__init__(self, alpha, bootstrap_type='soft')</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00423">losses.py:423</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss_html_a20a73b254e0341b61ddb91b7e54e7543"><div class="ttname"><a href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a20a73b254e0341b61ddb91b7e54e7543">detection_utils.core.losses.BootstrappedSigmoidClassificationLoss._bootstrap_type</a></div><div class="ttdeci">_bootstrap_type</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00439">losses.py:439</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss_html_a4587575bad0c453943b4faf57527853c"><div class="ttname"><a href="../../db/d6d/classdetection__utils_1_1core_1_1losses_1_1_bootstrapped_sigmoid_classification_loss.html#a4587575bad0c453943b4faf57527853c">detection_utils.core.losses.BootstrappedSigmoidClassificationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00441">losses.py:441</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html">detection_utils.core.losses.HardExampleMiner</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00469">losses.py:469</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a04a79ab082067e7db546cdbe01f734f8"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a04a79ab082067e7db546cdbe01f734f8">detection_utils.core.losses.HardExampleMiner._num_negatives_list</a></div><div class="ttdeci">_num_negatives_list</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00537">losses.py:537</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a0c4ee1d3c14876d6ac0f3cb444a2c0eb"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a0c4ee1d3c14876d6ac0f3cb444a2c0eb">detection_utils.core.losses.HardExampleMiner._max_negatives_per_positive</a></div><div class="ttdeci">_max_negatives_per_positive</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00532">losses.py:532</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a4714a733ae4075fe0201c4ae524c893b"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a4714a733ae4075fe0201c4ae524c893b">detection_utils.core.losses.HardExampleMiner.__init__</a></div><div class="ttdeci">__init__(self, num_hard_examples=64, iou_threshold=0.7, loss_type='both', cls_loss_weight=0.05, loc_loss_weight=0.06, max_negatives_per_positive=None, min_negatives_per_image=0)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00485">losses.py:492</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a5102f1118d6088014302904479ff3f81"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a5102f1118d6088014302904479ff3f81">detection_utils.core.losses.HardExampleMiner.summarize</a></div><div class="ttdeci">summarize(self)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00623">losses.py:623</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a53dea51ec308ccfdb6517195b24e3a57"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a53dea51ec308ccfdb6517195b24e3a57">detection_utils.core.losses.HardExampleMiner._loc_loss_weight</a></div><div class="ttdeci">_loc_loss_weight</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00531">losses.py:531</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a6e62eb86f10ebdf80850f4490719f292"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a6e62eb86f10ebdf80850f4490719f292">detection_utils.core.losses.HardExampleMiner._loss_type</a></div><div class="ttdeci">_loss_type</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00529">losses.py:529</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a7f13fd5f8f6e0f1fbe3297cad7cebd0f"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a7f13fd5f8f6e0f1fbe3297cad7cebd0f">detection_utils.core.losses.HardExampleMiner.__call__</a></div><div class="ttdeci">__call__(self, location_losses, cls_losses, decoded_boxlist_list, match_list=None)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00539">losses.py:543</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_a9050aefac710d08563f24a578253c5ea"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#a9050aefac710d08563f24a578253c5ea">detection_utils.core.losses.HardExampleMiner._num_hard_examples</a></div><div class="ttdeci">_num_hard_examples</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00527">losses.py:527</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_aada46a2de44d7810ebc15e830599004a"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#aada46a2de44d7810ebc15e830599004a">detection_utils.core.losses.HardExampleMiner._cls_loss_weight</a></div><div class="ttdeci">_cls_loss_weight</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00530">losses.py:530</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_acf91868a8598f087df796a515012f05b"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#acf91868a8598f087df796a515012f05b">detection_utils.core.losses.HardExampleMiner._iou_threshold</a></div><div class="ttdeci">_iou_threshold</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00528">losses.py:528</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_ad1541128616ed73e7e7d669330909b48"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad1541128616ed73e7e7d669330909b48">detection_utils.core.losses.HardExampleMiner._subsample_selection_to_desired_neg_pos_ratio</a></div><div class="ttdeci">_subsample_selection_to_desired_neg_pos_ratio(self, indices, match, max_negatives_per_positive, min_negatives_per_image=0)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00633">losses.py:637</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_ad7dc2027cdc13b61de9ba1daab9779af"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad7dc2027cdc13b61de9ba1daab9779af">detection_utils.core.losses.HardExampleMiner._min_negatives_per_image</a></div><div class="ttdeci">_min_negatives_per_image</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00533">losses.py:533</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_hard_example_miner_html_ad9f01903634e61d36c7ebfefed1edc4e"><div class="ttname"><a href="../../d5/dd7/classdetection__utils_1_1core_1_1losses_1_1_hard_example_miner.html#ad9f01903634e61d36c7ebfefed1edc4e">detection_utils.core.losses.HardExampleMiner._num_positives_list</a></div><div class="ttdeci">_num_positives_list</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00536">losses.py:536</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_loss_html"><div class="ttname"><a href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html">detection_utils.core.losses.Loss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00044">losses.py:44</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_loss_html_a8555bca99fcc03e1fd78e25e3b2e8843"><div class="ttname"><a href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#a8555bca99fcc03e1fd78e25e3b2e8843">detection_utils.core.losses.Loss.__call__</a></div><div class="ttdeci">__call__(self, prediction_tensor, target_tensor, ignore_nan_targets=False, losses_mask=None, scope=None, **params)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00047">losses.py:53</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_loss_html_aadcefe6d066fd31b3b5a2542d3fef144"><div class="ttname"><a href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#aadcefe6d066fd31b3b5a2542d3fef144">detection_utils.core.losses.Loss._get_loss_multiplier_for_tensor</a></div><div class="ttdeci">_get_loss_multiplier_for_tensor(self, tensor, losses_mask)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00097">losses.py:97</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_loss_html_ae772289a8be37a802e11150c81e7ece7"><div class="ttname"><a href="../../d4/d09/classdetection__utils_1_1core_1_1losses_1_1_loss.html#ae772289a8be37a802e11150c81e7ece7">detection_utils.core.losses.Loss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, **params)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00102">losses.py:102</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss_html"><div class="ttname"><a href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html">detection_utils.core.losses.SigmoidFocalClassificationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00251">losses.py:251</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss_html_a8fabfd8883d2be73deb91513ac7ab456"><div class="ttname"><a href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#a8fabfd8883d2be73deb91513ac7ab456">detection_utils.core.losses.SigmoidFocalClassificationLoss._gamma</a></div><div class="ttdeci">_gamma</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00267">losses.py:267</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss_html_abd4817631560e14e14c853c01c069732"><div class="ttname"><a href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#abd4817631560e14e14c853c01c069732">detection_utils.core.losses.SigmoidFocalClassificationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights, class_indices=None)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00269">losses.py:273</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss_html_acc5e74c93eb3c34dd4370bc1c6a7b23f"><div class="ttname"><a href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#acc5e74c93eb3c34dd4370bc1c6a7b23f">detection_utils.core.losses.SigmoidFocalClassificationLoss.__init__</a></div><div class="ttdeci">__init__(self, gamma=2.0, alpha=0.25)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00258">losses.py:258</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss_html_ae7a2f9c1c0913c37e806e7ad3487d0a4"><div class="ttname"><a href="../../de/d81/classdetection__utils_1_1core_1_1losses_1_1_sigmoid_focal_classification_loss.html#ae7a2f9c1c0913c37e806e7ad3487d0a4">detection_utils.core.losses.SigmoidFocalClassificationLoss._alpha</a></div><div class="ttdeci">_alpha</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00266">losses.py:266</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss_html"><div class="ttname"><a href="../../dc/d60/classdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss.html">detection_utils.core.losses.WeightedIOULocalizationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00187">losses.py:187</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss_html_ab954132a3ba751ba0d64828ebb3c18d3"><div class="ttname"><a href="../../dc/d60/classdetection__utils_1_1core_1_1losses_1_1_weighted_i_o_u_localization_loss.html#ab954132a3ba751ba0d64828ebb3c18d3">detection_utils.core.losses.WeightedIOULocalizationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00195">losses.py:195</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss_html"><div class="ttname"><a href="../../dc/dbe/classdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss.html">detection_utils.core.losses.WeightedL2LocalizationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00118">losses.py:118</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss_html_aaee905ead7ab9ffd710cdcfee0ffed81"><div class="ttname"><a href="../../dc/dbe/classdetection__utils_1_1core_1_1losses_1_1_weighted_l2_localization_loss.html#aaee905ead7ab9ffd710cdcfee0ffed81">detection_utils.core.losses.WeightedL2LocalizationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00124">losses.py:124</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss_html"><div class="ttname"><a href="../../d2/de5/classdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss.html">detection_utils.core.losses.WeightedSigmoidClassificationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00216">losses.py:216</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss_html_ac42b20743e94260a6d6d838f654f2ddb"><div class="ttname"><a href="../../d2/de5/classdetection__utils_1_1core_1_1losses_1_1_weighted_sigmoid_classification_loss.html#ac42b20743e94260a6d6d838f654f2ddb">detection_utils.core.losses.WeightedSigmoidClassificationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights, class_indices=None)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00219">losses.py:223</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss_html"><div class="ttname"><a href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html">detection_utils.core.losses.WeightedSmoothL1LocalizationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00144">losses.py:144</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss_html_a5d030db122ef9b27011d28659e4538d0"><div class="ttname"><a href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#a5d030db122ef9b27011d28659e4538d0">detection_utils.core.losses.WeightedSmoothL1LocalizationLoss._delta</a></div><div class="ttdeci">_delta</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00161">losses.py:161</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss_html_abc0b28eb08b090611695730272fac82d"><div class="ttname"><a href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#abc0b28eb08b090611695730272fac82d">detection_utils.core.losses.WeightedSmoothL1LocalizationLoss.__init__</a></div><div class="ttdeci">__init__(self, delta=1.0)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00154">losses.py:154</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss_html_ac0d45f835b9f05f34490955109ec1432"><div class="ttname"><a href="../../df/d23/classdetection__utils_1_1core_1_1losses_1_1_weighted_smooth_l1_localization_loss.html#ac0d45f835b9f05f34490955109ec1432">detection_utils.core.losses.WeightedSmoothL1LocalizationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00163">losses.py:163</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss_html"><div class="ttname"><a href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html">detection_utils.core.losses.WeightedSoftmaxClassificationAgainstLogitsLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00354">losses.py:354</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss_html_a34c03e1dffb28a11c360679afedec8e4"><div class="ttname"><a href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a34c03e1dffb28a11c360679afedec8e4">detection_utils.core.losses.WeightedSoftmaxClassificationAgainstLogitsLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00378">losses.py:378</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss_html_a7fb6902c62d6a331ae8dd5521b6a1089"><div class="ttname"><a href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a7fb6902c62d6a331ae8dd5521b6a1089">detection_utils.core.losses.WeightedSoftmaxClassificationAgainstLogitsLoss._scale_and_softmax_logits</a></div><div class="ttdeci">_scale_and_softmax_logits(self, logits)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00373">losses.py:373</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss_html_a8b44b227d04e7dd1b8e6079342a535fa"><div class="ttname"><a href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a8b44b227d04e7dd1b8e6079342a535fa">detection_utils.core.losses.WeightedSoftmaxClassificationAgainstLogitsLoss.__init__</a></div><div class="ttdeci">__init__(self, logit_scale=1.0)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00361">losses.py:361</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss_html_a90b59234980cf95e5139fc5e2f00843e"><div class="ttname"><a href="../../d5/d4c/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_against_logits_loss.html#a90b59234980cf95e5139fc5e2f00843e">detection_utils.core.losses.WeightedSoftmaxClassificationAgainstLogitsLoss._logit_scale</a></div><div class="ttdeci">_logit_scale</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00371">losses.py:371</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss_html"><div class="ttname"><a href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html">detection_utils.core.losses.WeightedSoftmaxClassificationLoss</a></div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00313">losses.py:313</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss_html_a15a0162c97856f7ba8a5c1121017d853"><div class="ttname"><a href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a15a0162c97856f7ba8a5c1121017d853">detection_utils.core.losses.WeightedSoftmaxClassificationLoss._compute_loss</a></div><div class="ttdeci">_compute_loss(self, prediction_tensor, target_tensor, weights)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00328">losses.py:328</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss_html_a24408057d3ced7f7f55949e8da83a047"><div class="ttname"><a href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a24408057d3ced7f7f55949e8da83a047">detection_utils.core.losses.WeightedSoftmaxClassificationLoss.__init__</a></div><div class="ttdeci">__init__(self, logit_scale=1.0)</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00316">losses.py:316</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss_html_a404314a3aab27fc9dcb2dbc25851b56c"><div class="ttname"><a href="../../d4/d1b/classdetection__utils_1_1core_1_1losses_1_1_weighted_softmax_classification_loss.html#a404314a3aab27fc9dcb2dbc25851b56c">detection_utils.core.losses.WeightedSoftmaxClassificationLoss._logit_scale</a></div><div class="ttdeci">_logit_scale</div><div class="ttdef"><b>Definition</b> <a href="../../dc/db7/losses_8py_source.html#l00326">losses.py:326</a></div></div>
<div class="ttc" id="aclassdetection__utils_1_1core_1_1matcher_1_1_match_html"><div class="ttname"><a href="../../db/d24/classdetection__utils_1_1core_1_1matcher_1_1_match.html">detection_utils.core.matcher.Match</a></div><div class="ttdef"><b>Definition</b> <a href="../../d0/d86/matcher_8py_source.html#l00045">matcher.py:45</a></div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
