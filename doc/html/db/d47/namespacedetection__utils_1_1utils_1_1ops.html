<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RESIIST: detection_utils.utils.ops Namespace Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">RESIIST
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d8/d97/namespacedetection__utils.html">detection_utils</a></li><li class="navelem"><a class="el" href="../../d5/d2b/namespacedetection__utils_1_1utils.html">utils</a></li><li class="navelem"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html">ops</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">detection_utils.utils.ops Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a361f89dc99c799c108b569851f420be2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a361f89dc99c799c108b569851f420be2">expanded_shape</a> (orig_shape, start_dim, num_dims)</td></tr>
<tr class="separator:a361f89dc99c799c108b569851f420be2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc866ef74c28004b32df8315d34c8805"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#adc866ef74c28004b32df8315d34c8805">normalized_to_image_coordinates</a> (normalized_boxes, image_shape, parallel_iterations=32)</td></tr>
<tr class="separator:adc866ef74c28004b32df8315d34c8805"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af311e77e054cb389029fd2e4a40c2955"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af311e77e054cb389029fd2e4a40c2955">meshgrid</a> (x, y)</td></tr>
<tr class="separator:af311e77e054cb389029fd2e4a40c2955"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a516b301f1397988c4021aec757b16d2d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a516b301f1397988c4021aec757b16d2d">fixed_padding</a> (inputs, kernel_size, rate=1)</td></tr>
<tr class="separator:a516b301f1397988c4021aec757b16d2d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afcdac23eebee9bb6a17790afbdf223d9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#afcdac23eebee9bb6a17790afbdf223d9">pad_to_multiple</a> (tensor, multiple)</td></tr>
<tr class="separator:afcdac23eebee9bb6a17790afbdf223d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe923c1879971de61ca2630119d56287"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#afe923c1879971de61ca2630119d56287">padded_one_hot_encoding</a> (indices, depth, left_pad)</td></tr>
<tr class="separator:afe923c1879971de61ca2630119d56287"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:addc98bd6fb2ea843a7e291c1f4f761d2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#addc98bd6fb2ea843a7e291c1f4f761d2">dense_to_sparse_boxes</a> (dense_locations, dense_num_boxes, num_classes)</td></tr>
<tr class="separator:addc98bd6fb2ea843a7e291c1f4f761d2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9fad235f916265ec93571df2b5269b46"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a9fad235f916265ec93571df2b5269b46">indices_to_dense_vector</a> (indices, size, indices_value=1., default_value=0, dtype=tf.float32)</td></tr>
<tr class="separator:a9fad235f916265ec93571df2b5269b46"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8c5e626e71f1d4e2bf1a4693b1035984"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a8c5e626e71f1d4e2bf1a4693b1035984">reduce_sum_trailing_dimensions</a> (tensor, ndims)</td></tr>
<tr class="separator:a8c5e626e71f1d4e2bf1a4693b1035984"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af4c44e343c3cb222937eb3e496ce68e6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af4c44e343c3cb222937eb3e496ce68e6">retain_groundtruth</a> (tensor_dict, valid_indices)</td></tr>
<tr class="separator:af4c44e343c3cb222937eb3e496ce68e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae6ecd4d38671df8c284d9a856f1d603f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#ae6ecd4d38671df8c284d9a856f1d603f">retain_groundtruth_with_positive_classes</a> (tensor_dict)</td></tr>
<tr class="separator:ae6ecd4d38671df8c284d9a856f1d603f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9ea79fd4a604caa7430abce7d10bcef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#ae9ea79fd4a604caa7430abce7d10bcef">replace_nan_groundtruth_label_scores_with_ones</a> (label_scores)</td></tr>
<tr class="separator:ae9ea79fd4a604caa7430abce7d10bcef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a14259559c91fbe3753ef93fd614eebd8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a14259559c91fbe3753ef93fd614eebd8">filter_groundtruth_with_crowd_boxes</a> (tensor_dict)</td></tr>
<tr class="separator:a14259559c91fbe3753ef93fd614eebd8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9caa9fbd25912b008f9dfbe9ca636567"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a9caa9fbd25912b008f9dfbe9ca636567">filter_groundtruth_with_nan_box_coordinates</a> (tensor_dict)</td></tr>
<tr class="separator:a9caa9fbd25912b008f9dfbe9ca636567"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a391c9d74117ad32ba170f1df7be9efc9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a391c9d74117ad32ba170f1df7be9efc9">filter_unrecognized_classes</a> (tensor_dict)</td></tr>
<tr class="separator:a391c9d74117ad32ba170f1df7be9efc9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a427d2293178f37f8f3030837d3813b65"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a427d2293178f37f8f3030837d3813b65">normalize_to_target</a> (inputs, target_norm_value, dim, epsilon=1e-7, trainable=True, scope='NormalizeToTarget', summarize=True)</td></tr>
<tr class="separator:a427d2293178f37f8f3030837d3813b65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8dc56974f34bbceff44a4dc9f4dace05"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a8dc56974f34bbceff44a4dc9f4dace05">batch_position_sensitive_crop_regions</a> (images, boxes, crop_size, num_spatial_bins, global_pool, parallel_iterations=64)</td></tr>
<tr class="separator:a8dc56974f34bbceff44a4dc9f4dace05"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a674b91c79c0575b09d5b79114912a8fa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a674b91c79c0575b09d5b79114912a8fa">position_sensitive_crop_regions</a> (image, boxes, crop_size, num_spatial_bins, global_pool)</td></tr>
<tr class="separator:a674b91c79c0575b09d5b79114912a8fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae862e7f24dbb83f231c678895bfdf766"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#ae862e7f24dbb83f231c678895bfdf766">reframe_box_masks_to_image_masks</a> (box_masks, boxes, image_height, image_width)</td></tr>
<tr class="separator:ae862e7f24dbb83f231c678895bfdf766"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa05d5979ad4881e4f972be53d5b4200d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#aa05d5979ad4881e4f972be53d5b4200d">merge_boxes_with_multiple_labels</a> (boxes, classes, confidences, num_classes, quantization_bins=10000)</td></tr>
<tr class="separator:aa05d5979ad4881e4f972be53d5b4200d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc950a7496c9cea7a96d5fe6acd77d82"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#adc950a7496c9cea7a96d5fe6acd77d82">nearest_neighbor_upsampling</a> (input_tensor, scale=None, height_scale=None, width_scale=None)</td></tr>
<tr class="separator:adc950a7496c9cea7a96d5fe6acd77d82"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6323da655ab0d0f545c213c5b0382b7f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a6323da655ab0d0f545c213c5b0382b7f">matmul_gather_on_zeroth_axis</a> (params, indices, scope=None)</td></tr>
<tr class="separator:a6323da655ab0d0f545c213c5b0382b7f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a140f2d38716d4f6f82081e7a6dfc38c7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a140f2d38716d4f6f82081e7a6dfc38c7">fpn_feature_levels</a> (num_levels, unit_scale_index, image_ratio, boxes)</td></tr>
<tr class="separator:a140f2d38716d4f6f82081e7a6dfc38c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab995660ac802c5af8c902b336a138b2b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#ab995660ac802c5af8c902b336a138b2b">bfloat16_to_float32_nested</a> (tensor_nested)</td></tr>
<tr class="separator:ab995660ac802c5af8c902b336a138b2b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f2f992f354f09d7235817f9787a6454"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a4f2f992f354f09d7235817f9787a6454">gather_with_padding_values</a> (input_tensor, indices, padding_value)</td></tr>
<tr class="separator:a4f2f992f354f09d7235817f9787a6454"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a33f64e9ecb63a23af0c998ebb402c533"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a33f64e9ecb63a23af0c998ebb402c533">matmul_crop_and_resize</a> = spatial_ops.matmul_crop_and_resize</td></tr>
<tr class="separator:a33f64e9ecb63a23af0c998ebb402c533"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af020a014cef7a2230e195b6b6a02e88f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af020a014cef7a2230e195b6b6a02e88f">multilevel_roi_align</a> = spatial_ops.multilevel_roi_align</td></tr>
<tr class="separator:af020a014cef7a2230e195b6b6a02e88f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3c7872f0750bfae89334d4e6073caabf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a3c7872f0750bfae89334d4e6073caabf">native_crop_and_resize</a> = spatial_ops.native_crop_and_resize</td></tr>
<tr class="separator:a3c7872f0750bfae89334d4e6073caabf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a82ed092503588fcc71b43646a1100dac"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a82ed092503588fcc71b43646a1100dac">EqualizationLossConfig</a></td></tr>
<tr class="separator:a82ed092503588fcc71b43646a1100dac"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">A module for helper tensorflow ops.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a8dc56974f34bbceff44a4dc9f4dace05" name="a8dc56974f34bbceff44a4dc9f4dace05"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8dc56974f34bbceff44a4dc9f4dace05">&#9670;&#160;</a></span>batch_position_sensitive_crop_regions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.batch_position_sensitive_crop_regions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>images</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>crop_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_spatial_bins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_pool</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>parallel_iterations</em> = <code>64</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Position sensitive crop with batches of images and boxes.

This op is exactly like `position_sensitive_crop_regions` below but operates
on batches of images and boxes. See `position_sensitive_crop_regions` function
below for the operation applied per batch element.

Args:
  images: A `Tensor`. Must be one of the following types: `uint8`, `int8`,
    `int16`, `int32`, `int64`, `half`, `float32`, `float64`.
    A 4-D tensor of shape `[batch, image_height, image_width, depth]`.
    Both `image_height` and `image_width` need to be positive.
  boxes: A `Tensor` of type `float32`.
    A 3-D tensor of shape `[batch, num_boxes, 4]`. Each box is specified in
    normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value
    of `y` is mapped to the image coordinate at `y * (image_height - 1)`, so
    as the `[0, 1]` interval of normalized image height is mapped to
    `[0, image_height - 1] in image height coordinates. We do allow y1 &gt; y2,
    in which case the sampled crop is an up-down flipped version of the
    original image. The width dimension is treated similarly.
  crop_size: See `position_sensitive_crop_regions` below.
  num_spatial_bins: See `position_sensitive_crop_regions` below.
  global_pool: See `position_sensitive_crop_regions` below.
  parallel_iterations: Number of batch items to process in parallel.

Returns:
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00604">604</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  609</span>                                          parallel_iterations=64):</div>
<div class="line"><span class="lineno">  610</span>  <span class="stringliteral">&quot;&quot;&quot;Position sensitive crop with batches of images and boxes.</span></div>
<div class="line"><span class="lineno">  611</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  612</span><span class="stringliteral">  This op </span><span class="keywordflow">is</span> exactly like `position_sensitive_crop_regions` below but operates</div>
<div class="line"><span class="lineno">  613</span>  on batches of images <span class="keywordflow">and</span> boxes. See `position_sensitive_crop_regions` function</div>
<div class="line"><span class="lineno">  614</span>  below <span class="keywordflow">for</span> the operation applied per batch element.</div>
<div class="line"><span class="lineno">  615</span> </div>
<div class="line"><span class="lineno">  616</span>  Args:</div>
<div class="line"><span class="lineno">  617</span>    images: A `Tensor`. Must be one of the following types: `uint8`, `int8`,</div>
<div class="line"><span class="lineno">  618</span>      `int16`, `int32`, `int64`, `half`, `float32`, `float64`.</div>
<div class="line"><span class="lineno">  619</span>      A 4-D tensor of shape `[batch, image_height, image_width, depth]`.</div>
<div class="line"><span class="lineno">  620</span>      Both `image_height` <span class="keywordflow">and</span> `image_width` need to be positive.</div>
<div class="line"><span class="lineno">  621</span>    boxes: A `Tensor` of type `float32`.</div>
<div class="line"><span class="lineno">  622</span>      A 3-D tensor of shape `[batch, num_boxes, 4]`. Each box <span class="keywordflow">is</span> specified <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  623</span>      normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value</div>
<div class="line"><span class="lineno">  624</span>      of `y` <span class="keywordflow">is</span> mapped to the image coordinate at `y * (image_height - 1)`, so</div>
<div class="line"><span class="lineno">  625</span>      <span class="keyword">as</span> the `[0, 1]` interval of normalized image height <span class="keywordflow">is</span> mapped to</div>
<div class="line"><span class="lineno">  626</span>      `[0, image_height - 1] <span class="keywordflow">in</span> image height coordinates. We do allow y1 &gt; y2,</div>
<div class="line"><span class="lineno">  627</span>      <span class="keywordflow">in</span> which case the sampled crop <span class="keywordflow">is</span> an up-down flipped version of the</div>
<div class="line"><span class="lineno">  628</span>      original image. The width dimension <span class="keywordflow">is</span> treated similarly.</div>
<div class="line"><span class="lineno">  629</span>    crop_size: See `position_sensitive_crop_regions` below.</div>
<div class="line"><span class="lineno">  630</span>    num_spatial_bins: See `position_sensitive_crop_regions` below.</div>
<div class="line"><span class="lineno">  631</span>    global_pool: See `position_sensitive_crop_regions` below.</div>
<div class="line"><span class="lineno">  632</span>    parallel_iterations: Number of batch items to process <span class="keywordflow">in</span> parallel.</div>
<div class="line"><span class="lineno">  633</span> </div>
<div class="line"><span class="lineno">  634</span>  Returns:</div>
<div class="line"><span class="lineno">  635</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  636</span><span class="stringliteral">  </span><span class="keyword">def </span>_position_sensitive_crop_fn(inputs):</div>
<div class="line"><span class="lineno">  637</span>    images, boxes = inputs</div>
<div class="line"><span class="lineno">  638</span>    <span class="keywordflow">return</span> position_sensitive_crop_regions(</div>
<div class="line"><span class="lineno">  639</span>        images,</div>
<div class="line"><span class="lineno">  640</span>        boxes,</div>
<div class="line"><span class="lineno">  641</span>        crop_size=crop_size,</div>
<div class="line"><span class="lineno">  642</span>        num_spatial_bins=num_spatial_bins,</div>
<div class="line"><span class="lineno">  643</span>        global_pool=global_pool)</div>
<div class="line"><span class="lineno">  644</span> </div>
<div class="line"><span class="lineno">  645</span>  <span class="keywordflow">return</span> shape_utils.static_or_dynamic_map_fn(</div>
<div class="line"><span class="lineno">  646</span>      _position_sensitive_crop_fn,</div>
<div class="line"><span class="lineno">  647</span>      elems=[images, boxes],</div>
<div class="line"><span class="lineno">  648</span>      dtype=tf.float32,</div>
<div class="line"><span class="lineno">  649</span>      parallel_iterations=parallel_iterations)</div>
<div class="line"><span class="lineno">  650</span> </div>
<div class="line"><span class="lineno">  651</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_a8dc56974f34bbceff44a4dc9f4dace05_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_a8dc56974f34bbceff44a4dc9f4dace05_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a8dc56974f34bbceff44a4dc9f4dace05_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a8dc56974f34bbceff44a4dc9f4dace05_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,217,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a674b91c79c0575b09d5b79114912a8fa" title=" " alt="" coords="265,5,473,45"/>
<area shape="poly" title=" " alt="" coords="218,23,251,23,251,28,218,28"/>
</map>
</div>

</div>
</div>
<a id="ab995660ac802c5af8c902b336a138b2b" name="ab995660ac802c5af8c902b336a138b2b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab995660ac802c5af8c902b336a138b2b">&#9670;&#160;</a></span>bfloat16_to_float32_nested()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.bfloat16_to_float32_nested </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_nested</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert float32 tensors in a nested structure to bfloat16.

Args:
  tensor_nested: A Python dict, values being Tensor or Python list/tuple of
    Tensor.

Returns:
  A Python dict with the same structure as `tensor_dict`,
  with all bfloat16 tensors converted to float32.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l01038">1038</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1038</span><span class="keyword">def </span>bfloat16_to_float32_nested(tensor_nested):</div>
<div class="line"><span class="lineno"> 1039</span>  <span class="stringliteral">&quot;&quot;&quot;Convert float32 tensors in a nested structure to bfloat16.</span></div>
<div class="line"><span class="lineno"> 1040</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1041</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno"> 1042</span><span class="stringliteral">    tensor_nested: A Python dict, values being Tensor </span><span class="keywordflow">or</span> Python list/tuple of</div>
<div class="line"><span class="lineno"> 1043</span>      Tensor.</div>
<div class="line"><span class="lineno"> 1044</span> </div>
<div class="line"><span class="lineno"> 1045</span>  Returns:</div>
<div class="line"><span class="lineno"> 1046</span>    A Python dict <span class="keyword">with</span> the same structure <span class="keyword">as</span> `tensor_dict`,</div>
<div class="line"><span class="lineno"> 1047</span>    <span class="keyword">with</span> all bfloat16 tensors converted to float32.</div>
<div class="line"><span class="lineno"> 1048</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1049</span><span class="stringliteral">  </span><span class="keywordflow">if</span> isinstance(tensor_nested, tf.Tensor):</div>
<div class="line"><span class="lineno"> 1050</span>    <span class="keywordflow">if</span> tensor_nested.dtype == tf.bfloat16:</div>
<div class="line"><span class="lineno"> 1051</span>      <span class="keywordflow">return</span> tf.cast(tensor_nested, dtype=tf.float32)</div>
<div class="line"><span class="lineno"> 1052</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno"> 1053</span>      <span class="keywordflow">return</span> tensor_nested</div>
<div class="line"><span class="lineno"> 1054</span>  <span class="keywordflow">elif</span> isinstance(tensor_nested, (list, tuple)):</div>
<div class="line"><span class="lineno"> 1055</span>    out_tensor_dict = [bfloat16_to_float32_nested(t) <span class="keywordflow">for</span> t <span class="keywordflow">in</span> tensor_nested]</div>
<div class="line"><span class="lineno"> 1056</span>  <span class="keywordflow">elif</span> isinstance(tensor_nested, dict):</div>
<div class="line"><span class="lineno"> 1057</span>    out_tensor_dict = {</div>
<div class="line"><span class="lineno"> 1058</span>        k: bfloat16_to_float32_nested(v) <span class="keywordflow">for</span> k, v <span class="keywordflow">in</span> tensor_nested.items()</div>
<div class="line"><span class="lineno"> 1059</span>    }</div>
<div class="line"><span class="lineno"> 1060</span>  <span class="keywordflow">return</span> out_tensor_dict</div>
<div class="line"><span class="lineno"> 1061</span> </div>
<div class="line"><span class="lineno"> 1062</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_cgraph">
<area shape="rect" title=" " alt="" coords="5,29,213,69"/>
<area shape="poly" title=" " alt="" coords="70,30,68,20,74,10,88,5,109,3,134,6,147,13,144,18,132,11,109,8,89,10,77,15,73,21,75,28"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_icgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_icgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_icgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_ab995660ac802c5af8c902b336a138b2b_icgraph">
<area shape="rect" title=" " alt="" coords="5,29,213,69"/>
<area shape="poly" title=" " alt="" coords="144,18,132,11,109,8,89,10,77,15,73,21,75,28,70,30,68,20,74,10,88,5,109,3,134,6,147,13"/>
</map>
</div>

</div>
</div>
<a id="addc98bd6fb2ea843a7e291c1f4f761d2" name="addc98bd6fb2ea843a7e291c1f4f761d2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#addc98bd6fb2ea843a7e291c1f4f761d2">&#9670;&#160;</a></span>dense_to_sparse_boxes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.dense_to_sparse_boxes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dense_locations</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dense_num_boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_classes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Converts bounding boxes from dense to sparse form.

Args:
  dense_locations:  a [max_num_boxes, 4] tensor in which only the first k rows
    are valid bounding box location coordinates, where k is the sum of
    elements in dense_num_boxes.
  dense_num_boxes: a [max_num_classes] tensor indicating the counts of
     various bounding box classes e.g. [1, 0, 0, 2] means that the first
     bounding box is of class 0 and the second and third bounding boxes are
     of class 3. The sum of elements in this tensor is the number of valid
     bounding boxes.
  num_classes: number of classes

Returns:
  box_locations: a [num_boxes, 4] tensor containing only valid bounding
     boxes (i.e. the first num_boxes rows of dense_locations)
  box_classes: a [num_boxes] tensor containing the classes of each bounding
     box (e.g. dense_num_boxes = [1, 0, 0, 2] =&gt; box_classes = [0, 3, 3]
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00275">275</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  275</span><span class="keyword">def </span>dense_to_sparse_boxes(dense_locations, dense_num_boxes, num_classes):</div>
<div class="line"><span class="lineno">  276</span>  <span class="stringliteral">&quot;&quot;&quot;Converts bounding boxes from dense to sparse form.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">    dense_locations:  a [max_num_boxes, 4] tensor </span><span class="keywordflow">in</span> which only the first k rows</div>
<div class="line"><span class="lineno">  280</span>      are valid bounding box location coordinates, where k <span class="keywordflow">is</span> the sum of</div>
<div class="line"><span class="lineno">  281</span>      elements <span class="keywordflow">in</span> dense_num_boxes.</div>
<div class="line"><span class="lineno">  282</span>    dense_num_boxes: a [max_num_classes] tensor indicating the counts of</div>
<div class="line"><span class="lineno">  283</span>       various bounding box classes e.g. [1, 0, 0, 2] means that the first</div>
<div class="line"><span class="lineno">  284</span>       bounding box <span class="keywordflow">is</span> of <span class="keyword">class </span>0 <span class="keywordflow">and</span> the second <span class="keywordflow">and</span> third bounding boxes are</div>
<div class="line"><span class="lineno">  285</span>       of <span class="keyword">class </span>3. The sum of elements <span class="keywordflow">in</span> this tensor <span class="keywordflow">is</span> the number of valid</div>
<div class="line"><span class="lineno">  286</span>       bounding boxes.</div>
<div class="line"><span class="lineno">  287</span>    num_classes: number of classes</div>
<div class="line"><span class="lineno">  288</span> </div>
<div class="line"><span class="lineno">  289</span>  Returns:</div>
<div class="line"><span class="lineno">  290</span>    box_locations: a [num_boxes, 4] tensor containing only valid bounding</div>
<div class="line"><span class="lineno">  291</span>       boxes (i.e. the first num_boxes rows of dense_locations)</div>
<div class="line"><span class="lineno">  292</span>    box_classes: a [num_boxes] tensor containing the classes of each bounding</div>
<div class="line"><span class="lineno">  293</span>       box (e.g. dense_num_boxes = [1, 0, 0, 2] =&gt; box_classes = [0, 3, 3]</div>
<div class="line"><span class="lineno">  294</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  295</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  296</span><span class="stringliteral">  num_valid_boxes = tf.reduce_sum(dense_num_boxes)</span></div>
<div class="line"><span class="lineno">  297</span><span class="stringliteral">  box_locations = tf.slice(dense_locations,</span></div>
<div class="line"><span class="lineno">  298</span><span class="stringliteral">                           tf.constant([0, 0]), tf.stack([num_valid_boxes, 4]))</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral">  tiled_classes = [tf.tile([i], tf.expand_dims(dense_num_boxes[i], 0))</span></div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">                   </span><span class="keywordflow">for</span> i <span class="keywordflow">in</span> range(num_classes)]</div>
<div class="line"><span class="lineno">  301</span>  box_classes = tf.concat(tiled_classes, 0)</div>
<div class="line"><span class="lineno">  302</span>  box_locations.set_shape([<span class="keywordtype">None</span>, 4])</div>
<div class="line"><span class="lineno">  303</span>  <span class="keywordflow">return</span> box_locations, box_classes</div>
<div class="line"><span class="lineno">  304</span> </div>
<div class="line"><span class="lineno">  305</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a361f89dc99c799c108b569851f420be2" name="a361f89dc99c799c108b569851f420be2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a361f89dc99c799c108b569851f420be2">&#9670;&#160;</a></span>expanded_shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.expanded_shape </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>orig_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>start_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_dims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Inserts multiple ones into a shape vector.

Inserts an all-1 vector of length num_dims at position start_dim into a shape.
Can be combined with tf.reshape to generalize tf.expand_dims.

Args:
  orig_shape: the shape into which the all-1 vector is added (int32 vector)
  start_dim: insertion position (int scalar)
  num_dims: length of the inserted all-1 vector (int scalar)
Returns:
  An int32 vector of length tf.size(orig_shape) + num_dims.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00040">40</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   40</span><span class="keyword">def </span>expanded_shape(orig_shape, start_dim, num_dims):</div>
<div class="line"><span class="lineno">   41</span>  <span class="stringliteral">&quot;&quot;&quot;Inserts multiple ones into a shape vector.</span></div>
<div class="line"><span class="lineno">   42</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   43</span><span class="stringliteral">  Inserts an all-1 vector of length num_dims at position start_dim into a shape.</span></div>
<div class="line"><span class="lineno">   44</span><span class="stringliteral">  Can be combined </span><span class="keyword">with</span> tf.reshape to generalize tf.expand_dims.</div>
<div class="line"><span class="lineno">   45</span> </div>
<div class="line"><span class="lineno">   46</span>  Args:</div>
<div class="line"><span class="lineno">   47</span>    orig_shape: the shape into which the all-1 vector <span class="keywordflow">is</span> added (int32 vector)</div>
<div class="line"><span class="lineno">   48</span>    start_dim: insertion position (int scalar)</div>
<div class="line"><span class="lineno">   49</span>    num_dims: length of the inserted all-1 vector (int scalar)</div>
<div class="line"><span class="lineno">   50</span>  Returns:</div>
<div class="line"><span class="lineno">   51</span>    An int32 vector of length tf.size(orig_shape) + num_dims.</div>
<div class="line"><span class="lineno">   52</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">  </span><span class="keyword">with</span> tf.name_scope(<span class="stringliteral">&#39;ExpandedShape&#39;</span>):</div>
<div class="line"><span class="lineno">   54</span>    start_dim = tf.expand_dims(start_dim, 0)  <span class="comment"># scalar to rank-1</span></div>
<div class="line"><span class="lineno">   55</span>    before = tf.slice(orig_shape, [0], start_dim)</div>
<div class="line"><span class="lineno">   56</span>    add_shape = tf.ones(tf.reshape(num_dims, [1]), dtype=tf.int32)</div>
<div class="line"><span class="lineno">   57</span>    after = tf.slice(orig_shape, start_dim, [-1])</div>
<div class="line"><span class="lineno">   58</span>    new_shape = tf.concat([before, add_shape, after], 0)</div>
<div class="line"><span class="lineno">   59</span>    <span class="keywordflow">return</span> new_shape</div>
<div class="line"><span class="lineno">   60</span> </div>
<div class="line"><span class="lineno">   61</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_a361f89dc99c799c108b569851f420be2_icgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_a361f89dc99c799c108b569851f420be2_icgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a361f89dc99c799c108b569851f420be2_icgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a361f89dc99c799c108b569851f420be2_icgraph">
<area shape="rect" title=" " alt="" coords="269,5,488,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af311e77e054cb389029fd2e4a40c2955" title=" " alt="" coords="5,13,221,38"/>
<area shape="poly" title=" " alt="" coords="255,28,222,28,222,23,255,23"/>
</map>
</div>

</div>
</div>
<a id="a14259559c91fbe3753ef93fd614eebd8" name="a14259559c91fbe3753ef93fd614eebd8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a14259559c91fbe3753ef93fd614eebd8">&#9670;&#160;</a></span>filter_groundtruth_with_crowd_boxes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.filter_groundtruth_with_crowd_boxes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_dict</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Filters out groundtruth with boxes corresponding to crowd.

Args:
  tensor_dict: a dictionary of following groundtruth tensors -
    fields.InputDataFields.groundtruth_boxes
    fields.InputDataFields.groundtruth_classes
    fields.InputDataFields.groundtruth_confidences
    fields.InputDataFields.groundtruth_keypoints
    fields.InputDataFields.groundtruth_instance_masks
    fields.InputDataFields.groundtruth_is_crowd
    fields.InputDataFields.groundtruth_area
    fields.InputDataFields.groundtruth_label_types

Returns:
  a dictionary of tensors containing only the groundtruth that have bounding
  boxes.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00445">445</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  445</span><span class="keyword">def </span>filter_groundtruth_with_crowd_boxes(tensor_dict):</div>
<div class="line"><span class="lineno">  446</span>  <span class="stringliteral">&quot;&quot;&quot;Filters out groundtruth with boxes corresponding to crowd.</span></div>
<div class="line"><span class="lineno">  447</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  448</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  449</span><span class="stringliteral">    tensor_dict: a dictionary of following groundtruth tensors -</span></div>
<div class="line"><span class="lineno">  450</span><span class="stringliteral">      fields.InputDataFields.groundtruth_boxes</span></div>
<div class="line"><span class="lineno">  451</span><span class="stringliteral">      fields.InputDataFields.groundtruth_classes</span></div>
<div class="line"><span class="lineno">  452</span><span class="stringliteral">      fields.InputDataFields.groundtruth_confidences</span></div>
<div class="line"><span class="lineno">  453</span><span class="stringliteral">      fields.InputDataFields.groundtruth_keypoints</span></div>
<div class="line"><span class="lineno">  454</span><span class="stringliteral">      fields.InputDataFields.groundtruth_instance_masks</span></div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">      fields.InputDataFields.groundtruth_is_crowd</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">      fields.InputDataFields.groundtruth_area</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral">      fields.InputDataFields.groundtruth_label_types</span></div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  459</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">  460</span><span class="stringliteral">    a dictionary of tensors containing only the groundtruth that have bounding</span></div>
<div class="line"><span class="lineno">  461</span><span class="stringliteral">    boxes.</span></div>
<div class="line"><span class="lineno">  462</span><span class="stringliteral">  &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  463</span><span class="stringliteral">  </span><span class="keywordflow">if</span> fields.InputDataFields.groundtruth_is_crowd <span class="keywordflow">in</span> tensor_dict:</div>
<div class="line"><span class="lineno">  464</span>    is_crowd = tensor_dict[fields.InputDataFields.groundtruth_is_crowd]</div>
<div class="line"><span class="lineno">  465</span>    is_not_crowd = tf.logical_not(is_crowd)</div>
<div class="line"><span class="lineno">  466</span>    is_not_crowd_indices = tf.where(is_not_crowd)</div>
<div class="line"><span class="lineno">  467</span>    tensor_dict = retain_groundtruth(tensor_dict, is_not_crowd_indices)</div>
<div class="line"><span class="lineno">  468</span>  <span class="keywordflow">return</span> tensor_dict</div>
<div class="line"><span class="lineno">  469</span> </div>
<div class="line"><span class="lineno">  470</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_a14259559c91fbe3753ef93fd614eebd8_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_a14259559c91fbe3753ef93fd614eebd8_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a14259559c91fbe3753ef93fd614eebd8_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a14259559c91fbe3753ef93fd614eebd8_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,212,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af4c44e343c3cb222937eb3e496ce68e6" title=" " alt="" coords="260,5,455,45"/>
<area shape="poly" title=" " alt="" coords="212,23,246,23,246,28,212,28"/>
</map>
</div>

</div>
</div>
<a id="a9caa9fbd25912b008f9dfbe9ca636567" name="a9caa9fbd25912b008f9dfbe9ca636567"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9caa9fbd25912b008f9dfbe9ca636567">&#9670;&#160;</a></span>filter_groundtruth_with_nan_box_coordinates()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.filter_groundtruth_with_nan_box_coordinates </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_dict</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Filters out groundtruth with no bounding boxes.

Args:
  tensor_dict: a dictionary of following groundtruth tensors -
    fields.InputDataFields.groundtruth_boxes
    fields.InputDataFields.groundtruth_classes
    fields.InputDataFields.groundtruth_confidences
    fields.InputDataFields.groundtruth_keypoints
    fields.InputDataFields.groundtruth_instance_masks
    fields.InputDataFields.groundtruth_is_crowd
    fields.InputDataFields.groundtruth_area
    fields.InputDataFields.groundtruth_label_types

Returns:
  a dictionary of tensors containing only the groundtruth that have bounding
  boxes.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00471">471</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  471</span><span class="keyword">def </span>filter_groundtruth_with_nan_box_coordinates(tensor_dict):</div>
<div class="line"><span class="lineno">  472</span>  <span class="stringliteral">&quot;&quot;&quot;Filters out groundtruth with no bounding boxes.</span></div>
<div class="line"><span class="lineno">  473</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  474</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  475</span><span class="stringliteral">    tensor_dict: a dictionary of following groundtruth tensors -</span></div>
<div class="line"><span class="lineno">  476</span><span class="stringliteral">      fields.InputDataFields.groundtruth_boxes</span></div>
<div class="line"><span class="lineno">  477</span><span class="stringliteral">      fields.InputDataFields.groundtruth_classes</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral">      fields.InputDataFields.groundtruth_confidences</span></div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">      fields.InputDataFields.groundtruth_keypoints</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">      fields.InputDataFields.groundtruth_instance_masks</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">      fields.InputDataFields.groundtruth_is_crowd</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">      fields.InputDataFields.groundtruth_area</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">      fields.InputDataFields.groundtruth_label_types</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">    a dictionary of tensors containing only the groundtruth that have bounding</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">    boxes.</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral">  &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  489</span><span class="stringliteral">  groundtruth_boxes = tensor_dict[fields.InputDataFields.groundtruth_boxes]</span></div>
<div class="line"><span class="lineno">  490</span><span class="stringliteral">  nan_indicator_vector = tf.greater(tf.reduce_sum(tf.cast(</span></div>
<div class="line"><span class="lineno">  491</span><span class="stringliteral">      tf.is_nan(groundtruth_boxes), dtype=tf.int32), reduction_indices=[1]), 0)</span></div>
<div class="line"><span class="lineno">  492</span><span class="stringliteral">  valid_indicator_vector = tf.logical_not(nan_indicator_vector)</span></div>
<div class="line"><span class="lineno">  493</span><span class="stringliteral">  valid_indices = tf.where(valid_indicator_vector)</span></div>
<div class="line"><span class="lineno">  494</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  495</span><span class="stringliteral">  </span><span class="keywordflow">return</span> retain_groundtruth(tensor_dict, valid_indices)</div>
<div class="line"><span class="lineno">  496</span> </div>
<div class="line"><span class="lineno">  497</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_a9caa9fbd25912b008f9dfbe9ca636567_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_a9caa9fbd25912b008f9dfbe9ca636567_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a9caa9fbd25912b008f9dfbe9ca636567_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a9caa9fbd25912b008f9dfbe9ca636567_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,260,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af4c44e343c3cb222937eb3e496ce68e6" title=" " alt="" coords="308,5,503,45"/>
<area shape="poly" title=" " alt="" coords="260,23,294,23,294,28,260,28"/>
</map>
</div>

</div>
</div>
<a id="a391c9d74117ad32ba170f1df7be9efc9" name="a391c9d74117ad32ba170f1df7be9efc9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a391c9d74117ad32ba170f1df7be9efc9">&#9670;&#160;</a></span>filter_unrecognized_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.filter_unrecognized_classes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_dict</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Filters out class labels that are not unrecognized by the labelmap.

Decoder would parse unrecognized classes (not included in the labelmap) to
a label of value -1. Such targets are unecessary for training, and causes
issue for evaluation, due to labeling mapping logic. This function filters
those labels out for both training and evaluation.

Args:
  tensor_dict: dictionary containing input tensors keyed by
    fields.InputDataFields.

Returns:
  A dictionary keyed by fields.InputDataFields containing the tensors
  obtained after applying the filtering.

Raises:
  ValueError: If groundtruth_classes tensor is not in tensor_dict.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00498">498</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  498</span><span class="keyword">def </span>filter_unrecognized_classes(tensor_dict):</div>
<div class="line"><span class="lineno">  499</span>  <span class="stringliteral">&quot;&quot;&quot;Filters out class labels that are not unrecognized by the labelmap.</span></div>
<div class="line"><span class="lineno">  500</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  501</span><span class="stringliteral">  Decoder would parse unrecognized classes (</span><span class="keywordflow">not</span> included <span class="keywordflow">in</span> the labelmap) to</div>
<div class="line"><span class="lineno">  502</span>  a label of value -1. Such targets are unecessary <span class="keywordflow">for</span> training, <span class="keywordflow">and</span> causes</div>
<div class="line"><span class="lineno">  503</span>  issue <span class="keywordflow">for</span> evaluation, due to labeling mapping logic. This function filters</div>
<div class="line"><span class="lineno">  504</span>  those labels out <span class="keywordflow">for</span> both training <span class="keywordflow">and</span> evaluation.</div>
<div class="line"><span class="lineno">  505</span> </div>
<div class="line"><span class="lineno">  506</span>  Args:</div>
<div class="line"><span class="lineno">  507</span>    tensor_dict: dictionary containing input tensors keyed by</div>
<div class="line"><span class="lineno">  508</span>      fields.InputDataFields.</div>
<div class="line"><span class="lineno">  509</span> </div>
<div class="line"><span class="lineno">  510</span>  Returns:</div>
<div class="line"><span class="lineno">  511</span>    A dictionary keyed by fields.InputDataFields containing the tensors</div>
<div class="line"><span class="lineno">  512</span>    obtained after applying the filtering.</div>
<div class="line"><span class="lineno">  513</span> </div>
<div class="line"><span class="lineno">  514</span>  Raises:</div>
<div class="line"><span class="lineno">  515</span>    ValueError: If groundtruth_classes tensor <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> tensor_dict.</div>
<div class="line"><span class="lineno">  516</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  517</span><span class="stringliteral">  </span><span class="keywordflow">if</span> fields.InputDataFields.groundtruth_classes <span class="keywordflow">not</span> <span class="keywordflow">in</span> tensor_dict:</div>
<div class="line"><span class="lineno">  518</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`groundtruth classes` not in tensor_dict.&#39;</span>)</div>
<div class="line"><span class="lineno">  519</span>  <span class="comment"># Refer to tf_example_decoder for how unrecognized labels are handled.</span></div>
<div class="line"><span class="lineno">  520</span>  unrecognized_label = -1</div>
<div class="line"><span class="lineno">  521</span>  recognized_indices = tf.where(</div>
<div class="line"><span class="lineno">  522</span>      tf.greater(tensor_dict[fields.InputDataFields.groundtruth_classes],</div>
<div class="line"><span class="lineno">  523</span>                 unrecognized_label))</div>
<div class="line"><span class="lineno">  524</span> </div>
<div class="line"><span class="lineno">  525</span>  <span class="keywordflow">return</span> retain_groundtruth(tensor_dict, recognized_indices)</div>
<div class="line"><span class="lineno">  526</span> </div>
<div class="line"><span class="lineno">  527</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_a391c9d74117ad32ba170f1df7be9efc9_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_a391c9d74117ad32ba170f1df7be9efc9_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a391c9d74117ad32ba170f1df7be9efc9_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a391c9d74117ad32ba170f1df7be9efc9_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,192,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af4c44e343c3cb222937eb3e496ce68e6" title=" " alt="" coords="240,5,435,45"/>
<area shape="poly" title=" " alt="" coords="192,23,227,23,227,28,192,28"/>
</map>
</div>

</div>
</div>
<a id="a516b301f1397988c4021aec757b16d2d" name="a516b301f1397988c4021aec757b16d2d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a516b301f1397988c4021aec757b16d2d">&#9670;&#160;</a></span>fixed_padding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.fixed_padding </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>kernel_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rate</em> = <code>1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pads the input along the spatial dimensions independently of input size.

Args:
  inputs: A tensor of size [batch, height_in, width_in, channels].
  kernel_size: The kernel to be used in the conv2d or max_pool2d operation.
               Should be a positive integer.
  rate: An integer, rate for atrous convolution.

Returns:
  output: A tensor of size [batch, height_out, width_out, channels] with the
    input, either intact (if kernel_size == 1) or padded (if kernel_size &gt; 1).
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00138">138</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  138</span><span class="keyword">def </span>fixed_padding(inputs, kernel_size, rate=1):</div>
<div class="line"><span class="lineno">  139</span>  <span class="stringliteral">&quot;&quot;&quot;Pads the input along the spatial dimensions independently of input size.</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">    inputs: A tensor of size [batch, height_in, width_in, channels].</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">    kernel_size: The kernel to be used </span><span class="keywordflow">in</span> the conv2d <span class="keywordflow">or</span> max_pool2d operation.</div>
<div class="line"><span class="lineno">  144</span>                 Should be a positive integer.</div>
<div class="line"><span class="lineno">  145</span>    rate: An integer, rate <span class="keywordflow">for</span> atrous convolution.</div>
<div class="line"><span class="lineno">  146</span> </div>
<div class="line"><span class="lineno">  147</span>  Returns:</div>
<div class="line"><span class="lineno">  148</span>    output: A tensor of size [batch, height_out, width_out, channels] <span class="keyword">with</span> the</div>
<div class="line"><span class="lineno">  149</span>      input, either intact (<span class="keywordflow">if</span> kernel_size == 1) <span class="keywordflow">or</span> padded (<span class="keywordflow">if</span> kernel_size &gt; 1).</div>
<div class="line"><span class="lineno">  150</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">  kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">  pad_total = kernel_size_effective - 1</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">  pad_beg = pad_total // 2</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">  pad_end = pad_total - pad_beg</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">  padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">                                  [pad_beg, pad_end], [0, 0]])</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">  </span><span class="keywordflow">return</span> padded_inputs</div>
<div class="line"><span class="lineno">  158</span> </div>
<div class="line"><span class="lineno">  159</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a140f2d38716d4f6f82081e7a6dfc38c7" name="a140f2d38716d4f6f82081e7a6dfc38c7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a140f2d38716d4f6f82081e7a6dfc38c7">&#9670;&#160;</a></span>fpn_feature_levels()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.fpn_feature_levels </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_levels</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>unit_scale_index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>image_ratio</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boxes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns fpn feature level for each box based on its area.

See section 4.2 of https://arxiv.org/pdf/1612.03144.pdf for details.

Args:
  num_levels: An integer indicating the number of feature levels to crop boxes
    from.
  unit_scale_index: An 0-based integer indicating the index of feature map
    which most closely matches the resolution of the pretrained model.
  image_ratio: A float indicating the ratio of input image area to pretraining
    image area.
  boxes: A float tensor of shape [batch, num_boxes, 4] containing boxes of the
    form [ymin, xmin, ymax, xmax] in normalized coordinates.

Returns:
  An int32 tensor of shape [batch_size, num_boxes] containing feature indices.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l01003">1003</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1003</span><span class="keyword">def </span>fpn_feature_levels(num_levels, unit_scale_index, image_ratio, boxes):</div>
<div class="line"><span class="lineno"> 1004</span>  <span class="stringliteral">&quot;&quot;&quot;Returns fpn feature level for each box based on its area.</span></div>
<div class="line"><span class="lineno"> 1005</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1006</span><span class="stringliteral">  See section 4.2 of https://arxiv.org/pdf/1612.03144.pdf </span><span class="keywordflow">for</span> details.</div>
<div class="line"><span class="lineno"> 1007</span> </div>
<div class="line"><span class="lineno"> 1008</span>  Args:</div>
<div class="line"><span class="lineno"> 1009</span>    num_levels: An integer indicating the number of feature levels to crop boxes</div>
<div class="line"><span class="lineno"> 1010</span>      <span class="keyword">from</span>.</div>
<div class="line"><span class="lineno"> 1011</span>    unit_scale_index: An 0-based integer indicating the index of feature map</div>
<div class="line"><span class="lineno"> 1012</span>      which most closely matches the resolution of the pretrained model.</div>
<div class="line"><span class="lineno"> 1013</span>    image_ratio: A float indicating the ratio of input image area to pretraining</div>
<div class="line"><span class="lineno"> 1014</span>      image area.</div>
<div class="line"><span class="lineno"> 1015</span>    boxes: A float tensor of shape [batch, num_boxes, 4] containing boxes of the</div>
<div class="line"><span class="lineno"> 1016</span>      form [ymin, xmin, ymax, xmax] <span class="keywordflow">in</span> normalized coordinates.</div>
<div class="line"><span class="lineno"> 1017</span> </div>
<div class="line"><span class="lineno"> 1018</span>  Returns:</div>
<div class="line"><span class="lineno"> 1019</span>    An int32 tensor of shape [batch_size, num_boxes] containing feature indices.</div>
<div class="line"><span class="lineno"> 1020</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1021</span><span class="stringliteral">  </span><span class="keyword">assert</span> num_levels &gt; 0, (</div>
<div class="line"><span class="lineno"> 1022</span>      <span class="stringliteral">&#39;`num_levels` must be &gt; 0. Found {}&#39;</span>.format(num_levels))</div>
<div class="line"><span class="lineno"> 1023</span>  <span class="keyword">assert</span> unit_scale_index &lt; num_levels <span class="keywordflow">and</span> unit_scale_index &gt;= 0, (</div>
<div class="line"><span class="lineno"> 1024</span>      <span class="stringliteral">&#39;`unit_scale_index` must be in [0, {}). Found {}.&#39;</span>.format(</div>
<div class="line"><span class="lineno"> 1025</span>          num_levels, unit_scale_index))</div>
<div class="line"><span class="lineno"> 1026</span>  box_height_width = boxes[:, :, 2:4] - boxes[:, :, 0:2]</div>
<div class="line"><span class="lineno"> 1027</span>  areas_sqrt = tf.sqrt(tf.reduce_prod(box_height_width, axis=2))</div>
<div class="line"><span class="lineno"> 1028</span>  log_2 = tf.cast(tf.log(2.0), dtype=boxes.dtype)</div>
<div class="line"><span class="lineno"> 1029</span>  levels = tf.cast(</div>
<div class="line"><span class="lineno"> 1030</span>      tf.floordiv(tf.log(areas_sqrt * image_ratio), log_2)</div>
<div class="line"><span class="lineno"> 1031</span>      +</div>
<div class="line"><span class="lineno"> 1032</span>      unit_scale_index,</div>
<div class="line"><span class="lineno"> 1033</span>      dtype=tf.int32)</div>
<div class="line"><span class="lineno"> 1034</span>  levels = tf.maximum(0, tf.minimum(num_levels - 1, levels))</div>
<div class="line"><span class="lineno"> 1035</span>  <span class="keywordflow">return</span> levels</div>
<div class="line"><span class="lineno"> 1036</span> </div>
<div class="line"><span class="lineno"> 1037</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4f2f992f354f09d7235817f9787a6454" name="a4f2f992f354f09d7235817f9787a6454"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f2f992f354f09d7235817f9787a6454">&#9670;&#160;</a></span>gather_with_padding_values()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.gather_with_padding_values </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>padding_value</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Gathers elements from tensor and pads `padding_value` for ignore indices.

Gathers elements from `input_tensor` based on `indices`. If there are ignore
indices (which are "-1"s) in `indices`, `padding_value` will be gathered for
those positions.

Args:
  input_tensor: A N-D tensor of shape [M, d_1, d_2 .. d_(N-1)] to gather
    values from.
  indices: A 1-D tensor in which each element is either an index in the
    first dimension of input_tensor or -1.
  padding_value: A (N-1)-D tensor of shape [d_1, d_2 .. d_(N-1)] which will be
    used as gathered value for each ignore index in `indices`.

Returns:
  gathered_tensor: A tensor of shape [L, d_1, d_2 .. d_(N-1)] containing
    values gathered from input_tensor. The first dimension L is equal to the
    length of `indices`.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l01063">1063</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 1063</span><span class="keyword">def </span>gather_with_padding_values(input_tensor, indices, padding_value):</div>
<div class="line"><span class="lineno"> 1064</span>  <span class="stringliteral">&quot;&quot;&quot;Gathers elements from tensor and pads `padding_value` for ignore indices.</span></div>
<div class="line"><span class="lineno"> 1065</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno"> 1066</span><span class="stringliteral">  Gathers elements </span><span class="keyword">from</span> `input_tensor` based on `indices`. If there are ignore</div>
<div class="line"><span class="lineno"> 1067</span>  indices (which are <span class="stringliteral">&quot;-1&quot;</span>s) <span class="keywordflow">in</span> `indices`, `padding_value` will be gathered <span class="keywordflow">for</span></div>
<div class="line"><span class="lineno"> 1068</span>  those positions.</div>
<div class="line"><span class="lineno"> 1069</span> </div>
<div class="line"><span class="lineno"> 1070</span>  Args:</div>
<div class="line"><span class="lineno"> 1071</span>    input_tensor: A N-D tensor of shape [M, d_1, d_2 .. d_(N-1)] to gather</div>
<div class="line"><span class="lineno"> 1072</span>      values <span class="keyword">from</span>.</div>
<div class="line"><span class="lineno"> 1073</span>    indices: A 1-D tensor <span class="keywordflow">in</span> which each element <span class="keywordflow">is</span> either an index <span class="keywordflow">in</span> the</div>
<div class="line"><span class="lineno"> 1074</span>      first dimension of input_tensor <span class="keywordflow">or</span> -1.</div>
<div class="line"><span class="lineno"> 1075</span>    padding_value: A (N-1)-D tensor of shape [d_1, d_2 .. d_(N-1)] which will be</div>
<div class="line"><span class="lineno"> 1076</span>      used <span class="keyword">as</span> gathered value <span class="keywordflow">for</span> each ignore index <span class="keywordflow">in</span> `indices`.</div>
<div class="line"><span class="lineno"> 1077</span> </div>
<div class="line"><span class="lineno"> 1078</span>  Returns:</div>
<div class="line"><span class="lineno"> 1079</span>    gathered_tensor: A tensor of shape [L, d_1, d_2 .. d_(N-1)] containing</div>
<div class="line"><span class="lineno"> 1080</span>      values gathered <span class="keyword">from</span> input_tensor. The first dimension L <span class="keywordflow">is</span> equal to the</div>
<div class="line"><span class="lineno"> 1081</span>      length of `indices`.</div>
<div class="line"><span class="lineno"> 1082</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno"> 1083</span><span class="stringliteral">  padding_value = tf.expand_dims(padding_value, axis=0)</span></div>
<div class="line"><span class="lineno"> 1084</span><span class="stringliteral">  input_tensor = tf.concat([padding_value, input_tensor], axis=0)</span></div>
<div class="line"><span class="lineno"> 1085</span><span class="stringliteral">  gather_indices = indices + 1</span></div>
<div class="line"><span class="lineno"> 1086</span><span class="stringliteral">  gathered_tensor = tf.gather(input_tensor, gather_indices)</span></div>
<div class="line"><span class="lineno"> 1087</span><span class="stringliteral">  </span><span class="keywordflow">return</span> gathered_tensor</div>
<div class="line"><span class="lineno"> 1088</span> </div>
<div class="line"><span class="lineno"> 1089</span> </div>
<div class="line"><span class="lineno"> 1090</span> </div>
<div class="line"><span class="lineno"> 1091</span> </div>
<div class="line"><span class="lineno"> 1092</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a9fad235f916265ec93571df2b5269b46" name="a9fad235f916265ec93571df2b5269b46"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9fad235f916265ec93571df2b5269b46">&#9670;&#160;</a></span>indices_to_dense_vector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.indices_to_dense_vector </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices_value</em> = <code>1.</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>default_value</em> = <code>0</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>tf.float32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Creates dense vector with indices set to specific value and rest to zeros.

This function exists because it is unclear if it is safe to use
  tf.sparse_to_dense(indices, [size], 1, validate_indices=False)
with indices which are not ordered.
This function accepts a dynamic size (e.g. tf.shape(tensor)[0])

Args:
  indices: 1d Tensor with integer indices which are to be set to
      indices_values.
  size: scalar with size (integer) of output Tensor.
  indices_value: values of elements specified by indices in the output vector
  default_value: values of other elements in the output vector.
  dtype: data type.

Returns:
  dense 1D Tensor of shape [size] with indices set to indices_values and the
      rest set to default_value.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00306">306</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  310</span>                            dtype=tf.float32):</div>
<div class="line"><span class="lineno">  311</span>  <span class="stringliteral">&quot;&quot;&quot;Creates dense vector with indices set to specific value and rest to zeros.</span></div>
<div class="line"><span class="lineno">  312</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  313</span><span class="stringliteral">  This function exists because it </span><span class="keywordflow">is</span> unclear <span class="keywordflow">if</span> it <span class="keywordflow">is</span> safe to use</div>
<div class="line"><span class="lineno">  314</span>    tf.sparse_to_dense(indices, [size], 1, validate_indices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  315</span>  <span class="keyword">with</span> indices which are <span class="keywordflow">not</span> ordered.</div>
<div class="line"><span class="lineno">  316</span>  This function accepts a dynamic size (e.g. tf.shape(tensor)[0])</div>
<div class="line"><span class="lineno">  317</span> </div>
<div class="line"><span class="lineno">  318</span>  Args:</div>
<div class="line"><span class="lineno">  319</span>    indices: 1d Tensor <span class="keyword">with</span> integer indices which are to be set to</div>
<div class="line"><span class="lineno">  320</span>        indices_values.</div>
<div class="line"><span class="lineno">  321</span>    size: scalar <span class="keyword">with</span> size (integer) of output Tensor.</div>
<div class="line"><span class="lineno">  322</span>    indices_value: values of elements specified by indices <span class="keywordflow">in</span> the output vector</div>
<div class="line"><span class="lineno">  323</span>    default_value: values of other elements <span class="keywordflow">in</span> the output vector.</div>
<div class="line"><span class="lineno">  324</span>    dtype: data type.</div>
<div class="line"><span class="lineno">  325</span> </div>
<div class="line"><span class="lineno">  326</span>  Returns:</div>
<div class="line"><span class="lineno">  327</span>    dense 1D Tensor of shape [size] <span class="keyword">with</span> indices set to indices_values <span class="keywordflow">and</span> the</div>
<div class="line"><span class="lineno">  328</span>        rest set to default_value.</div>
<div class="line"><span class="lineno">  329</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">  size = tf.cast(size, dtype=tf.int32)</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral">  zeros = tf.ones([size], dtype=dtype) * default_value</span></div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">  values = tf.ones_like(indices, dtype=dtype) * indices_value</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral">  </span><span class="keywordflow">return</span> tf.dynamic_stitch([tf.range(size), tf.cast(indices, dtype=tf.int32)],</div>
<div class="line"><span class="lineno">  335</span>                           [zeros, values])</div>
<div class="line"><span class="lineno">  336</span> </div>
<div class="line"><span class="lineno">  337</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a6323da655ab0d0f545c213c5b0382b7f" name="a6323da655ab0d0f545c213c5b0382b7f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6323da655ab0d0f545c213c5b0382b7f">&#9670;&#160;</a></span>matmul_gather_on_zeroth_axis()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.matmul_gather_on_zeroth_axis </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>scope</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Matrix multiplication based implementation of tf.gather on zeroth axis.

TODO(rathodv, jonathanhuang): enable sparse matmul option.

Args:
  params: A float32 Tensor. The tensor from which to gather values.
    Must be at least rank 1.
  indices: A Tensor. Must be one of the following types: int32, int64.
    Must be in range [0, params.shape[0])
  scope: A name for the operation (optional).

Returns:
  A Tensor. Has the same type as params. Values from params gathered
  from indices given by indices, with shape indices.shape + params.shape[1:].
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00977">977</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  977</span><span class="keyword">def </span>matmul_gather_on_zeroth_axis(params, indices, scope=None):</div>
<div class="line"><span class="lineno">  978</span>  <span class="stringliteral">&quot;&quot;&quot;Matrix multiplication based implementation of tf.gather on zeroth axis.</span></div>
<div class="line"><span class="lineno">  979</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  980</span><span class="stringliteral">  TODO(rathodv, jonathanhuang): enable sparse matmul option.</span></div>
<div class="line"><span class="lineno">  981</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  982</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  983</span><span class="stringliteral">    params: A float32 Tensor. The tensor </span><span class="keyword">from</span> which to gather values.</div>
<div class="line"><span class="lineno">  984</span>      Must be at least rank 1.</div>
<div class="line"><span class="lineno">  985</span>    indices: A Tensor. Must be one of the following types: int32, int64.</div>
<div class="line"><span class="lineno">  986</span>      Must be <span class="keywordflow">in</span> range [0, params.shape[0])</div>
<div class="line"><span class="lineno">  987</span>    scope: A name <span class="keywordflow">for</span> the operation (optional).</div>
<div class="line"><span class="lineno">  988</span> </div>
<div class="line"><span class="lineno">  989</span>  Returns:</div>
<div class="line"><span class="lineno">  990</span>    A Tensor. Has the same type <span class="keyword">as</span> params. Values <span class="keyword">from</span> params gathered</div>
<div class="line"><span class="lineno">  991</span>    <span class="keyword">from</span> indices given by indices, <span class="keyword">with</span> shape indices.shape + params.shape[1:].</div>
<div class="line"><span class="lineno">  992</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  993</span><span class="stringliteral">  </span><span class="keyword">with</span> tf.name_scope(scope, <span class="stringliteral">&#39;MatMulGather&#39;</span>):</div>
<div class="line"><span class="lineno">  994</span>    params_shape = shape_utils.combined_static_and_dynamic_shape(params)</div>
<div class="line"><span class="lineno">  995</span>    indices_shape = shape_utils.combined_static_and_dynamic_shape(indices)</div>
<div class="line"><span class="lineno">  996</span>    params2d = tf.reshape(params, [params_shape[0], -1])</div>
<div class="line"><span class="lineno">  997</span>    indicator_matrix = tf.one_hot(indices, params_shape[0])</div>
<div class="line"><span class="lineno">  998</span>    gathered_result_flattened = tf.matmul(indicator_matrix, params2d)</div>
<div class="line"><span class="lineno">  999</span>    <span class="keywordflow">return</span> tf.reshape(gathered_result_flattened,</div>
<div class="line"><span class="lineno"> 1000</span>                      tf.stack(indices_shape + params_shape[1:]))</div>
<div class="line"><span class="lineno"> 1001</span> </div>
<div class="line"><span class="lineno"> 1002</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa05d5979ad4881e4f972be53d5b4200d" name="aa05d5979ad4881e4f972be53d5b4200d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa05d5979ad4881e4f972be53d5b4200d">&#9670;&#160;</a></span>merge_boxes_with_multiple_labels()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.merge_boxes_with_multiple_labels </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>classes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>confidences</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_classes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>quantization_bins</em> = <code>10000</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Merges boxes with same coordinates and returns K-hot encoded classes.

Args:
  boxes: A tf.float32 tensor with shape [N, 4] holding N boxes. Only
    normalized coordinates are allowed.
  classes: A tf.int32 tensor with shape [N] holding class indices.
    The class index starts at 0.
  confidences: A tf.float32 tensor with shape [N] holding class confidences.
  num_classes: total number of classes to use for K-hot encoding.
  quantization_bins: the number of bins used to quantize the box coordinate.

Returns:
  merged_boxes: A tf.float32 tensor with shape [N', 4] holding boxes,
    where N' &lt;= N.
  class_encodings: A tf.int32 tensor with shape [N', num_classes] holding
    K-hot encodings for the merged boxes.
  confidence_encodings: A tf.float32 tensor with shape [N', num_classes]
    holding encodings of confidences for the merged boxes.
  merged_box_indices: A tf.int32 tensor with shape [N'] holding original
    indices of the boxes.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00849">849</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  853</span>                                     quantization_bins=10000):</div>
<div class="line"><span class="lineno">  854</span>  <span class="stringliteral">&quot;&quot;&quot;Merges boxes with same coordinates and returns K-hot encoded classes.</span></div>
<div class="line"><span class="lineno">  855</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  856</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  857</span><span class="stringliteral">    boxes: A tf.float32 tensor </span><span class="keyword">with</span> shape [N, 4] holding N boxes. Only</div>
<div class="line"><span class="lineno">  858</span>      normalized coordinates are allowed.</div>
<div class="line"><span class="lineno">  859</span>    classes: A tf.int32 tensor <span class="keyword">with</span> shape [N] holding <span class="keyword">class </span>indices.</div>
<div class="line"><span class="lineno">  860</span>      The <span class="keyword">class </span>index starts at 0.</div>
<div class="line"><span class="lineno">  861</span>    confidences: A tf.float32 tensor <span class="keyword">with</span> shape [N] holding <span class="keyword">class </span>confidences.</div>
<div class="line"><span class="lineno">  862</span>    num_classes: total number of classes to use <span class="keywordflow">for</span> K-hot encoding.</div>
<div class="line"><span class="lineno">  863</span>    quantization_bins: the number of bins used to quantize the box coordinate.</div>
<div class="line"><span class="lineno">  864</span> </div>
<div class="line"><span class="lineno">  865</span>  Returns:</div>
<div class="line"><span class="lineno">  866</span>    merged_boxes: A tf.float32 tensor <span class="keyword">with</span> shape [N<span class="stringliteral">&#39;, 4] holding boxes,</span></div>
<div class="line"><span class="lineno">  867</span><span class="stringliteral">      where N&#39; &lt;= N.</span></div>
<div class="line"><span class="lineno">  868</span><span class="stringliteral">    class_encodings: A tf.int32 tensor </span><span class="keyword">with</span> shape [N<span class="stringliteral">&#39;, num_classes] holding</span></div>
<div class="line"><span class="lineno">  869</span><span class="stringliteral">      K-hot encodings </span><span class="keywordflow">for</span> the merged boxes.</div>
<div class="line"><span class="lineno">  870</span>    confidence_encodings: A tf.float32 tensor <span class="keyword">with</span> shape [N<span class="stringliteral">&#39;, num_classes]</span></div>
<div class="line"><span class="lineno">  871</span><span class="stringliteral">      holding encodings of confidences </span><span class="keywordflow">for</span> the merged boxes.</div>
<div class="line"><span class="lineno">  872</span>    merged_box_indices: A tf.int32 tensor <span class="keyword">with</span> shape [N<span class="stringliteral">&#39;] holding original</span></div>
<div class="line"><span class="lineno">  873</span><span class="stringliteral">      indices of the boxes.</span></div>
<div class="line"><span class="lineno">  874</span><span class="stringliteral">  &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  875</span><span class="stringliteral">  boxes_shape = tf.shape(boxes)</span></div>
<div class="line"><span class="lineno">  876</span><span class="stringliteral">  classes_shape = tf.shape(classes)</span></div>
<div class="line"><span class="lineno">  877</span><span class="stringliteral">  confidences_shape = tf.shape(confidences)</span></div>
<div class="line"><span class="lineno">  878</span><span class="stringliteral">  box_class_shape_assert = shape_utils.assert_shape_equal_along_first_dimension(</span></div>
<div class="line"><span class="lineno">  879</span><span class="stringliteral">      boxes_shape, classes_shape)</span></div>
<div class="line"><span class="lineno">  880</span><span class="stringliteral">  box_confidence_shape_assert = (</span></div>
<div class="line"><span class="lineno">  881</span><span class="stringliteral">      shape_utils.assert_shape_equal_along_first_dimension(</span></div>
<div class="line"><span class="lineno">  882</span><span class="stringliteral">          boxes_shape, confidences_shape))</span></div>
<div class="line"><span class="lineno">  883</span><span class="stringliteral">  box_dimension_assert = tf.assert_equal(boxes_shape[1], 4)</span></div>
<div class="line"><span class="lineno">  884</span><span class="stringliteral">  box_normalized_assert = shape_utils.assert_box_normalized(boxes)</span></div>
<div class="line"><span class="lineno">  885</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  886</span><span class="stringliteral">  </span><span class="keyword">with</span> tf.control_dependencies(</div>
<div class="line"><span class="lineno">  887</span>      [box_class_shape_assert, box_confidence_shape_assert,</div>
<div class="line"><span class="lineno">  888</span>       box_dimension_assert, box_normalized_assert]):</div>
<div class="line"><span class="lineno">  889</span>    quantized_boxes = tf.to_int64(boxes * (quantization_bins - 1))</div>
<div class="line"><span class="lineno">  890</span>    ymin, xmin, ymax, xmax = tf.unstack(quantized_boxes, axis=1)</div>
<div class="line"><span class="lineno">  891</span>    hashcodes = (</div>
<div class="line"><span class="lineno">  892</span>        ymin +</div>
<div class="line"><span class="lineno">  893</span>        xmin * quantization_bins +</div>
<div class="line"><span class="lineno">  894</span>        ymax * quantization_bins * quantization_bins +</div>
<div class="line"><span class="lineno">  895</span>        xmax * quantization_bins * quantization_bins * quantization_bins)</div>
<div class="line"><span class="lineno">  896</span>    unique_hashcodes, unique_indices = tf.unique(hashcodes)</div>
<div class="line"><span class="lineno">  897</span>    num_boxes = tf.shape(boxes)[0]</div>
<div class="line"><span class="lineno">  898</span>    num_unique_boxes = tf.shape(unique_hashcodes)[0]</div>
<div class="line"><span class="lineno">  899</span>    merged_box_indices = tf.unsorted_segment_min(</div>
<div class="line"><span class="lineno">  900</span>        tf.range(num_boxes), unique_indices, num_unique_boxes)</div>
<div class="line"><span class="lineno">  901</span>    merged_boxes = tf.gather(boxes, merged_box_indices)</div>
<div class="line"><span class="lineno">  902</span>    unique_indices = tf.to_int64(unique_indices)</div>
<div class="line"><span class="lineno">  903</span>    classes = tf.to_int64(classes)</div>
<div class="line"><span class="lineno">  904</span> </div>
<div class="line"><span class="lineno">  905</span>    <span class="keyword">def </span>map_box_encodings(i):</div>
<div class="line"><span class="lineno">  906</span>      <span class="stringliteral">&quot;&quot;&quot;Produces box K-hot and score encodings for each class index.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  907</span>      box_mask = tf.equal(</div>
<div class="line"><span class="lineno">  908</span>          unique_indices, i * tf.ones(num_boxes, dtype=tf.int64))</div>
<div class="line"><span class="lineno">  909</span>      box_mask = tf.reshape(box_mask, [-1])</div>
<div class="line"><span class="lineno">  910</span>      box_indices = tf.boolean_mask(classes, box_mask)</div>
<div class="line"><span class="lineno">  911</span>      box_confidences = tf.boolean_mask(confidences, box_mask)</div>
<div class="line"><span class="lineno">  912</span>      box_class_encodings = tf.sparse_to_dense(</div>
<div class="line"><span class="lineno">  913</span>          box_indices, [num_classes], tf.constant(1, dtype=tf.int64),</div>
<div class="line"><span class="lineno">  914</span>          validate_indices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  915</span>      box_confidence_encodings = tf.sparse_to_dense(</div>
<div class="line"><span class="lineno">  916</span>          box_indices, [num_classes], box_confidences, validate_indices=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  917</span>      <span class="keywordflow">return</span> box_class_encodings, box_confidence_encodings</div>
<div class="line"><span class="lineno">  918</span> </div>
<div class="line"><span class="lineno">  919</span>    <span class="comment"># Important to avoid int32 here since there is no GPU kernel for int32.</span></div>
<div class="line"><span class="lineno">  920</span>    <span class="comment"># int64 and float32 are fine.</span></div>
<div class="line"><span class="lineno">  921</span>    class_encodings, confidence_encodings = tf.map_fn(</div>
<div class="line"><span class="lineno">  922</span>        map_box_encodings,</div>
<div class="line"><span class="lineno">  923</span>        tf.range(tf.to_int64(num_unique_boxes)),</div>
<div class="line"><span class="lineno">  924</span>        back_prop=<span class="keyword">False</span>,</div>
<div class="line"><span class="lineno">  925</span>        dtype=(tf.int64, tf.float32))</div>
<div class="line"><span class="lineno">  926</span> </div>
<div class="line"><span class="lineno">  927</span>    merged_boxes = tf.reshape(merged_boxes, [-1, 4])</div>
<div class="line"><span class="lineno">  928</span>    class_encodings = tf.cast(class_encodings, dtype=tf.int32)</div>
<div class="line"><span class="lineno">  929</span>    class_encodings = tf.reshape(class_encodings, [-1, num_classes])</div>
<div class="line"><span class="lineno">  930</span>    confidence_encodings = tf.reshape(confidence_encodings, [-1, num_classes])</div>
<div class="line"><span class="lineno">  931</span>    merged_box_indices = tf.reshape(merged_box_indices, [-1])</div>
<div class="line"><span class="lineno">  932</span>    <span class="keywordflow">return</span> (merged_boxes, class_encodings, confidence_encodings,</div>
<div class="line"><span class="lineno">  933</span>            merged_box_indices)</div>
<div class="line"><span class="lineno">  934</span> </div>
<div class="line"><span class="lineno">  935</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af311e77e054cb389029fd2e4a40c2955" name="af311e77e054cb389029fd2e4a40c2955"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af311e77e054cb389029fd2e4a40c2955">&#9670;&#160;</a></span>meshgrid()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.meshgrid </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>x</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Tiles the contents of x and y into a pair of grids.

Multidimensional analog of numpy.meshgrid, giving the same behavior if x and y
are vectors. Generally, this will give:

xgrid(i1, ..., i_m, j_1, ..., j_n) = x(j_1, ..., j_n)
ygrid(i1, ..., i_m, j_1, ..., j_n) = y(i_1, ..., i_m)

Keep in mind that the order of the arguments and outputs is reverse relative
to the order of the indices they go into, done for compatibility with numpy.
The output tensors have the same shapes.  Specifically:

xgrid.get_shape() = y.get_shape().concatenate(x.get_shape())
ygrid.get_shape() = y.get_shape().concatenate(x.get_shape())

Args:
  x: A tensor of arbitrary shape and rank. xgrid will contain these values
     varying in its last dimensions.
  y: A tensor of arbitrary shape and rank. ygrid will contain these values
     varying in its first dimensions.
Returns:
  A tuple of tensors (xgrid, ygrid).
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00099">99</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   99</span><span class="keyword">def </span>meshgrid(x, y):</div>
<div class="line"><span class="lineno">  100</span>  <span class="stringliteral">&quot;&quot;&quot;Tiles the contents of x and y into a pair of grids.</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">  Multidimensional analog of numpy.meshgrid, giving the same behavior </span><span class="keywordflow">if</span> x <span class="keywordflow">and</span> y</div>
<div class="line"><span class="lineno">  103</span>  are vectors. Generally, this will give:</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>  xgrid(i1, ..., i_m, j_1, ..., j_n) = x(j_1, ..., j_n)</div>
<div class="line"><span class="lineno">  106</span>  ygrid(i1, ..., i_m, j_1, ..., j_n) = y(i_1, ..., i_m)</div>
<div class="line"><span class="lineno">  107</span> </div>
<div class="line"><span class="lineno">  108</span>  Keep <span class="keywordflow">in</span> mind that the order of the arguments <span class="keywordflow">and</span> outputs <span class="keywordflow">is</span> reverse relative</div>
<div class="line"><span class="lineno">  109</span>  to the order of the indices they go into, done <span class="keywordflow">for</span> compatibility <span class="keyword">with</span> numpy.</div>
<div class="line"><span class="lineno">  110</span>  The output tensors have the same shapes.  Specifically:</div>
<div class="line"><span class="lineno">  111</span> </div>
<div class="line"><span class="lineno">  112</span>  xgrid.get_shape() = y.get_shape().concatenate(x.get_shape())</div>
<div class="line"><span class="lineno">  113</span>  ygrid.get_shape() = y.get_shape().concatenate(x.get_shape())</div>
<div class="line"><span class="lineno">  114</span> </div>
<div class="line"><span class="lineno">  115</span>  Args:</div>
<div class="line"><span class="lineno">  116</span>    x: A tensor of arbitrary shape <span class="keywordflow">and</span> rank. xgrid will contain these values</div>
<div class="line"><span class="lineno">  117</span>       varying <span class="keywordflow">in</span> its last dimensions.</div>
<div class="line"><span class="lineno">  118</span>    y: A tensor of arbitrary shape <span class="keywordflow">and</span> rank. ygrid will contain these values</div>
<div class="line"><span class="lineno">  119</span>       varying <span class="keywordflow">in</span> its first dimensions.</div>
<div class="line"><span class="lineno">  120</span>  Returns:</div>
<div class="line"><span class="lineno">  121</span>    A tuple of tensors (xgrid, ygrid).</div>
<div class="line"><span class="lineno">  122</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">  </span><span class="keyword">with</span> tf.name_scope(<span class="stringliteral">&#39;Meshgrid&#39;</span>):</div>
<div class="line"><span class="lineno">  124</span>    x = tf.convert_to_tensor(x)</div>
<div class="line"><span class="lineno">  125</span>    y = tf.convert_to_tensor(y)</div>
<div class="line"><span class="lineno">  126</span>    x_exp_shape = expanded_shape(tf.shape(x), 0, tf.rank(y))</div>
<div class="line"><span class="lineno">  127</span>    y_exp_shape = expanded_shape(tf.shape(y), tf.rank(y), tf.rank(x))</div>
<div class="line"><span class="lineno">  128</span> </div>
<div class="line"><span class="lineno">  129</span>    xgrid = tf.tile(tf.reshape(x, x_exp_shape), y_exp_shape)</div>
<div class="line"><span class="lineno">  130</span>    ygrid = tf.tile(tf.reshape(y, y_exp_shape), x_exp_shape)</div>
<div class="line"><span class="lineno">  131</span>    new_shape = y.get_shape().concatenate(x.get_shape())</div>
<div class="line"><span class="lineno">  132</span>    xgrid.set_shape(new_shape)</div>
<div class="line"><span class="lineno">  133</span>    ygrid.set_shape(new_shape)</div>
<div class="line"><span class="lineno">  134</span> </div>
<div class="line"><span class="lineno">  135</span>    <span class="keywordflow">return</span> xgrid, ygrid</div>
<div class="line"><span class="lineno">  136</span> </div>
<div class="line"><span class="lineno">  137</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_af311e77e054cb389029fd2e4a40c2955_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_af311e77e054cb389029fd2e4a40c2955_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_af311e77e054cb389029fd2e4a40c2955_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_af311e77e054cb389029fd2e4a40c2955_cgraph">
<area shape="rect" title=" " alt="" coords="5,13,221,38"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a361f89dc99c799c108b569851f420be2" title=" " alt="" coords="269,5,488,45"/>
<area shape="poly" title=" " alt="" coords="222,23,256,23,256,28,222,28"/>
</map>
</div>

</div>
</div>
<a id="adc950a7496c9cea7a96d5fe6acd77d82" name="adc950a7496c9cea7a96d5fe6acd77d82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc950a7496c9cea7a96d5fe6acd77d82">&#9670;&#160;</a></span>nearest_neighbor_upsampling()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.nearest_neighbor_upsampling </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>scale</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>height_scale</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>width_scale</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Nearest neighbor upsampling implementation.

Nearest neighbor upsampling function that maps input tensor with shape
[batch_size, height, width, channels] to [batch_size, height * scale
, width * scale, channels]. This implementation only uses reshape and
broadcasting to make it TPU compatible.

Args:
  input_tensor: A float32 tensor of size [batch, height_in, width_in,
    channels].
  scale: An integer multiple to scale resolution of input data in both height
    and width dimensions.
  height_scale: An integer multiple to scale the height of input image. This
    option when provided overrides `scale` option.
  width_scale: An integer multiple to scale the width of input image. This
    option when provided overrides `scale` option.
Returns:
  data_up: A float32 tensor of size
    [batch, height_in*scale, width_in*scale, channels].

Raises:
  ValueError: If both scale and height_scale or if both scale and width_scale
    are None.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00936">936</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  937</span>                                width_scale=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  938</span>  <span class="stringliteral">&quot;&quot;&quot;Nearest neighbor upsampling implementation.</span></div>
<div class="line"><span class="lineno">  939</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  940</span><span class="stringliteral">  Nearest neighbor upsampling function that maps input tensor </span><span class="keyword">with</span> shape</div>
<div class="line"><span class="lineno">  941</span>  [batch_size, height, width, channels] to [batch_size, height * scale</div>
<div class="line"><span class="lineno">  942</span>  , width * scale, channels]. This implementation only uses reshape <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  943</span>  broadcasting to make it TPU compatible.</div>
<div class="line"><span class="lineno">  944</span> </div>
<div class="line"><span class="lineno">  945</span>  Args:</div>
<div class="line"><span class="lineno">  946</span>    input_tensor: A float32 tensor of size [batch, height_in, width_in,</div>
<div class="line"><span class="lineno">  947</span>      channels].</div>
<div class="line"><span class="lineno">  948</span>    scale: An integer multiple to scale resolution of input data <span class="keywordflow">in</span> both height</div>
<div class="line"><span class="lineno">  949</span>      <span class="keywordflow">and</span> width dimensions.</div>
<div class="line"><span class="lineno">  950</span>    height_scale: An integer multiple to scale the height of input image. This</div>
<div class="line"><span class="lineno">  951</span>      option when provided overrides `scale` option.</div>
<div class="line"><span class="lineno">  952</span>    width_scale: An integer multiple to scale the width of input image. This</div>
<div class="line"><span class="lineno">  953</span>      option when provided overrides `scale` option.</div>
<div class="line"><span class="lineno">  954</span>  Returns:</div>
<div class="line"><span class="lineno">  955</span>    data_up: A float32 tensor of size</div>
<div class="line"><span class="lineno">  956</span>      [batch, height_in*scale, width_in*scale, channels].</div>
<div class="line"><span class="lineno">  957</span> </div>
<div class="line"><span class="lineno">  958</span>  Raises:</div>
<div class="line"><span class="lineno">  959</span>    ValueError: If both scale <span class="keywordflow">and</span> height_scale <span class="keywordflow">or</span> <span class="keywordflow">if</span> both scale <span class="keywordflow">and</span> width_scale</div>
<div class="line"><span class="lineno">  960</span>      are <span class="keywordtype">None</span>.</div>
<div class="line"><span class="lineno">  961</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  962</span><span class="stringliteral">  </span><span class="keywordflow">if</span> <span class="keywordflow">not</span> scale <span class="keywordflow">and</span> (height_scale <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> width_scale <span class="keywordflow">is</span> <span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  963</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;Provide either `scale` or `height_scale` and&#39;</span></div>
<div class="line"><span class="lineno">  964</span>                     <span class="stringliteral">&#39; `width_scale`.&#39;</span>)</div>
<div class="line"><span class="lineno">  965</span>  <span class="keyword">with</span> tf.name_scope(<span class="stringliteral">&#39;nearest_neighbor_upsampling&#39;</span>):</div>
<div class="line"><span class="lineno">  966</span>    h_scale = scale <span class="keywordflow">if</span> height_scale <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> height_scale</div>
<div class="line"><span class="lineno">  967</span>    w_scale = scale <span class="keywordflow">if</span> width_scale <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> width_scale</div>
<div class="line"><span class="lineno">  968</span>    (batch_size, height, width,</div>
<div class="line"><span class="lineno">  969</span>     channels) = shape_utils.combined_static_and_dynamic_shape(input_tensor)</div>
<div class="line"><span class="lineno">  970</span>    output_tensor = tf.reshape(</div>
<div class="line"><span class="lineno">  971</span>        input_tensor, [batch_size, height, 1, width, 1, channels]) * tf.ones(</div>
<div class="line"><span class="lineno">  972</span>            [1, 1, h_scale, 1, w_scale, 1], dtype=input_tensor.dtype)</div>
<div class="line"><span class="lineno">  973</span>    <span class="keywordflow">return</span> tf.reshape(output_tensor,</div>
<div class="line"><span class="lineno">  974</span>                      [batch_size, height * h_scale, width * w_scale, channels])</div>
<div class="line"><span class="lineno">  975</span> </div>
<div class="line"><span class="lineno">  976</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a427d2293178f37f8f3030837d3813b65" name="a427d2293178f37f8f3030837d3813b65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a427d2293178f37f8f3030837d3813b65">&#9670;&#160;</a></span>normalize_to_target()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.normalize_to_target </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>target_norm_value</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>epsilon</em> = <code>1e-7</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>trainable</em> = <code>True</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>scope</em> = <code>'NormalizeToTarget'</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>summarize</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">L2 normalizes the inputs across the specified dimension to a target norm.

This op implements the L2 Normalization layer introduced in
Liu, Wei, et al. "SSD: Single Shot MultiBox Detector."
and Liu, Wei, Andrew Rabinovich, and Alexander C. Berg.
"Parsenet: Looking wider to see better." and is useful for bringing
activations from multiple layers in a convnet to a standard scale.

Note that the rank of `inputs` must be known and the dimension to which
normalization is to be applied should be statically defined.

TODO(jonathanhuang): Add option to scale by L2 norm of the entire input.

Args:
  inputs: A `Tensor` of arbitrary size.
  target_norm_value: A float value that specifies an initial target norm or
    a list of floats (whose length must be equal to the depth along the
    dimension to be normalized) specifying a per-dimension multiplier
    after normalization.
  dim: The dimension along which the input is normalized.
  epsilon: A small value to add to the inputs to avoid dividing by zero.
  trainable: Whether the norm is trainable or not
  scope: Optional scope for variable_scope.
  summarize: Whether or not to add a tensorflow summary for the op.

Returns:
  The input tensor normalized to the specified target norm.

Raises:
  ValueError: If dim is smaller than the number of dimensions in 'inputs'.
  ValueError: If target_norm_value is not a float or a list of floats with
    length equal to the depth along the dimension to be normalized.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00528">528</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  534</span>                        summarize=<span class="keyword">True</span>):</div>
<div class="line"><span class="lineno">  535</span>  <span class="stringliteral">&quot;&quot;&quot;L2 normalizes the inputs across the specified dimension to a target norm.</span></div>
<div class="line"><span class="lineno">  536</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  537</span><span class="stringliteral">  This op implements the L2 Normalization layer introduced </span><span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  538</span>  Liu, Wei, et al. <span class="stringliteral">&quot;SSD: Single Shot MultiBox Detector.&quot;</span></div>
<div class="line"><span class="lineno">  539</span>  <span class="keywordflow">and</span> Liu, Wei, Andrew Rabinovich, <span class="keywordflow">and</span> Alexander C. Berg.</div>
<div class="line"><span class="lineno">  540</span>  <span class="stringliteral">&quot;Parsenet: Looking wider to see better.&quot;</span> <span class="keywordflow">and</span> <span class="keywordflow">is</span> useful <span class="keywordflow">for</span> bringing</div>
<div class="line"><span class="lineno">  541</span>  activations <span class="keyword">from</span> multiple layers <span class="keywordflow">in</span> a convnet to a standard scale.</div>
<div class="line"><span class="lineno">  542</span> </div>
<div class="line"><span class="lineno">  543</span>  Note that the rank of `inputs` must be known <span class="keywordflow">and</span> the dimension to which</div>
<div class="line"><span class="lineno">  544</span>  normalization <span class="keywordflow">is</span> to be applied should be statically defined.</div>
<div class="line"><span class="lineno">  545</span> </div>
<div class="line"><span class="lineno">  546</span>  TODO(jonathanhuang): Add option to scale by L2 norm of the entire input.</div>
<div class="line"><span class="lineno">  547</span> </div>
<div class="line"><span class="lineno">  548</span>  Args:</div>
<div class="line"><span class="lineno">  549</span>    inputs: A `Tensor` of arbitrary size.</div>
<div class="line"><span class="lineno">  550</span>    target_norm_value: A float value that specifies an initial target norm <span class="keywordflow">or</span></div>
<div class="line"><span class="lineno">  551</span>      a list of floats (whose length must be equal to the depth along the</div>
<div class="line"><span class="lineno">  552</span>      dimension to be normalized) specifying a per-dimension multiplier</div>
<div class="line"><span class="lineno">  553</span>      after normalization.</div>
<div class="line"><span class="lineno">  554</span>    dim: The dimension along which the input <span class="keywordflow">is</span> normalized.</div>
<div class="line"><span class="lineno">  555</span>    epsilon: A small value to add to the inputs to avoid dividing by zero.</div>
<div class="line"><span class="lineno">  556</span>    trainable: Whether the norm <span class="keywordflow">is</span> trainable <span class="keywordflow">or</span> <span class="keywordflow">not</span></div>
<div class="line"><span class="lineno">  557</span>    scope: Optional scope <span class="keywordflow">for</span> variable_scope.</div>
<div class="line"><span class="lineno">  558</span>    summarize: Whether <span class="keywordflow">or</span> <span class="keywordflow">not</span> to add a tensorflow summary <span class="keywordflow">for</span> the op.</div>
<div class="line"><span class="lineno">  559</span> </div>
<div class="line"><span class="lineno">  560</span>  Returns:</div>
<div class="line"><span class="lineno">  561</span>    The input tensor normalized to the specified target norm.</div>
<div class="line"><span class="lineno">  562</span> </div>
<div class="line"><span class="lineno">  563</span>  Raises:</div>
<div class="line"><span class="lineno">  564</span>    ValueError: If dim <span class="keywordflow">is</span> smaller than the number of dimensions <span class="keywordflow">in</span> <span class="stringliteral">&#39;inputs&#39;</span>.</div>
<div class="line"><span class="lineno">  565</span>    ValueError: If target_norm_value <span class="keywordflow">is</span> <span class="keywordflow">not</span> a float <span class="keywordflow">or</span> a list of floats <span class="keyword">with</span></div>
<div class="line"><span class="lineno">  566</span>      length equal to the depth along the dimension to be normalized.</div>
<div class="line"><span class="lineno">  567</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  568</span><span class="stringliteral">  </span><span class="keyword">with</span> tf.variable_scope(scope, <span class="stringliteral">&#39;NormalizeToTarget&#39;</span>, [inputs]):</div>
<div class="line"><span class="lineno">  569</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> inputs.get_shape():</div>
<div class="line"><span class="lineno">  570</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;The input rank must be known.&#39;</span>)</div>
<div class="line"><span class="lineno">  571</span>    input_shape = inputs.get_shape().as_list()</div>
<div class="line"><span class="lineno">  572</span>    input_rank = len(input_shape)</div>
<div class="line"><span class="lineno">  573</span>    <span class="keywordflow">if</span> dim &lt; 0 <span class="keywordflow">or</span> dim &gt;= input_rank:</div>
<div class="line"><span class="lineno">  574</span>      <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  575</span>          <span class="stringliteral">&#39;dim must be non-negative but smaller than the input rank.&#39;</span>)</div>
<div class="line"><span class="lineno">  576</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> input_shape[dim]:</div>
<div class="line"><span class="lineno">  577</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;input shape should be statically defined along &#39;</span></div>
<div class="line"><span class="lineno">  578</span>                       <span class="stringliteral">&#39;the specified dimension.&#39;</span>)</div>
<div class="line"><span class="lineno">  579</span>    depth = input_shape[dim]</div>
<div class="line"><span class="lineno">  580</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> (isinstance(target_norm_value, float) <span class="keywordflow">or</span></div>
<div class="line"><span class="lineno">  581</span>            (isinstance(target_norm_value, list) <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  582</span>             len(target_norm_value) == depth) <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  583</span>            all([isinstance(val, float) <span class="keywordflow">for</span> val <span class="keywordflow">in</span> target_norm_value])):</div>
<div class="line"><span class="lineno">  584</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;target_norm_value must be a float or a list of floats &#39;</span></div>
<div class="line"><span class="lineno">  585</span>                       <span class="stringliteral">&#39;with length equal to the depth along the dimension to &#39;</span></div>
<div class="line"><span class="lineno">  586</span>                       <span class="stringliteral">&#39;be normalized.&#39;</span>)</div>
<div class="line"><span class="lineno">  587</span>    <span class="keywordflow">if</span> isinstance(target_norm_value, float):</div>
<div class="line"><span class="lineno">  588</span>      initial_norm = depth * [target_norm_value]</div>
<div class="line"><span class="lineno">  589</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  590</span>      initial_norm = target_norm_value</div>
<div class="line"><span class="lineno">  591</span>    target_norm = tf.contrib.framework.model_variable(</div>
<div class="line"><span class="lineno">  592</span>        name=<span class="stringliteral">&#39;weights&#39;</span>, dtype=tf.float32,</div>
<div class="line"><span class="lineno">  593</span>        initializer=tf.constant(initial_norm, dtype=tf.float32),</div>
<div class="line"><span class="lineno">  594</span>        trainable=trainable)</div>
<div class="line"><span class="lineno">  595</span>    <span class="keywordflow">if</span> summarize:</div>
<div class="line"><span class="lineno">  596</span>      mean = tf.reduce_mean(target_norm)</div>
<div class="line"><span class="lineno">  597</span>      tf.summary.scalar(tf.get_variable_scope().name, mean)</div>
<div class="line"><span class="lineno">  598</span>    lengths = epsilon + tf.sqrt(tf.reduce_sum(tf.square(inputs), dim, <span class="keyword">True</span>))</div>
<div class="line"><span class="lineno">  599</span>    mult_shape = input_rank*[1]</div>
<div class="line"><span class="lineno">  600</span>    mult_shape[dim] = depth</div>
<div class="line"><span class="lineno">  601</span>    <span class="keywordflow">return</span> tf.reshape(target_norm, mult_shape) * tf.truediv(inputs, lengths)</div>
<div class="line"><span class="lineno">  602</span> </div>
<div class="line"><span class="lineno">  603</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="adc866ef74c28004b32df8315d34c8805" name="adc866ef74c28004b32df8315d34c8805"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc866ef74c28004b32df8315d34c8805">&#9670;&#160;</a></span>normalized_to_image_coordinates()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.normalized_to_image_coordinates </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>normalized_boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>image_shape</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>parallel_iterations</em> = <code>32</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Converts a batch of boxes from normal to image coordinates.

Args:
  normalized_boxes: a tensor of shape [None, num_boxes, 4] in
    normalized coordinates. The dtype of this tensor must support tf.mul.
  image_shape: a tensor of shape [4] containing the image shape, with same
    dtype as `normalized_boxes`.
  parallel_iterations: parallelism for the map_fn op.

Returns:
  absolute_boxes: a tensor of shape [None, num_boxes, 4] containing
    the boxes in image coordinates, with same
    dtype as `normalized_boxes`.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00062">62</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   63</span>                                    parallel_iterations=32):</div>
<div class="line"><span class="lineno">   64</span>  <span class="stringliteral">&quot;&quot;&quot;Converts a batch of boxes from normal to image coordinates.</span></div>
<div class="line"><span class="lineno">   65</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   66</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">   67</span><span class="stringliteral">    normalized_boxes: a tensor of shape [</span><span class="keywordtype">None</span>, num_boxes, 4] <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">   68</span>      normalized coordinates. The dtype of this tensor must support tf.mul.</div>
<div class="line"><span class="lineno">   69</span>    image_shape: a tensor of shape [4] containing the image shape, <span class="keyword">with</span> same</div>
<div class="line"><span class="lineno">   70</span>      dtype <span class="keyword">as</span> `normalized_boxes`.</div>
<div class="line"><span class="lineno">   71</span>    parallel_iterations: parallelism <span class="keywordflow">for</span> the map_fn op.</div>
<div class="line"><span class="lineno">   72</span> </div>
<div class="line"><span class="lineno">   73</span>  Returns:</div>
<div class="line"><span class="lineno">   74</span>    absolute_boxes: a tensor of shape [<span class="keywordtype">None</span>, num_boxes, 4] containing</div>
<div class="line"><span class="lineno">   75</span>      the boxes <span class="keywordflow">in</span> image coordinates, <span class="keyword">with</span> same</div>
<div class="line"><span class="lineno">   76</span>      dtype <span class="keyword">as</span> `normalized_boxes`.</div>
<div class="line"><span class="lineno">   77</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   78</span><span class="stringliteral">  x_scale = tf.cast(image_shape[2], normalized_boxes.dtype)</span></div>
<div class="line"><span class="lineno">   79</span><span class="stringliteral">  y_scale = tf.cast(image_shape[1], normalized_boxes.dtype)</span></div>
<div class="line"><span class="lineno">   80</span><span class="stringliteral">  </span><span class="keyword">def </span>_to_absolute_coordinates(normalized_boxes):</div>
<div class="line"><span class="lineno">   81</span>    y_min, x_min, y_max, x_max = tf.split(</div>
<div class="line"><span class="lineno">   82</span>        value=normalized_boxes, num_or_size_splits=4, axis=1)</div>
<div class="line"><span class="lineno">   83</span>    y_min = y_scale * y_min</div>
<div class="line"><span class="lineno">   84</span>    y_max = y_scale * y_max</div>
<div class="line"><span class="lineno">   85</span>    x_min = x_scale * x_min</div>
<div class="line"><span class="lineno">   86</span>    x_max = x_scale * x_max</div>
<div class="line"><span class="lineno">   87</span>    scaled_boxes = tf.concat([y_min, x_min, y_max, x_max], 1)</div>
<div class="line"><span class="lineno">   88</span>    <span class="keywordflow">return</span> scaled_boxes</div>
<div class="line"><span class="lineno">   89</span> </div>
<div class="line"><span class="lineno">   90</span>  absolute_boxes = shape_utils.static_or_dynamic_map_fn(</div>
<div class="line"><span class="lineno">   91</span>      _to_absolute_coordinates,</div>
<div class="line"><span class="lineno">   92</span>      elems=(normalized_boxes),</div>
<div class="line"><span class="lineno">   93</span>      dtype=normalized_boxes.dtype,</div>
<div class="line"><span class="lineno">   94</span>      parallel_iterations=parallel_iterations,</div>
<div class="line"><span class="lineno">   95</span>      back_prop=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">   96</span>  <span class="keywordflow">return</span> absolute_boxes</div>
<div class="line"><span class="lineno">   97</span> </div>
<div class="line"><span class="lineno">   98</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afcdac23eebee9bb6a17790afbdf223d9" name="afcdac23eebee9bb6a17790afbdf223d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afcdac23eebee9bb6a17790afbdf223d9">&#9670;&#160;</a></span>pad_to_multiple()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.pad_to_multiple </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>multiple</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the tensor zero padded to the specified multiple.

Appends 0s to the end of the first and second dimension (height and width) of
the tensor until both dimensions are a multiple of the input argument
'multiple'. E.g. given an input tensor of shape [1, 3, 5, 1] and an input
multiple of 4, PadToMultiple will append 0s so that the resulting tensor will
be of shape [1, 4, 8, 1].

Args:
  tensor: rank 4 float32 tensor, where
          tensor -&gt; [batch_size, height, width, channels].
  multiple: the multiple to pad to.

Returns:
  padded_tensor: the tensor zero padded to the specified multiple.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00160">160</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  160</span><span class="keyword">def </span>pad_to_multiple(tensor, multiple):</div>
<div class="line"><span class="lineno">  161</span>  <span class="stringliteral">&quot;&quot;&quot;Returns the tensor zero padded to the specified multiple.</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">  Appends 0s to the end of the first </span><span class="keywordflow">and</span> second dimension (height <span class="keywordflow">and</span> width) of</div>
<div class="line"><span class="lineno">  164</span>  the tensor until both dimensions are a multiple of the input argument</div>
<div class="line"><span class="lineno">  165</span>  <span class="stringliteral">&#39;multiple&#39;</span>. E.g. given an input tensor of shape [1, 3, 5, 1] <span class="keywordflow">and</span> an input</div>
<div class="line"><span class="lineno">  166</span>  multiple of 4, PadToMultiple will append 0s so that the resulting tensor will</div>
<div class="line"><span class="lineno">  167</span>  be of shape [1, 4, 8, 1].</div>
<div class="line"><span class="lineno">  168</span> </div>
<div class="line"><span class="lineno">  169</span>  Args:</div>
<div class="line"><span class="lineno">  170</span>    tensor: rank 4 float32 tensor, where</div>
<div class="line"><span class="lineno">  171</span>            tensor -&gt; [batch_size, height, width, channels].</div>
<div class="line"><span class="lineno">  172</span>    multiple: the multiple to pad to.</div>
<div class="line"><span class="lineno">  173</span> </div>
<div class="line"><span class="lineno">  174</span>  Returns:</div>
<div class="line"><span class="lineno">  175</span>    padded_tensor: the tensor zero padded to the specified multiple.</div>
<div class="line"><span class="lineno">  176</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">  </span><span class="keywordflow">if</span> multiple == 1:</div>
<div class="line"><span class="lineno">  178</span>    <span class="keywordflow">return</span> tensor</div>
<div class="line"><span class="lineno">  179</span> </div>
<div class="line"><span class="lineno">  180</span>  tensor_shape = tensor.get_shape()</div>
<div class="line"><span class="lineno">  181</span>  batch_size = static_shape.get_batch_size(tensor_shape)</div>
<div class="line"><span class="lineno">  182</span>  tensor_height = static_shape.get_height(tensor_shape)</div>
<div class="line"><span class="lineno">  183</span>  tensor_width = static_shape.get_width(tensor_shape)</div>
<div class="line"><span class="lineno">  184</span>  tensor_depth = static_shape.get_depth(tensor_shape)</div>
<div class="line"><span class="lineno">  185</span> </div>
<div class="line"><span class="lineno">  186</span>  <span class="keywordflow">if</span> batch_size <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  187</span>    batch_size = tf.shape(tensor)[0]</div>
<div class="line"><span class="lineno">  188</span> </div>
<div class="line"><span class="lineno">  189</span>  <span class="keywordflow">if</span> tensor_height <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  190</span>    tensor_height = tf.shape(tensor)[1]</div>
<div class="line"><span class="lineno">  191</span>    padded_tensor_height = tf.cast(</div>
<div class="line"><span class="lineno">  192</span>        tf.ceil(</div>
<div class="line"><span class="lineno">  193</span>            tf.cast(tensor_height, dtype=tf.float32) /</div>
<div class="line"><span class="lineno">  194</span>            tf.cast(multiple, dtype=tf.float32)),</div>
<div class="line"><span class="lineno">  195</span>        dtype=tf.int32) * multiple</div>
<div class="line"><span class="lineno">  196</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  197</span>    padded_tensor_height = int(</div>
<div class="line"><span class="lineno">  198</span>        math.ceil(float(tensor_height) / multiple) * multiple)</div>
<div class="line"><span class="lineno">  199</span> </div>
<div class="line"><span class="lineno">  200</span>  <span class="keywordflow">if</span> tensor_width <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  201</span>    tensor_width = tf.shape(tensor)[2]</div>
<div class="line"><span class="lineno">  202</span>    padded_tensor_width = tf.cast(</div>
<div class="line"><span class="lineno">  203</span>        tf.ceil(</div>
<div class="line"><span class="lineno">  204</span>            tf.cast(tensor_width, dtype=tf.float32) /</div>
<div class="line"><span class="lineno">  205</span>            tf.cast(multiple, dtype=tf.float32)),</div>
<div class="line"><span class="lineno">  206</span>        dtype=tf.int32) * multiple</div>
<div class="line"><span class="lineno">  207</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  208</span>    padded_tensor_width = int(</div>
<div class="line"><span class="lineno">  209</span>        math.ceil(float(tensor_width) / multiple) * multiple)</div>
<div class="line"><span class="lineno">  210</span> </div>
<div class="line"><span class="lineno">  211</span>  <span class="keywordflow">if</span> tensor_depth <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  212</span>    tensor_depth = tf.shape(tensor)[3]</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>  <span class="comment"># Use tf.concat instead of tf.pad to preserve static shape</span></div>
<div class="line"><span class="lineno">  215</span>  <span class="keywordflow">if</span> padded_tensor_height != tensor_height:</div>
<div class="line"><span class="lineno">  216</span>    height_pad = tf.zeros([</div>
<div class="line"><span class="lineno">  217</span>        batch_size, padded_tensor_height - tensor_height, tensor_width,</div>
<div class="line"><span class="lineno">  218</span>        tensor_depth</div>
<div class="line"><span class="lineno">  219</span>    ])</div>
<div class="line"><span class="lineno">  220</span>    tensor = tf.concat([tensor, height_pad], 1)</div>
<div class="line"><span class="lineno">  221</span>  <span class="keywordflow">if</span> padded_tensor_width != tensor_width:</div>
<div class="line"><span class="lineno">  222</span>    width_pad = tf.zeros([</div>
<div class="line"><span class="lineno">  223</span>        batch_size, padded_tensor_height, padded_tensor_width - tensor_width,</div>
<div class="line"><span class="lineno">  224</span>        tensor_depth</div>
<div class="line"><span class="lineno">  225</span>    ])</div>
<div class="line"><span class="lineno">  226</span>    tensor = tf.concat([tensor, width_pad], 2)</div>
<div class="line"><span class="lineno">  227</span> </div>
<div class="line"><span class="lineno">  228</span>  <span class="keywordflow">return</span> tensor</div>
<div class="line"><span class="lineno">  229</span> </div>
<div class="line"><span class="lineno">  230</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="afe923c1879971de61ca2630119d56287" name="afe923c1879971de61ca2630119d56287"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe923c1879971de61ca2630119d56287">&#9670;&#160;</a></span>padded_one_hot_encoding()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.padded_one_hot_encoding </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>indices</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>depth</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>left_pad</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a zero padded one-hot tensor.

This function converts a sparse representation of indices (e.g., [4]) to a
zero padded one-hot representation (e.g., [0, 0, 0, 0, 1] with depth = 4 and
left_pad = 1). If `indices` is empty, the result will simply be a tensor of
shape (0, depth + left_pad). If depth = 0, then this function just returns
`None`.

Args:
  indices: an integer tensor of shape [num_indices].
  depth: depth for the one-hot tensor (integer).
  left_pad: number of zeros to left pad the one-hot tensor with (integer).

Returns:
  padded_onehot: a tensor with shape (num_indices, depth + left_pad). Returns
    `None` if the depth is zero.

Raises:
  ValueError: if `indices` does not have rank 1 or if `left_pad` or `depth are
    either negative or non-integers.

TODO(rathodv): add runtime checks for depth and indices.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00231">231</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  231</span><span class="keyword">def </span>padded_one_hot_encoding(indices, depth, left_pad):</div>
<div class="line"><span class="lineno">  232</span>  <span class="stringliteral">&quot;&quot;&quot;Returns a zero padded one-hot tensor.</span></div>
<div class="line"><span class="lineno">  233</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  234</span><span class="stringliteral">  This function converts a sparse representation of indices (e.g., [4]) to a</span></div>
<div class="line"><span class="lineno">  235</span><span class="stringliteral">  zero padded one-hot representation (e.g., [0, 0, 0, 0, 1] </span><span class="keyword">with</span> depth = 4 <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  236</span>  left_pad = 1). If `indices` <span class="keywordflow">is</span> empty, the result will simply be a tensor of</div>
<div class="line"><span class="lineno">  237</span>  shape (0, depth + left_pad). If depth = 0, then this function just returns</div>
<div class="line"><span class="lineno">  238</span>  `<span class="keywordtype">None</span>`.</div>
<div class="line"><span class="lineno">  239</span> </div>
<div class="line"><span class="lineno">  240</span>  Args:</div>
<div class="line"><span class="lineno">  241</span>    indices: an integer tensor of shape [num_indices].</div>
<div class="line"><span class="lineno">  242</span>    depth: depth <span class="keywordflow">for</span> the one-hot tensor (integer).</div>
<div class="line"><span class="lineno">  243</span>    left_pad: number of zeros to left pad the one-hot tensor <span class="keyword">with</span> (integer).</div>
<div class="line"><span class="lineno">  244</span> </div>
<div class="line"><span class="lineno">  245</span>  Returns:</div>
<div class="line"><span class="lineno">  246</span>    padded_onehot: a tensor <span class="keyword">with</span> shape (num_indices, depth + left_pad). Returns</div>
<div class="line"><span class="lineno">  247</span>      `<span class="keywordtype">None</span>` <span class="keywordflow">if</span> the depth <span class="keywordflow">is</span> zero.</div>
<div class="line"><span class="lineno">  248</span> </div>
<div class="line"><span class="lineno">  249</span>  Raises:</div>
<div class="line"><span class="lineno">  250</span>    ValueError: <span class="keywordflow">if</span> `indices` does <span class="keywordflow">not</span> have rank 1 <span class="keywordflow">or</span> <span class="keywordflow">if</span> `left_pad` <span class="keywordflow">or</span> `depth are</div>
<div class="line"><span class="lineno">  251</span>      either negative <span class="keywordflow">or</span> non-integers.</div>
<div class="line"><span class="lineno">  252</span> </div>
<div class="line"><span class="lineno">  253</span>  TODO(rathodv): add runtime checks <span class="keywordflow">for</span> depth <span class="keywordflow">and</span> indices.</div>
<div class="line"><span class="lineno">  254</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">  </span><span class="keywordflow">if</span> depth &lt; 0 <span class="keywordflow">or</span> <span class="keywordflow">not</span> isinstance(depth, six.integer_types):</div>
<div class="line"><span class="lineno">  256</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`depth` must be a non-negative integer.&#39;</span>)</div>
<div class="line"><span class="lineno">  257</span>  <span class="keywordflow">if</span> left_pad &lt; 0 <span class="keywordflow">or</span> <span class="keywordflow">not</span> isinstance(left_pad, six.integer_types):</div>
<div class="line"><span class="lineno">  258</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`left_pad` must be a non-negative integer.&#39;</span>)</div>
<div class="line"><span class="lineno">  259</span>  <span class="keywordflow">if</span> depth == 0:</div>
<div class="line"><span class="lineno">  260</span>    <span class="keywordflow">return</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  261</span> </div>
<div class="line"><span class="lineno">  262</span>  rank = len(indices.get_shape().as_list())</div>
<div class="line"><span class="lineno">  263</span>  <span class="keywordflow">if</span> rank != 1:</div>
<div class="line"><span class="lineno">  264</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`indices` must have rank 1, but has rank=%s&#39;</span> % rank)</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>  <span class="keyword">def </span>one_hot_and_pad():</div>
<div class="line"><span class="lineno">  267</span>    one_hot = tf.cast(tf.one_hot(tf.cast(indices, tf.int64), depth,</div>
<div class="line"><span class="lineno">  268</span>                                 on_value=1, off_value=0), tf.float32)</div>
<div class="line"><span class="lineno">  269</span>    <span class="keywordflow">return</span> tf.pad(one_hot, [[0, 0], [left_pad, 0]], mode=<span class="stringliteral">&#39;CONSTANT&#39;</span>)</div>
<div class="line"><span class="lineno">  270</span>  result = tf.cond(tf.greater(tf.size(indices), 0), one_hot_and_pad,</div>
<div class="line"><span class="lineno">  271</span>                   <span class="keyword">lambda</span>: tf.zeros((depth + left_pad, 0)))</div>
<div class="line"><span class="lineno">  272</span>  <span class="keywordflow">return</span> tf.reshape(result, [-1, depth + left_pad])</div>
<div class="line"><span class="lineno">  273</span> </div>
<div class="line"><span class="lineno">  274</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a674b91c79c0575b09d5b79114912a8fa" name="a674b91c79c0575b09d5b79114912a8fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a674b91c79c0575b09d5b79114912a8fa">&#9670;&#160;</a></span>position_sensitive_crop_regions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.position_sensitive_crop_regions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>image</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>crop_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_spatial_bins</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>global_pool</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Position-sensitive crop and pool rectangular regions from a feature grid.

The output crops are split into `spatial_bins_y` vertical bins
and `spatial_bins_x` horizontal bins. For each intersection of a vertical
and a horizontal bin the output values are gathered by performing
`tf.image.crop_and_resize` (bilinear resampling) on a a separate subset of
channels of the image. This reduces `depth` by a factor of
`(spatial_bins_y * spatial_bins_x)`.

When global_pool is True, this function implements a differentiable version
of position-sensitive RoI pooling used in
[R-FCN detection system](https://arxiv.org/abs/1605.06409).

When global_pool is False, this function implements a differentiable version
of position-sensitive assembling operation used in
[instance FCN](https://arxiv.org/abs/1603.08678).

Args:
  image: A `Tensor`. Must be one of the following types: `uint8`, `int8`,
    `int16`, `int32`, `int64`, `half`, `float32`, `float64`.
    A 3-D tensor of shape `[image_height, image_width, depth]`.
    Both `image_height` and `image_width` need to be positive.
  boxes: A `Tensor` of type `float32`.
    A 2-D tensor of shape `[num_boxes, 4]`. Each box is specified in
    normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value
    of `y` is mapped to the image coordinate at `y * (image_height - 1)`, so
    as the `[0, 1]` interval of normalized image height is mapped to
    `[0, image_height - 1] in image height coordinates. We do allow y1 &gt; y2,
    in which case the sampled crop is an up-down flipped version of the
    original image. The width dimension is treated similarly.
  crop_size: A list of two integers `[crop_height, crop_width]`. All
    cropped image patches are resized to this size. The aspect ratio of the
    image content is not preserved. Both `crop_height` and `crop_width` need
    to be positive.
  num_spatial_bins: A list of two integers `[spatial_bins_y, spatial_bins_x]`.
    Represents the number of position-sensitive bins in y and x directions.
    Both values should be &gt;= 1. `crop_height` should be divisible by
    `spatial_bins_y`, and similarly for width.
    The number of image channels should be divisible by
    (spatial_bins_y * spatial_bins_x).
    Suggested value from R-FCN paper: [3, 3].
  global_pool: A boolean variable.
    If True, we perform average global pooling on the features assembled from
      the position-sensitive score maps.
    If False, we keep the position-pooled features without global pooling
      over the spatial coordinates.
    Note that using global_pool=True is equivalent to but more efficient than
      running the function with global_pool=False and then performing global
      average pooling.

Returns:
  position_sensitive_features: A 4-D tensor of shape
    `[num_boxes, K, K, crop_channels]`,
    where `crop_channels = depth / (spatial_bins_y * spatial_bins_x)`,
    where K = 1 when global_pool is True (Average-pooled cropped regions),
    and K = crop_size when global_pool is False.
Raises:
  ValueError: Raised in four situations:
    `num_spatial_bins` is not &gt;= 1;
    `num_spatial_bins` does not divide `crop_size`;
    `(spatial_bins_y*spatial_bins_x)` does not divide `depth`;
    `bin_crop_size` is not square when global_pool=False due to the
      constraint in function space_to_depth.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00652">652</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  656</span>                                    global_pool):</div>
<div class="line"><span class="lineno">  657</span>  <span class="stringliteral">&quot;&quot;&quot;Position-sensitive crop and pool rectangular regions from a feature grid.</span></div>
<div class="line"><span class="lineno">  658</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  659</span><span class="stringliteral">  The output crops are split into `spatial_bins_y` vertical bins</span></div>
<div class="line"><span class="lineno">  660</span><span class="stringliteral">  </span><span class="keywordflow">and</span> `spatial_bins_x` horizontal bins. For each intersection of a vertical</div>
<div class="line"><span class="lineno">  661</span>  <span class="keywordflow">and</span> a horizontal bin the output values are gathered by performing</div>
<div class="line"><span class="lineno">  662</span>  `tf.image.crop_and_resize` (bilinear resampling) on a a separate subset of</div>
<div class="line"><span class="lineno">  663</span>  channels of the image. This reduces `depth` by a factor of</div>
<div class="line"><span class="lineno">  664</span>  `(spatial_bins_y * spatial_bins_x)`.</div>
<div class="line"><span class="lineno">  665</span> </div>
<div class="line"><span class="lineno">  666</span>  When global_pool <span class="keywordflow">is</span> <span class="keyword">True</span>, this function implements a differentiable version</div>
<div class="line"><span class="lineno">  667</span>  of position-sensitive RoI pooling used <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  668</span>  [R-FCN detection system](https://arxiv.org/abs/1605.06409).</div>
<div class="line"><span class="lineno">  669</span> </div>
<div class="line"><span class="lineno">  670</span>  When global_pool <span class="keywordflow">is</span> <span class="keyword">False</span>, this function implements a differentiable version</div>
<div class="line"><span class="lineno">  671</span>  of position-sensitive assembling operation used <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  672</span>  [instance FCN](https://arxiv.org/abs/1603.08678).</div>
<div class="line"><span class="lineno">  673</span> </div>
<div class="line"><span class="lineno">  674</span>  Args:</div>
<div class="line"><span class="lineno">  675</span>    image: A `Tensor`. Must be one of the following types: `uint8`, `int8`,</div>
<div class="line"><span class="lineno">  676</span>      `int16`, `int32`, `int64`, `half`, `float32`, `float64`.</div>
<div class="line"><span class="lineno">  677</span>      A 3-D tensor of shape `[image_height, image_width, depth]`.</div>
<div class="line"><span class="lineno">  678</span>      Both `image_height` <span class="keywordflow">and</span> `image_width` need to be positive.</div>
<div class="line"><span class="lineno">  679</span>    boxes: A `Tensor` of type `float32`.</div>
<div class="line"><span class="lineno">  680</span>      A 2-D tensor of shape `[num_boxes, 4]`. Each box <span class="keywordflow">is</span> specified <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  681</span>      normalized coordinates `[y1, x1, y2, x2]`. A normalized coordinate value</div>
<div class="line"><span class="lineno">  682</span>      of `y` <span class="keywordflow">is</span> mapped to the image coordinate at `y * (image_height - 1)`, so</div>
<div class="line"><span class="lineno">  683</span>      <span class="keyword">as</span> the `[0, 1]` interval of normalized image height <span class="keywordflow">is</span> mapped to</div>
<div class="line"><span class="lineno">  684</span>      `[0, image_height - 1] <span class="keywordflow">in</span> image height coordinates. We do allow y1 &gt; y2,</div>
<div class="line"><span class="lineno">  685</span>      <span class="keywordflow">in</span> which case the sampled crop <span class="keywordflow">is</span> an up-down flipped version of the</div>
<div class="line"><span class="lineno">  686</span>      original image. The width dimension <span class="keywordflow">is</span> treated similarly.</div>
<div class="line"><span class="lineno">  687</span>    crop_size: A list of two integers `[crop_height, crop_width]`. All</div>
<div class="line"><span class="lineno">  688</span>      cropped image patches are resized to this size. The aspect ratio of the</div>
<div class="line"><span class="lineno">  689</span>      image content <span class="keywordflow">is</span> <span class="keywordflow">not</span> preserved. Both `crop_height` <span class="keywordflow">and</span> `crop_width` need</div>
<div class="line"><span class="lineno">  690</span>      to be positive.</div>
<div class="line"><span class="lineno">  691</span>    num_spatial_bins: A list of two integers `[spatial_bins_y, spatial_bins_x]`.</div>
<div class="line"><span class="lineno">  692</span>      Represents the number of position-sensitive bins <span class="keywordflow">in</span> y <span class="keywordflow">and</span> x directions.</div>
<div class="line"><span class="lineno">  693</span>      Both values should be &gt;= 1. `crop_height` should be divisible by</div>
<div class="line"><span class="lineno">  694</span>      `spatial_bins_y`, <span class="keywordflow">and</span> similarly <span class="keywordflow">for</span> width.</div>
<div class="line"><span class="lineno">  695</span>      The number of image channels should be divisible by</div>
<div class="line"><span class="lineno">  696</span>      (spatial_bins_y * spatial_bins_x).</div>
<div class="line"><span class="lineno">  697</span>      Suggested value <span class="keyword">from</span> R-FCN paper: [3, 3].</div>
<div class="line"><span class="lineno">  698</span>    global_pool: A boolean variable.</div>
<div class="line"><span class="lineno">  699</span>      If <span class="keyword">True</span>, we perform average <span class="keyword">global</span> pooling on the features assembled <span class="keyword">from</span></div>
<div class="line"><span class="lineno">  700</span>        the position-sensitive score maps.</div>
<div class="line"><span class="lineno">  701</span>      If <span class="keyword">False</span>, we keep the position-pooled features without <span class="keyword">global</span> pooling</div>
<div class="line"><span class="lineno">  702</span>        over the spatial coordinates.</div>
<div class="line"><span class="lineno">  703</span>      Note that using global_pool=<span class="keyword">True</span> <span class="keywordflow">is</span> equivalent to but more efficient than</div>
<div class="line"><span class="lineno">  704</span>        running the function <span class="keyword">with</span> global_pool=<span class="keyword">False</span> <span class="keywordflow">and</span> then performing <span class="keyword">global</span></div>
<div class="line"><span class="lineno">  705</span>        average pooling.</div>
<div class="line"><span class="lineno">  706</span> </div>
<div class="line"><span class="lineno">  707</span>  Returns:</div>
<div class="line"><span class="lineno">  708</span>    position_sensitive_features: A 4-D tensor of shape</div>
<div class="line"><span class="lineno">  709</span>      `[num_boxes, K, K, crop_channels]`,</div>
<div class="line"><span class="lineno">  710</span>      where `crop_channels = depth / (spatial_bins_y * spatial_bins_x)`,</div>
<div class="line"><span class="lineno">  711</span>      where K = 1 when global_pool <span class="keywordflow">is</span> <span class="keyword">True</span> (Average-pooled cropped regions),</div>
<div class="line"><span class="lineno">  712</span>      <span class="keywordflow">and</span> K = crop_size when global_pool <span class="keywordflow">is</span> <span class="keyword">False</span>.</div>
<div class="line"><span class="lineno">  713</span>  Raises:</div>
<div class="line"><span class="lineno">  714</span>    ValueError: Raised <span class="keywordflow">in</span> four situations:</div>
<div class="line"><span class="lineno">  715</span>      `num_spatial_bins` <span class="keywordflow">is</span> <span class="keywordflow">not</span> &gt;= 1;</div>
<div class="line"><span class="lineno">  716</span>      `num_spatial_bins` does <span class="keywordflow">not</span> divide `crop_size`;</div>
<div class="line"><span class="lineno">  717</span>      `(spatial_bins_y*spatial_bins_x)` does <span class="keywordflow">not</span> divide `depth`;</div>
<div class="line"><span class="lineno">  718</span>      `bin_crop_size` <span class="keywordflow">is</span> <span class="keywordflow">not</span> square when global_pool=<span class="keyword">False</span> due to the</div>
<div class="line"><span class="lineno">  719</span>        constraint <span class="keywordflow">in</span> function space_to_depth.</div>
<div class="line"><span class="lineno">  720</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  721</span><span class="stringliteral">  total_bins = 1</span></div>
<div class="line"><span class="lineno">  722</span><span class="stringliteral">  bin_crop_size = []</span></div>
<div class="line"><span class="lineno">  723</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  724</span><span class="stringliteral">  </span><span class="keywordflow">for</span> (num_bins, crop_dim) <span class="keywordflow">in</span> zip(num_spatial_bins, crop_size):</div>
<div class="line"><span class="lineno">  725</span>    <span class="keywordflow">if</span> num_bins &lt; 1:</div>
<div class="line"><span class="lineno">  726</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;num_spatial_bins should be &gt;= 1&#39;</span>)</div>
<div class="line"><span class="lineno">  727</span> </div>
<div class="line"><span class="lineno">  728</span>    <span class="keywordflow">if</span> crop_dim % num_bins != 0:</div>
<div class="line"><span class="lineno">  729</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;crop_size should be divisible by num_spatial_bins&#39;</span>)</div>
<div class="line"><span class="lineno">  730</span> </div>
<div class="line"><span class="lineno">  731</span>    total_bins *= num_bins</div>
<div class="line"><span class="lineno">  732</span>    bin_crop_size.append(crop_dim // num_bins)</div>
<div class="line"><span class="lineno">  733</span> </div>
<div class="line"><span class="lineno">  734</span>  <span class="keywordflow">if</span> <span class="keywordflow">not</span> global_pool <span class="keywordflow">and</span> bin_crop_size[0] != bin_crop_size[1]:</div>
<div class="line"><span class="lineno">  735</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;Only support square bin crop size for now.&#39;</span>)</div>
<div class="line"><span class="lineno">  736</span> </div>
<div class="line"><span class="lineno">  737</span>  ymin, xmin, ymax, xmax = tf.unstack(boxes, axis=1)</div>
<div class="line"><span class="lineno">  738</span>  spatial_bins_y, spatial_bins_x = num_spatial_bins</div>
<div class="line"><span class="lineno">  739</span> </div>
<div class="line"><span class="lineno">  740</span>  <span class="comment"># Split each box into spatial_bins_y * spatial_bins_x bins.</span></div>
<div class="line"><span class="lineno">  741</span>  position_sensitive_boxes = []</div>
<div class="line"><span class="lineno">  742</span>  <span class="keywordflow">for</span> bin_y <span class="keywordflow">in</span> range(spatial_bins_y):</div>
<div class="line"><span class="lineno">  743</span>    step_y = (ymax - ymin) / spatial_bins_y</div>
<div class="line"><span class="lineno">  744</span>    <span class="keywordflow">for</span> bin_x <span class="keywordflow">in</span> range(spatial_bins_x):</div>
<div class="line"><span class="lineno">  745</span>      step_x = (xmax - xmin) / spatial_bins_x</div>
<div class="line"><span class="lineno">  746</span>      box_coordinates = [ymin + bin_y * step_y,</div>
<div class="line"><span class="lineno">  747</span>                         xmin + bin_x * step_x,</div>
<div class="line"><span class="lineno">  748</span>                         ymin + (bin_y + 1) * step_y,</div>
<div class="line"><span class="lineno">  749</span>                         xmin + (bin_x + 1) * step_x,</div>
<div class="line"><span class="lineno">  750</span>                        ]</div>
<div class="line"><span class="lineno">  751</span>      position_sensitive_boxes.append(tf.stack(box_coordinates, axis=1))</div>
<div class="line"><span class="lineno">  752</span> </div>
<div class="line"><span class="lineno">  753</span>  image_splits = tf.split(value=image, num_or_size_splits=total_bins, axis=2)</div>
<div class="line"><span class="lineno">  754</span> </div>
<div class="line"><span class="lineno">  755</span>  image_crops = []</div>
<div class="line"><span class="lineno">  756</span>  <span class="keywordflow">for</span> (split, box) <span class="keywordflow">in</span> zip(image_splits, position_sensitive_boxes):</div>
<div class="line"><span class="lineno">  757</span>    <span class="keywordflow">if</span> split.shape.is_fully_defined() <span class="keywordflow">and</span> box.shape.is_fully_defined():</div>
<div class="line"><span class="lineno">  758</span>      crop = tf.squeeze(</div>
<div class="line"><span class="lineno">  759</span>          matmul_crop_and_resize(</div>
<div class="line"><span class="lineno">  760</span>              tf.expand_dims(split, axis=0), tf.expand_dims(box, axis=0),</div>
<div class="line"><span class="lineno">  761</span>              bin_crop_size),</div>
<div class="line"><span class="lineno">  762</span>          axis=0)</div>
<div class="line"><span class="lineno">  763</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  764</span>      crop = tf.image.crop_and_resize(</div>
<div class="line"><span class="lineno">  765</span>          tf.expand_dims(split, 0), box,</div>
<div class="line"><span class="lineno">  766</span>          tf.zeros(tf.shape(boxes)[0], dtype=tf.int32), bin_crop_size)</div>
<div class="line"><span class="lineno">  767</span>    image_crops.append(crop)</div>
<div class="line"><span class="lineno">  768</span> </div>
<div class="line"><span class="lineno">  769</span>  <span class="keywordflow">if</span> global_pool:</div>
<div class="line"><span class="lineno">  770</span>    <span class="comment"># Average over all bins.</span></div>
<div class="line"><span class="lineno">  771</span>    position_sensitive_features = tf.add_n(image_crops) / len(image_crops)</div>
<div class="line"><span class="lineno">  772</span>    <span class="comment"># Then average over spatial positions within the bins.</span></div>
<div class="line"><span class="lineno">  773</span>    position_sensitive_features = tf.reduce_mean(</div>
<div class="line"><span class="lineno">  774</span>        position_sensitive_features, [1, 2], keepdims=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  775</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  776</span>    <span class="comment"># Reorder height/width to depth channel.</span></div>
<div class="line"><span class="lineno">  777</span>    block_size = bin_crop_size[0]</div>
<div class="line"><span class="lineno">  778</span>    <span class="keywordflow">if</span> block_size &gt;= 2:</div>
<div class="line"><span class="lineno">  779</span>      image_crops = [tf.space_to_depth(</div>
<div class="line"><span class="lineno">  780</span>          crop, block_size=block_size) <span class="keywordflow">for</span> crop <span class="keywordflow">in</span> image_crops]</div>
<div class="line"><span class="lineno">  781</span> </div>
<div class="line"><span class="lineno">  782</span>    <span class="comment"># Pack image_crops so that first dimension is for position-senstive boxes.</span></div>
<div class="line"><span class="lineno">  783</span>    position_sensitive_features = tf.stack(image_crops, axis=0)</div>
<div class="line"><span class="lineno">  784</span> </div>
<div class="line"><span class="lineno">  785</span>    <span class="comment"># Unroll the position-sensitive boxes to spatial positions.</span></div>
<div class="line"><span class="lineno">  786</span>    position_sensitive_features = tf.squeeze(</div>
<div class="line"><span class="lineno">  787</span>        tf.batch_to_space_nd(position_sensitive_features,</div>
<div class="line"><span class="lineno">  788</span>                             block_shape=[1] + num_spatial_bins,</div>
<div class="line"><span class="lineno">  789</span>                             crops=tf.zeros((3, 2), dtype=tf.int32)),</div>
<div class="line"><span class="lineno">  790</span>        axis=[0])</div>
<div class="line"><span class="lineno">  791</span> </div>
<div class="line"><span class="lineno">  792</span>    <span class="comment"># Reorder back the depth channel.</span></div>
<div class="line"><span class="lineno">  793</span>    <span class="keywordflow">if</span> block_size &gt;= 2:</div>
<div class="line"><span class="lineno">  794</span>      position_sensitive_features = tf.depth_to_space(</div>
<div class="line"><span class="lineno">  795</span>          position_sensitive_features, block_size=block_size)</div>
<div class="line"><span class="lineno">  796</span> </div>
<div class="line"><span class="lineno">  797</span>  <span class="keywordflow">return</span> position_sensitive_features</div>
<div class="line"><span class="lineno">  798</span> </div>
<div class="line"><span class="lineno">  799</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_a674b91c79c0575b09d5b79114912a8fa_icgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_a674b91c79c0575b09d5b79114912a8fa_icgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a674b91c79c0575b09d5b79114912a8fa_icgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_a674b91c79c0575b09d5b79114912a8fa_icgraph">
<area shape="rect" title=" " alt="" coords="265,5,473,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a8dc56974f34bbceff44a4dc9f4dace05" title=" " alt="" coords="5,5,217,45"/>
<area shape="poly" title=" " alt="" coords="252,28,218,28,218,23,252,23"/>
</map>
</div>

</div>
</div>
<a id="a8c5e626e71f1d4e2bf1a4693b1035984" name="a8c5e626e71f1d4e2bf1a4693b1035984"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8c5e626e71f1d4e2bf1a4693b1035984">&#9670;&#160;</a></span>reduce_sum_trailing_dimensions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.reduce_sum_trailing_dimensions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>ndims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Computes sum across all dimensions following first `ndims` dimensions.</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00338">338</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  338</span><span class="keyword">def </span>reduce_sum_trailing_dimensions(tensor, ndims):</div>
<div class="line"><span class="lineno">  339</span>  <span class="stringliteral">&quot;&quot;&quot;Computes sum across all dimensions following first `ndims` dimensions.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  340</span>  <span class="keywordflow">return</span> tf.reduce_sum(tensor, axis=tuple(range(ndims, tensor.shape.ndims)))</div>
<div class="line"><span class="lineno">  341</span> </div>
<div class="line"><span class="lineno">  342</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae862e7f24dbb83f231c678895bfdf766" name="ae862e7f24dbb83f231c678895bfdf766"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae862e7f24dbb83f231c678895bfdf766">&#9670;&#160;</a></span>reframe_box_masks_to_image_masks()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.reframe_box_masks_to_image_masks </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>box_masks</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>image_height</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>image_width</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Transforms the box masks back to full image masks.

Embeds masks in bounding boxes of larger masks whose shapes correspond to
image shape.

Args:
  box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width].
  boxes: A tf.float32 tensor of size [num_masks, 4] containing the box
         corners. Row i contains [ymin, xmin, ymax, xmax] of the box
         corresponding to mask i. Note that the box corners are in
         normalized coordinates.
  image_height: Image height. The output mask will have the same height as
                the image height.
  image_width: Image width. The output mask will have the same width as the
               image width.

Returns:
  A tf.float32 tensor of size [num_masks, image_height, image_width].
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00800">800</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  801</span>                                     image_width):</div>
<div class="line"><span class="lineno">  802</span>  <span class="stringliteral">&quot;&quot;&quot;Transforms the box masks back to full image masks.</span></div>
<div class="line"><span class="lineno">  803</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  804</span><span class="stringliteral">  Embeds masks </span><span class="keywordflow">in</span> bounding boxes of larger masks whose shapes correspond to</div>
<div class="line"><span class="lineno">  805</span>  image shape.</div>
<div class="line"><span class="lineno">  806</span> </div>
<div class="line"><span class="lineno">  807</span>  Args:</div>
<div class="line"><span class="lineno">  808</span>    box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width].</div>
<div class="line"><span class="lineno">  809</span>    boxes: A tf.float32 tensor of size [num_masks, 4] containing the box</div>
<div class="line"><span class="lineno">  810</span>           corners. Row i contains [ymin, xmin, ymax, xmax] of the box</div>
<div class="line"><span class="lineno">  811</span>           corresponding to mask i. Note that the box corners are <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  812</span>           normalized coordinates.</div>
<div class="line"><span class="lineno">  813</span>    image_height: Image height. The output mask will have the same height <span class="keyword">as</span></div>
<div class="line"><span class="lineno">  814</span>                  the image height.</div>
<div class="line"><span class="lineno">  815</span>    image_width: Image width. The output mask will have the same width <span class="keyword">as</span> the</div>
<div class="line"><span class="lineno">  816</span>                 image width.</div>
<div class="line"><span class="lineno">  817</span> </div>
<div class="line"><span class="lineno">  818</span>  Returns:</div>
<div class="line"><span class="lineno">  819</span>    A tf.float32 tensor of size [num_masks, image_height, image_width].</div>
<div class="line"><span class="lineno">  820</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  821</span><span class="stringliteral">  </span><span class="comment"># TODO(rathodv): Make this a public function.</span></div>
<div class="line"><span class="lineno">  822</span>  <span class="keyword">def </span>reframe_box_masks_to_image_masks_default():</div>
<div class="line"><span class="lineno">  823</span>    <span class="stringliteral">&quot;&quot;&quot;The default function when there are more than 0 box masks.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  824</span>    <span class="keyword">def </span>transform_boxes_relative_to_boxes(boxes, reference_boxes):</div>
<div class="line"><span class="lineno">  825</span>      boxes = tf.reshape(boxes, [-1, 2, 2])</div>
<div class="line"><span class="lineno">  826</span>      min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1)</div>
<div class="line"><span class="lineno">  827</span>      max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1)</div>
<div class="line"><span class="lineno">  828</span>      transformed_boxes = (boxes - min_corner) / (max_corner - min_corner)</div>
<div class="line"><span class="lineno">  829</span>      <span class="keywordflow">return</span> tf.reshape(transformed_boxes, [-1, 4])</div>
<div class="line"><span class="lineno">  830</span> </div>
<div class="line"><span class="lineno">  831</span>    box_masks_expanded = tf.expand_dims(box_masks, axis=3)</div>
<div class="line"><span class="lineno">  832</span>    num_boxes = tf.shape(box_masks_expanded)[0]</div>
<div class="line"><span class="lineno">  833</span>    unit_boxes = tf.concat(</div>
<div class="line"><span class="lineno">  834</span>        [tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1)</div>
<div class="line"><span class="lineno">  835</span>    reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes)</div>
<div class="line"><span class="lineno">  836</span>    <span class="keywordflow">return</span> tf.image.crop_and_resize(</div>
<div class="line"><span class="lineno">  837</span>        image=box_masks_expanded,</div>
<div class="line"><span class="lineno">  838</span>        boxes=reverse_boxes,</div>
<div class="line"><span class="lineno">  839</span>        box_ind=tf.range(num_boxes),</div>
<div class="line"><span class="lineno">  840</span>        crop_size=[image_height, image_width],</div>
<div class="line"><span class="lineno">  841</span>        extrapolation_value=0.0)</div>
<div class="line"><span class="lineno">  842</span>  image_masks = tf.cond(</div>
<div class="line"><span class="lineno">  843</span>      tf.shape(box_masks)[0] &gt; 0,</div>
<div class="line"><span class="lineno">  844</span>      reframe_box_masks_to_image_masks_default,</div>
<div class="line"><span class="lineno">  845</span>      <span class="keyword">lambda</span>: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32))</div>
<div class="line"><span class="lineno">  846</span>  <span class="keywordflow">return</span> tf.squeeze(image_masks, axis=3)</div>
<div class="line"><span class="lineno">  847</span> </div>
<div class="line"><span class="lineno">  848</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae9ea79fd4a604caa7430abce7d10bcef" name="ae9ea79fd4a604caa7430abce7d10bcef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9ea79fd4a604caa7430abce7d10bcef">&#9670;&#160;</a></span>replace_nan_groundtruth_label_scores_with_ones()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.replace_nan_groundtruth_label_scores_with_ones </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>label_scores</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Replaces nan label scores with 1.0.

Args:
  label_scores: a tensor containing object annoation label scores.

Returns:
  a tensor where NaN label scores have been replaced by ones.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00432">432</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  432</span><span class="keyword">def </span>replace_nan_groundtruth_label_scores_with_ones(label_scores):</div>
<div class="line"><span class="lineno">  433</span>  <span class="stringliteral">&quot;&quot;&quot;Replaces nan label scores with 1.0.</span></div>
<div class="line"><span class="lineno">  434</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  435</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  436</span><span class="stringliteral">    label_scores: a tensor containing object annoation label scores.</span></div>
<div class="line"><span class="lineno">  437</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">    a tensor where NaN label scores have been replaced by ones.</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">  &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">  </span><span class="keywordflow">return</span> tf.where(</div>
<div class="line"><span class="lineno">  442</span>      tf.is_nan(label_scores), tf.ones(tf.shape(label_scores)), label_scores)</div>
<div class="line"><span class="lineno">  443</span> </div>
<div class="line"><span class="lineno">  444</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af4c44e343c3cb222937eb3e496ce68e6" name="af4c44e343c3cb222937eb3e496ce68e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af4c44e343c3cb222937eb3e496ce68e6">&#9670;&#160;</a></span>retain_groundtruth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.retain_groundtruth </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_dict</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>valid_indices</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Retains groundtruth by valid indices.

Args:
  tensor_dict: a dictionary of following groundtruth tensors -
    fields.InputDataFields.groundtruth_boxes
    fields.InputDataFields.groundtruth_classes
    fields.InputDataFields.groundtruth_confidences
    fields.InputDataFields.groundtruth_keypoints
    fields.InputDataFields.groundtruth_instance_masks
    fields.InputDataFields.groundtruth_is_crowd
    fields.InputDataFields.groundtruth_area
    fields.InputDataFields.groundtruth_label_types
    fields.InputDataFields.groundtruth_difficult
  valid_indices: a tensor with valid indices for the box-level groundtruth.

Returns:
  a dictionary of tensors containing only the groundtruth for valid_indices.

Raises:
  ValueError: If the shape of valid_indices is invalid.
  ValueError: field fields.InputDataFields.groundtruth_boxes is
    not present in tensor_dict.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00343">343</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  343</span><span class="keyword">def </span>retain_groundtruth(tensor_dict, valid_indices):</div>
<div class="line"><span class="lineno">  344</span>  <span class="stringliteral">&quot;&quot;&quot;Retains groundtruth by valid indices.</span></div>
<div class="line"><span class="lineno">  345</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  347</span><span class="stringliteral">    tensor_dict: a dictionary of following groundtruth tensors -</span></div>
<div class="line"><span class="lineno">  348</span><span class="stringliteral">      fields.InputDataFields.groundtruth_boxes</span></div>
<div class="line"><span class="lineno">  349</span><span class="stringliteral">      fields.InputDataFields.groundtruth_classes</span></div>
<div class="line"><span class="lineno">  350</span><span class="stringliteral">      fields.InputDataFields.groundtruth_confidences</span></div>
<div class="line"><span class="lineno">  351</span><span class="stringliteral">      fields.InputDataFields.groundtruth_keypoints</span></div>
<div class="line"><span class="lineno">  352</span><span class="stringliteral">      fields.InputDataFields.groundtruth_instance_masks</span></div>
<div class="line"><span class="lineno">  353</span><span class="stringliteral">      fields.InputDataFields.groundtruth_is_crowd</span></div>
<div class="line"><span class="lineno">  354</span><span class="stringliteral">      fields.InputDataFields.groundtruth_area</span></div>
<div class="line"><span class="lineno">  355</span><span class="stringliteral">      fields.InputDataFields.groundtruth_label_types</span></div>
<div class="line"><span class="lineno">  356</span><span class="stringliteral">      fields.InputDataFields.groundtruth_difficult</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral">    valid_indices: a tensor </span><span class="keyword">with</span> valid indices <span class="keywordflow">for</span> the box-level groundtruth.</div>
<div class="line"><span class="lineno">  358</span> </div>
<div class="line"><span class="lineno">  359</span>  Returns:</div>
<div class="line"><span class="lineno">  360</span>    a dictionary of tensors containing only the groundtruth <span class="keywordflow">for</span> valid_indices.</div>
<div class="line"><span class="lineno">  361</span> </div>
<div class="line"><span class="lineno">  362</span>  Raises:</div>
<div class="line"><span class="lineno">  363</span>    ValueError: If the shape of valid_indices <span class="keywordflow">is</span> invalid.</div>
<div class="line"><span class="lineno">  364</span>    ValueError: field fields.InputDataFields.groundtruth_boxes <span class="keywordflow">is</span></div>
<div class="line"><span class="lineno">  365</span>      <span class="keywordflow">not</span> present <span class="keywordflow">in</span> tensor_dict.</div>
<div class="line"><span class="lineno">  366</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral">  input_shape = valid_indices.get_shape().as_list()</span></div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">  </span><span class="keywordflow">if</span> <span class="keywordflow">not</span> (len(input_shape) == 1 <span class="keywordflow">or</span></div>
<div class="line"><span class="lineno">  369</span>          (len(input_shape) == 2 <span class="keywordflow">and</span> input_shape[1] == 1)):</div>
<div class="line"><span class="lineno">  370</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;The shape of valid_indices is invalid.&#39;</span>)</div>
<div class="line"><span class="lineno">  371</span>  valid_indices = tf.reshape(valid_indices, [-1])</div>
<div class="line"><span class="lineno">  372</span>  valid_dict = {}</div>
<div class="line"><span class="lineno">  373</span>  <span class="keywordflow">if</span> fields.InputDataFields.groundtruth_boxes <span class="keywordflow">in</span> tensor_dict:</div>
<div class="line"><span class="lineno">  374</span>    <span class="comment"># Prevents reshape failure when num_boxes is 0.</span></div>
<div class="line"><span class="lineno">  375</span>    num_boxes = tf.maximum(tf.shape(</div>
<div class="line"><span class="lineno">  376</span>        tensor_dict[fields.InputDataFields.groundtruth_boxes])[0], 1)</div>
<div class="line"><span class="lineno">  377</span>    <span class="keywordflow">for</span> key <span class="keywordflow">in</span> tensor_dict:</div>
<div class="line"><span class="lineno">  378</span>      <span class="keywordflow">if</span> key <span class="keywordflow">in</span> [fields.InputDataFields.groundtruth_boxes,</div>
<div class="line"><span class="lineno">  379</span>                 fields.InputDataFields.groundtruth_classes,</div>
<div class="line"><span class="lineno">  380</span>                 fields.InputDataFields.groundtruth_confidences,</div>
<div class="line"><span class="lineno">  381</span>                 fields.InputDataFields.groundtruth_keypoints,</div>
<div class="line"><span class="lineno">  382</span>                 fields.InputDataFields.groundtruth_keypoint_visibilities,</div>
<div class="line"><span class="lineno">  383</span>                 fields.InputDataFields.groundtruth_instance_masks]:</div>
<div class="line"><span class="lineno">  384</span>        valid_dict[key] = tf.gather(tensor_dict[key], valid_indices)</div>
<div class="line"><span class="lineno">  385</span>      <span class="comment"># Input decoder returns empty tensor when these fields are not provided.</span></div>
<div class="line"><span class="lineno">  386</span>      <span class="comment"># Needs to reshape into [num_boxes, -1] for tf.gather() to work.</span></div>
<div class="line"><span class="lineno">  387</span>      <span class="keywordflow">elif</span> key <span class="keywordflow">in</span> [fields.InputDataFields.groundtruth_is_crowd,</div>
<div class="line"><span class="lineno">  388</span>                   fields.InputDataFields.groundtruth_area,</div>
<div class="line"><span class="lineno">  389</span>                   fields.InputDataFields.groundtruth_difficult,</div>
<div class="line"><span class="lineno">  390</span>                   fields.InputDataFields.groundtruth_label_types]:</div>
<div class="line"><span class="lineno">  391</span>        valid_dict[key] = tf.reshape(</div>
<div class="line"><span class="lineno">  392</span>            tf.gather(tf.reshape(tensor_dict[key], [num_boxes, -1]),</div>
<div class="line"><span class="lineno">  393</span>                      valid_indices), [-1])</div>
<div class="line"><span class="lineno">  394</span>      <span class="comment"># Fields that are not associated with boxes.</span></div>
<div class="line"><span class="lineno">  395</span>      <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  396</span>        valid_dict[key] = tensor_dict[key]</div>
<div class="line"><span class="lineno">  397</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  398</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;%s not present in input tensor dict.&#39;</span> % (</div>
<div class="line"><span class="lineno">  399</span>        fields.InputDataFields.groundtruth_boxes))</div>
<div class="line"><span class="lineno">  400</span>  <span class="keywordflow">return</span> valid_dict</div>
<div class="line"><span class="lineno">  401</span> </div>
<div class="line"><span class="lineno">  402</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_af4c44e343c3cb222937eb3e496ce68e6_icgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_af4c44e343c3cb222937eb3e496ce68e6_icgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_af4c44e343c3cb222937eb3e496ce68e6_icgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_af4c44e343c3cb222937eb3e496ce68e6_icgraph">
<area shape="rect" title=" " alt="" coords="308,101,503,141"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a14259559c91fbe3753ef93fd614eebd8" title=" " alt="" coords="29,5,236,45"/>
<area shape="poly" title=" " alt="" coords="350,98,259,60,220,48,222,43,261,55,353,93"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a9caa9fbd25912b008f9dfbe9ca636567" title=" " alt="" coords="5,69,260,109"/>
<area shape="poly" title=" " alt="" coords="294,111,260,107,260,102,294,106"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#a391c9d74117ad32ba170f1df7be9efc9" title=" " alt="" coords="39,133,226,173"/>
<area shape="poly" title=" " alt="" coords="294,137,227,145,226,140,294,132"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#ae6ecd4d38671df8c284d9a856f1d603f" title=" " alt="" coords="19,197,246,237"/>
<area shape="poly" title=" " alt="" coords="353,150,261,188,222,200,220,195,259,183,350,145"/>
</map>
</div>

</div>
</div>
<a id="ae6ecd4d38671df8c284d9a856f1d603f" name="ae6ecd4d38671df8c284d9a856f1d603f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae6ecd4d38671df8c284d9a856f1d603f">&#9670;&#160;</a></span>retain_groundtruth_with_positive_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.retain_groundtruth_with_positive_classes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor_dict</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Retains only groundtruth with positive class ids.

Args:
  tensor_dict: a dictionary of following groundtruth tensors -
    fields.InputDataFields.groundtruth_boxes
    fields.InputDataFields.groundtruth_classes
    fields.InputDataFields.groundtruth_confidences
    fields.InputDataFields.groundtruth_keypoints
    fields.InputDataFields.groundtruth_instance_masks
    fields.InputDataFields.groundtruth_is_crowd
    fields.InputDataFields.groundtruth_area
    fields.InputDataFields.groundtruth_label_types
    fields.InputDataFields.groundtruth_difficult

Returns:
  a dictionary of tensors containing only the groundtruth with positive
  classes.

Raises:
  ValueError: If groundtruth_classes tensor is not in tensor_dict.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00403">403</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  403</span><span class="keyword">def </span>retain_groundtruth_with_positive_classes(tensor_dict):</div>
<div class="line"><span class="lineno">  404</span>  <span class="stringliteral">&quot;&quot;&quot;Retains only groundtruth with positive class ids.</span></div>
<div class="line"><span class="lineno">  405</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  406</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral">    tensor_dict: a dictionary of following groundtruth tensors -</span></div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">      fields.InputDataFields.groundtruth_boxes</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">      fields.InputDataFields.groundtruth_classes</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">      fields.InputDataFields.groundtruth_confidences</span></div>
<div class="line"><span class="lineno">  411</span><span class="stringliteral">      fields.InputDataFields.groundtruth_keypoints</span></div>
<div class="line"><span class="lineno">  412</span><span class="stringliteral">      fields.InputDataFields.groundtruth_instance_masks</span></div>
<div class="line"><span class="lineno">  413</span><span class="stringliteral">      fields.InputDataFields.groundtruth_is_crowd</span></div>
<div class="line"><span class="lineno">  414</span><span class="stringliteral">      fields.InputDataFields.groundtruth_area</span></div>
<div class="line"><span class="lineno">  415</span><span class="stringliteral">      fields.InputDataFields.groundtruth_label_types</span></div>
<div class="line"><span class="lineno">  416</span><span class="stringliteral">      fields.InputDataFields.groundtruth_difficult</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">  419</span><span class="stringliteral">    a dictionary of tensors containing only the groundtruth </span><span class="keyword">with</span> positive</div>
<div class="line"><span class="lineno">  420</span>    classes.</div>
<div class="line"><span class="lineno">  421</span> </div>
<div class="line"><span class="lineno">  422</span>  Raises:</div>
<div class="line"><span class="lineno">  423</span>    ValueError: If groundtruth_classes tensor <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordflow">in</span> tensor_dict.</div>
<div class="line"><span class="lineno">  424</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  425</span><span class="stringliteral">  </span><span class="keywordflow">if</span> fields.InputDataFields.groundtruth_classes <span class="keywordflow">not</span> <span class="keywordflow">in</span> tensor_dict:</div>
<div class="line"><span class="lineno">  426</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`groundtruth classes` not in tensor_dict.&#39;</span>)</div>
<div class="line"><span class="lineno">  427</span>  keep_indices = tf.where(tf.greater(</div>
<div class="line"><span class="lineno">  428</span>      tensor_dict[fields.InputDataFields.groundtruth_classes], 0))</div>
<div class="line"><span class="lineno">  429</span>  <span class="keywordflow">return</span> retain_groundtruth(tensor_dict, keep_indices)</div>
<div class="line"><span class="lineno">  430</span> </div>
<div class="line"><span class="lineno">  431</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../db/d47/namespacedetection__utils_1_1utils_1_1ops_ae6ecd4d38671df8c284d9a856f1d603f_cgraph.png" border="0" usemap="#adb/d47/namespacedetection__utils_1_1utils_1_1ops_ae6ecd4d38671df8c284d9a856f1d603f_cgraph" alt=""/></div>
<map name="adb/d47/namespacedetection__utils_1_1utils_1_1ops_ae6ecd4d38671df8c284d9a856f1d603f_cgraph" id="adb/d47/namespacedetection__utils_1_1utils_1_1ops_ae6ecd4d38671df8c284d9a856f1d603f_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,232,45"/>
<area shape="rect" href="../../db/d47/namespacedetection__utils_1_1utils_1_1ops.html#af4c44e343c3cb222937eb3e496ce68e6" title=" " alt="" coords="280,5,475,45"/>
<area shape="poly" title=" " alt="" coords="232,23,266,23,266,28,232,28"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a82ed092503588fcc71b43646a1100dac" name="a82ed092503588fcc71b43646a1100dac"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a82ed092503588fcc71b43646a1100dac">&#9670;&#160;</a></span>EqualizationLossConfig</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.EqualizationLossConfig</td>
        </tr>
      </table>
</div><div class="memdoc">
<b>Initial value:</b><div class="fragment"><div class="line"><span class="lineno">    1</span>=  collections.namedtuple(<span class="stringliteral">&#39;EqualizationLossConfig&#39;</span>,</div>
<div class="line"><span class="lineno">    2</span>                                                [<span class="stringliteral">&#39;weight&#39;</span>, <span class="stringliteral">&#39;exclude_prefixes&#39;</span>])</div>
</div><!-- fragment -->
<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l01093">1093</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>

</div>
</div>
<a id="a33f64e9ecb63a23af0c998ebb402c533" name="a33f64e9ecb63a23af0c998ebb402c533"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a33f64e9ecb63a23af0c998ebb402c533">&#9670;&#160;</a></span>matmul_crop_and_resize</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.matmul_crop_and_resize = spatial_ops.matmul_crop_and_resize</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00035">35</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>

</div>
</div>
<a id="af020a014cef7a2230e195b6b6a02e88f" name="af020a014cef7a2230e195b6b6a02e88f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af020a014cef7a2230e195b6b6a02e88f">&#9670;&#160;</a></span>multilevel_roi_align</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.multilevel_roi_align = spatial_ops.multilevel_roi_align</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00036">36</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>

</div>
</div>
<a id="a3c7872f0750bfae89334d4e6073caabf" name="a3c7872f0750bfae89334d4e6073caabf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c7872f0750bfae89334d4e6073caabf">&#9670;&#160;</a></span>native_crop_and_resize</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.ops.native_crop_and_resize = spatial_ops.native_crop_and_resize</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../dd/d65/ops_8py_source.html#l00037">37</a> of file <a class="el" href="../../dd/d65/ops_8py_source.html">ops.py</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
