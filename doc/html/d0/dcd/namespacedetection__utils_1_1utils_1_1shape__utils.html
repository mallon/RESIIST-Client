<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RESIIST: detection_utils.utils.shape_utils Namespace Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">RESIIST
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d8/d97/namespacedetection__utils.html">detection_utils</a></li><li class="navelem"><a class="el" href="../../d5/d2b/namespacedetection__utils_1_1utils.html">utils</a></li><li class="navelem"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html">shape_utils</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle"><div class="title">detection_utils.utils.shape_utils Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a40cccc95c5977459bd034bc0a18ddf28"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a40cccc95c5977459bd034bc0a18ddf28">_is_tensor</a> (t)</td></tr>
<tr class="separator:a40cccc95c5977459bd034bc0a18ddf28"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9495102c38b0c97f6e5ef53f4e8948c9"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a9495102c38b0c97f6e5ef53f4e8948c9">_set_dim_0</a> (t, d0)</td></tr>
<tr class="separator:a9495102c38b0c97f6e5ef53f4e8948c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43f88839ad82816f16c5dfc9a80fde17"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a43f88839ad82816f16c5dfc9a80fde17">pad_tensor</a> (t, length)</td></tr>
<tr class="separator:a43f88839ad82816f16c5dfc9a80fde17"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a961e10f2d22914e41c721971f98670fd"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a961e10f2d22914e41c721971f98670fd">clip_tensor</a> (t, length)</td></tr>
<tr class="separator:a961e10f2d22914e41c721971f98670fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae0526aa315e20a9497646fcf174bc259"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ae0526aa315e20a9497646fcf174bc259">pad_or_clip_tensor</a> (t, length)</td></tr>
<tr class="separator:ae0526aa315e20a9497646fcf174bc259"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a972697b6b4ab2bfdd42fe3013a28fa47"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a972697b6b4ab2bfdd42fe3013a28fa47">pad_or_clip_nd</a> (tensor, output_shape)</td></tr>
<tr class="separator:a972697b6b4ab2bfdd42fe3013a28fa47"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2716d6d75b6e5d892f11298d31dbd226"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a2716d6d75b6e5d892f11298d31dbd226">combined_static_and_dynamic_shape</a> (tensor)</td></tr>
<tr class="separator:a2716d6d75b6e5d892f11298d31dbd226"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adbdc407bf10ad7dc672f5ac1ae2404c1"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#adbdc407bf10ad7dc672f5ac1ae2404c1">static_or_dynamic_map_fn</a> (fn, elems, dtype=None, parallel_iterations=32, back_prop=True)</td></tr>
<tr class="separator:adbdc407bf10ad7dc672f5ac1ae2404c1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ea44d81f5ae2db5c0cbe745f0b2be12"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a0ea44d81f5ae2db5c0cbe745f0b2be12">check_min_image_dim</a> (min_dim, image_tensor)</td></tr>
<tr class="separator:a0ea44d81f5ae2db5c0cbe745f0b2be12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2f267cce441a3d8f39062fe394ea4324"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a2f267cce441a3d8f39062fe394ea4324">assert_shape_equal</a> (shape_a, shape_b)</td></tr>
<tr class="separator:a2f267cce441a3d8f39062fe394ea4324"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac0ee78b7cd7535a2604b585f6067b07a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ac0ee78b7cd7535a2604b585f6067b07a">assert_shape_equal_along_first_dimension</a> (shape_a, shape_b)</td></tr>
<tr class="separator:ac0ee78b7cd7535a2604b585f6067b07a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aec335b009bd21b97b82c51d993591424"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#aec335b009bd21b97b82c51d993591424">assert_box_normalized</a> (boxes, maximum_normalized_coordinate=1.1)</td></tr>
<tr class="separator:aec335b009bd21b97b82c51d993591424"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5ef07eddf0a0dff4b0c84c4ff23426e7"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a5ef07eddf0a0dff4b0c84c4ff23426e7">flatten_dimensions</a> (inputs, first, last)</td></tr>
<tr class="separator:a5ef07eddf0a0dff4b0c84c4ff23426e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad2d28655bc7c097813412148740044f5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ad2d28655bc7c097813412148740044f5">flatten_first_n_dimensions</a> (inputs, n)</td></tr>
<tr class="separator:ad2d28655bc7c097813412148740044f5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae9b0d9bf4014378f0008105db0fc066b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ae9b0d9bf4014378f0008105db0fc066b">expand_first_dimension</a> (inputs, dims)</td></tr>
<tr class="separator:ae9b0d9bf4014378f0008105db0fc066b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="var-members" name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:a4242130317b726719d430d77b294373c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a4242130317b726719d430d77b294373c">get_dim_as_int</a> = static_shape.get_dim_as_int</td></tr>
<tr class="separator:a4242130317b726719d430d77b294373c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Utils used to manipulate tensor shapes.</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="a40cccc95c5977459bd034bc0a18ddf28" name="a40cccc95c5977459bd034bc0a18ddf28"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a40cccc95c5977459bd034bc0a18ddf28">&#9670;&#160;</a></span>_is_tensor()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils._is_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Returns a boolean indicating whether the input is a tensor.

Args:
  t: the input to be tested.

Returns:
  a boolean that indicates whether t is a tensor.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00031">31</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   31</span><span class="keyword">def </span>_is_tensor(t):</div>
<div class="line"><span class="lineno">   32</span>  <span class="stringliteral">&quot;&quot;&quot;Returns a boolean indicating whether the input is a tensor.</span></div>
<div class="line"><span class="lineno">   33</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   34</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">   35</span><span class="stringliteral">    t: the input to be tested.</span></div>
<div class="line"><span class="lineno">   36</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   37</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">   38</span><span class="stringliteral">    a boolean that indicates whether t </span><span class="keywordflow">is</span> a tensor.</div>
<div class="line"><span class="lineno">   39</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   40</span><span class="stringliteral">  </span><span class="keywordflow">return</span> isinstance(t, (tf.Tensor, tf.SparseTensor, tf.Variable))</div>
<div class="line"><span class="lineno">   41</span> </div>
<div class="line"><span class="lineno">   42</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a40cccc95c5977459bd034bc0a18ddf28_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a40cccc95c5977459bd034bc0a18ddf28_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a40cccc95c5977459bd034bc0a18ddf28_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a40cccc95c5977459bd034bc0a18ddf28_icgraph">
<area shape="rect" title=" " alt="" coords="227,37,400,77"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a961e10f2d22914e41c721971f98670fd" title=" " alt="" coords="5,5,179,45"/>
<area shape="poly" title=" " alt="" coords="213,45,178,40,179,35,213,40"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a43f88839ad82816f16c5dfc9a80fde17" title=" " alt="" coords="5,69,179,109"/>
<area shape="poly" title=" " alt="" coords="213,74,179,79,178,74,213,69"/>
</map>
</div>

</div>
</div>
<a id="a9495102c38b0c97f6e5ef53f4e8948c9" name="a9495102c38b0c97f6e5ef53f4e8948c9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9495102c38b0c97f6e5ef53f4e8948c9">&#9670;&#160;</a></span>_set_dim_0()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils._set_dim_0 </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>d0</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Sets the 0-th dimension of the input tensor.

Args:
  t: the input tensor, assuming the rank is at least 1.
  d0: an integer indicating the 0-th dimension of the input tensor.

Returns:
  the tensor t with the 0-th dimension set.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00043">43</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   43</span><span class="keyword">def </span>_set_dim_0(t, d0):</div>
<div class="line"><span class="lineno">   44</span>  <span class="stringliteral">&quot;&quot;&quot;Sets the 0-th dimension of the input tensor.</span></div>
<div class="line"><span class="lineno">   45</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   46</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">   47</span><span class="stringliteral">    t: the input tensor, assuming the rank </span><span class="keywordflow">is</span> at least 1.</div>
<div class="line"><span class="lineno">   48</span>    d0: an integer indicating the 0-th dimension of the input tensor.</div>
<div class="line"><span class="lineno">   49</span> </div>
<div class="line"><span class="lineno">   50</span>  Returns:</div>
<div class="line"><span class="lineno">   51</span>    the tensor t <span class="keyword">with</span> the 0-th dimension set.</div>
<div class="line"><span class="lineno">   52</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   53</span><span class="stringliteral">  t_shape = t.get_shape().as_list()</span></div>
<div class="line"><span class="lineno">   54</span><span class="stringliteral">  t_shape[0] = d0</span></div>
<div class="line"><span class="lineno">   55</span><span class="stringliteral">  t.set_shape(t_shape)</span></div>
<div class="line"><span class="lineno">   56</span><span class="stringliteral">  </span><span class="keywordflow">return</span> t</div>
<div class="line"><span class="lineno">   57</span> </div>
<div class="line"><span class="lineno">   58</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a9495102c38b0c97f6e5ef53f4e8948c9_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a9495102c38b0c97f6e5ef53f4e8948c9_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a9495102c38b0c97f6e5ef53f4e8948c9_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a9495102c38b0c97f6e5ef53f4e8948c9_icgraph">
<area shape="rect" title=" " alt="" coords="227,37,400,77"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a961e10f2d22914e41c721971f98670fd" title=" " alt="" coords="5,5,179,45"/>
<area shape="poly" title=" " alt="" coords="213,45,178,40,179,35,213,40"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a43f88839ad82816f16c5dfc9a80fde17" title=" " alt="" coords="5,69,179,109"/>
<area shape="poly" title=" " alt="" coords="213,74,179,79,178,74,213,69"/>
</map>
</div>

</div>
</div>
<a id="aec335b009bd21b97b82c51d993591424" name="aec335b009bd21b97b82c51d993591424"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aec335b009bd21b97b82c51d993591424">&#9670;&#160;</a></span>assert_box_normalized()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.assert_box_normalized </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>boxes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>maximum_normalized_coordinate</em> = <code>1.1</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asserts the input box tensor is normalized.

Args:
  boxes: a tensor of shape [N, 4] where N is the number of boxes.
  maximum_normalized_coordinate: Maximum coordinate value to be considered
    as normalized, default to 1.1.

Returns:
  a tf.Assert op which fails when the input box tensor is not normalized.

Raises:
  ValueError: When the input box tensor is not normalized.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00355">355</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  355</span><span class="keyword">def </span>assert_box_normalized(boxes, maximum_normalized_coordinate=1.1):</div>
<div class="line"><span class="lineno">  356</span>  <span class="stringliteral">&quot;&quot;&quot;Asserts the input box tensor is normalized.</span></div>
<div class="line"><span class="lineno">  357</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  358</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  359</span><span class="stringliteral">    boxes: a tensor of shape [N, 4] where N </span><span class="keywordflow">is</span> the number of boxes.</div>
<div class="line"><span class="lineno">  360</span>    maximum_normalized_coordinate: Maximum coordinate value to be considered</div>
<div class="line"><span class="lineno">  361</span>      <span class="keyword">as</span> normalized, default to 1.1.</div>
<div class="line"><span class="lineno">  362</span> </div>
<div class="line"><span class="lineno">  363</span>  Returns:</div>
<div class="line"><span class="lineno">  364</span>    a tf.Assert op which fails when the input box tensor <span class="keywordflow">is</span> <span class="keywordflow">not</span> normalized.</div>
<div class="line"><span class="lineno">  365</span> </div>
<div class="line"><span class="lineno">  366</span>  Raises:</div>
<div class="line"><span class="lineno">  367</span>    ValueError: When the input box tensor <span class="keywordflow">is</span> <span class="keywordflow">not</span> normalized.</div>
<div class="line"><span class="lineno">  368</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  369</span><span class="stringliteral">  box_minimum = tf.reduce_min(boxes)</span></div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">  box_maximum = tf.reduce_max(boxes)</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral">  </span><span class="keywordflow">return</span> tf.Assert(</div>
<div class="line"><span class="lineno">  372</span>      tf.logical_and(</div>
<div class="line"><span class="lineno">  373</span>          tf.less_equal(box_maximum, maximum_normalized_coordinate),</div>
<div class="line"><span class="lineno">  374</span>          tf.greater_equal(box_minimum, 0)),</div>
<div class="line"><span class="lineno">  375</span>      [boxes])</div>
<div class="line"><span class="lineno">  376</span> </div>
<div class="line"><span class="lineno">  377</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2f267cce441a3d8f39062fe394ea4324" name="a2f267cce441a3d8f39062fe394ea4324"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2f267cce441a3d8f39062fe394ea4324">&#9670;&#160;</a></span>assert_shape_equal()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.assert_shape_equal </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape_a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape_b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asserts that shape_a and shape_b are equal.

If the shapes are static, raises a ValueError when the shapes
mismatch.

If the shapes are dynamic, raises a tf InvalidArgumentError when the shapes
mismatch.

Args:
  shape_a: a list containing shape of the first tensor.
  shape_b: a list containing shape of the second tensor.

Returns:
  Either a tf.no_op() when shapes are all static and a tf.assert_equal() op
  when the shapes are dynamic.

Raises:
  ValueError: When shapes are both static and unequal.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00297">297</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  297</span><span class="keyword">def </span>assert_shape_equal(shape_a, shape_b):</div>
<div class="line"><span class="lineno">  298</span>  <span class="stringliteral">&quot;&quot;&quot;Asserts that shape_a and shape_b are equal.</span></div>
<div class="line"><span class="lineno">  299</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  300</span><span class="stringliteral">  If the shapes are static, raises a ValueError when the shapes</span></div>
<div class="line"><span class="lineno">  301</span><span class="stringliteral">  mismatch.</span></div>
<div class="line"><span class="lineno">  302</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  303</span><span class="stringliteral">  If the shapes are dynamic, raises a tf InvalidArgumentError when the shapes</span></div>
<div class="line"><span class="lineno">  304</span><span class="stringliteral">  mismatch.</span></div>
<div class="line"><span class="lineno">  305</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    shape_a: a list containing shape of the first tensor.</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">    shape_b: a list containing shape of the second tensor.</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  310</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">  311</span><span class="stringliteral">    Either a tf.no_op() when shapes are all static </span><span class="keywordflow">and</span> a tf.assert_equal() op</div>
<div class="line"><span class="lineno">  312</span>    when the shapes are dynamic.</div>
<div class="line"><span class="lineno">  313</span> </div>
<div class="line"><span class="lineno">  314</span>  Raises:</div>
<div class="line"><span class="lineno">  315</span>    ValueError: When shapes are both static <span class="keywordflow">and</span> unequal.</div>
<div class="line"><span class="lineno">  316</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  317</span><span class="stringliteral">  </span><span class="keywordflow">if</span> (all(isinstance(dim, int) <span class="keywordflow">for</span> dim <span class="keywordflow">in</span> shape_a) <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  318</span>      all(isinstance(dim, int) <span class="keywordflow">for</span> dim <span class="keywordflow">in</span> shape_b)):</div>
<div class="line"><span class="lineno">  319</span>    <span class="keywordflow">if</span> shape_a != shape_b:</div>
<div class="line"><span class="lineno">  320</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;Unequal shapes {}, {}&#39;</span>.format(shape_a, shape_b))</div>
<div class="line"><span class="lineno">  321</span>    <span class="keywordflow">else</span>: <span class="keywordflow">return</span> tf.no_op()</div>
<div class="line"><span class="lineno">  322</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  323</span>    <span class="keywordflow">return</span> tf.assert_equal(shape_a, shape_b)</div>
<div class="line"><span class="lineno">  324</span> </div>
<div class="line"><span class="lineno">  325</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ac0ee78b7cd7535a2604b585f6067b07a" name="ac0ee78b7cd7535a2604b585f6067b07a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac0ee78b7cd7535a2604b585f6067b07a">&#9670;&#160;</a></span>assert_shape_equal_along_first_dimension()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.assert_shape_equal_along_first_dimension </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape_a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>shape_b</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Asserts that shape_a and shape_b are the same along the 0th-dimension.

If the shapes are static, raises a ValueError when the shapes
mismatch.

If the shapes are dynamic, raises a tf InvalidArgumentError when the shapes
mismatch.

Args:
  shape_a: a list containing shape of the first tensor.
  shape_b: a list containing shape of the second tensor.

Returns:
  Either a tf.no_op() when shapes are all static and a tf.assert_equal() op
  when the shapes are dynamic.

Raises:
  ValueError: When shapes are both static and unequal.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00326">326</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  326</span><span class="keyword">def </span>assert_shape_equal_along_first_dimension(shape_a, shape_b):</div>
<div class="line"><span class="lineno">  327</span>  <span class="stringliteral">&quot;&quot;&quot;Asserts that shape_a and shape_b are the same along the 0th-dimension.</span></div>
<div class="line"><span class="lineno">  328</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  329</span><span class="stringliteral">  If the shapes are static, raises a ValueError when the shapes</span></div>
<div class="line"><span class="lineno">  330</span><span class="stringliteral">  mismatch.</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">  If the shapes are dynamic, raises a tf InvalidArgumentError when the shapes</span></div>
<div class="line"><span class="lineno">  333</span><span class="stringliteral">  mismatch.</span></div>
<div class="line"><span class="lineno">  334</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  335</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  336</span><span class="stringliteral">    shape_a: a list containing shape of the first tensor.</span></div>
<div class="line"><span class="lineno">  337</span><span class="stringliteral">    shape_b: a list containing shape of the second tensor.</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  339</span><span class="stringliteral">  Returns:</span></div>
<div class="line"><span class="lineno">  340</span><span class="stringliteral">    Either a tf.no_op() when shapes are all static </span><span class="keywordflow">and</span> a tf.assert_equal() op</div>
<div class="line"><span class="lineno">  341</span>    when the shapes are dynamic.</div>
<div class="line"><span class="lineno">  342</span> </div>
<div class="line"><span class="lineno">  343</span>  Raises:</div>
<div class="line"><span class="lineno">  344</span>    ValueError: When shapes are both static <span class="keywordflow">and</span> unequal.</div>
<div class="line"><span class="lineno">  345</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  346</span><span class="stringliteral">  </span><span class="keywordflow">if</span> isinstance(shape_a[0], int) <span class="keywordflow">and</span> isinstance(shape_b[0], int):</div>
<div class="line"><span class="lineno">  347</span>    <span class="keywordflow">if</span> shape_a[0] != shape_b[0]:</div>
<div class="line"><span class="lineno">  348</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;Unequal first dimension {}, {}&#39;</span>.format(</div>
<div class="line"><span class="lineno">  349</span>          shape_a[0], shape_b[0]))</div>
<div class="line"><span class="lineno">  350</span>    <span class="keywordflow">else</span>: <span class="keywordflow">return</span> tf.no_op()</div>
<div class="line"><span class="lineno">  351</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  352</span>    <span class="keywordflow">return</span> tf.assert_equal(shape_a[0], shape_b[0])</div>
<div class="line"><span class="lineno">  353</span> </div>
<div class="line"><span class="lineno">  354</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a0ea44d81f5ae2db5c0cbe745f0b2be12" name="a0ea44d81f5ae2db5c0cbe745f0b2be12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0ea44d81f5ae2db5c0cbe745f0b2be12">&#9670;&#160;</a></span>check_min_image_dim()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.check_min_image_dim </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>min_dim</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>image_tensor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Checks that the image width/height are greater than some number.

This function is used to check that the width and height of an image are above
a certain value. If the image shape is static, this function will perform the
check at graph construction time. Otherwise, if the image shape varies, an
Assertion control dependency will be added to the graph.

Args:
  min_dim: The minimum number of pixels along the width and height of the
           image.
  image_tensor: The image tensor to check size for.

Returns:
  If `image_tensor` has dynamic size, return `image_tensor` with a Assert
  control dependency. Otherwise returns image_tensor.

Raises:
  ValueError: if `image_tensor`'s' width or height is smaller than `min_dim`.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00258">258</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  258</span><span class="keyword">def </span>check_min_image_dim(min_dim, image_tensor):</div>
<div class="line"><span class="lineno">  259</span>  <span class="stringliteral">&quot;&quot;&quot;Checks that the image width/height are greater than some number.</span></div>
<div class="line"><span class="lineno">  260</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  261</span><span class="stringliteral">  This function </span><span class="keywordflow">is</span> used to check that the width <span class="keywordflow">and</span> height of an image are above</div>
<div class="line"><span class="lineno">  262</span>  a certain value. If the image shape <span class="keywordflow">is</span> static, this function will perform the</div>
<div class="line"><span class="lineno">  263</span>  check at graph construction time. Otherwise, <span class="keywordflow">if</span> the image shape varies, an</div>
<div class="line"><span class="lineno">  264</span>  Assertion control dependency will be added to the graph.</div>
<div class="line"><span class="lineno">  265</span> </div>
<div class="line"><span class="lineno">  266</span>  Args:</div>
<div class="line"><span class="lineno">  267</span>    min_dim: The minimum number of pixels along the width <span class="keywordflow">and</span> height of the</div>
<div class="line"><span class="lineno">  268</span>             image.</div>
<div class="line"><span class="lineno">  269</span>    image_tensor: The image tensor to check size <span class="keywordflow">for</span>.</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span>  Returns:</div>
<div class="line"><span class="lineno">  272</span>    If `image_tensor` has dynamic size, <span class="keywordflow">return</span> `image_tensor` <span class="keyword">with</span> a Assert</div>
<div class="line"><span class="lineno">  273</span>    control dependency. Otherwise returns image_tensor.</div>
<div class="line"><span class="lineno">  274</span> </div>
<div class="line"><span class="lineno">  275</span>  Raises:</div>
<div class="line"><span class="lineno">  276</span>    ValueError: <span class="keywordflow">if</span> `image_tensor`<span class="stringliteral">&#39;s&#39;</span> width <span class="keywordflow">or</span> height <span class="keywordflow">is</span> smaller than `min_dim`.</div>
<div class="line"><span class="lineno">  277</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">  image_shape = image_tensor.get_shape()</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">  image_height = static_shape.get_height(image_shape)</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">  image_width = static_shape.get_width(image_shape)</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">  </span><span class="keywordflow">if</span> image_height <span class="keywordflow">is</span> <span class="keywordtype">None</span> <span class="keywordflow">or</span> image_width <span class="keywordflow">is</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  282</span>    shape_assert = tf.Assert(</div>
<div class="line"><span class="lineno">  283</span>        tf.logical_and(tf.greater_equal(tf.shape(image_tensor)[1], min_dim),</div>
<div class="line"><span class="lineno">  284</span>                       tf.greater_equal(tf.shape(image_tensor)[2], min_dim)),</div>
<div class="line"><span class="lineno">  285</span>        [<span class="stringliteral">&#39;image size must be &gt;= {} in both height and width.&#39;</span>.format(min_dim)])</div>
<div class="line"><span class="lineno">  286</span>    <span class="keyword">with</span> tf.control_dependencies([shape_assert]):</div>
<div class="line"><span class="lineno">  287</span>      <span class="keywordflow">return</span> tf.identity(image_tensor)</div>
<div class="line"><span class="lineno">  288</span> </div>
<div class="line"><span class="lineno">  289</span>  <span class="keywordflow">if</span> image_height &lt; min_dim <span class="keywordflow">or</span> image_width &lt; min_dim:</div>
<div class="line"><span class="lineno">  290</span>    <span class="keywordflow">raise</span> ValueError(</div>
<div class="line"><span class="lineno">  291</span>        <span class="stringliteral">&#39;image size must be &gt;= %d in both height and width; image dim = %d,%d&#39;</span> %</div>
<div class="line"><span class="lineno">  292</span>        (min_dim, image_height, image_width))</div>
<div class="line"><span class="lineno">  293</span> </div>
<div class="line"><span class="lineno">  294</span>  <span class="keywordflow">return</span> image_tensor</div>
<div class="line"><span class="lineno">  295</span> </div>
<div class="line"><span class="lineno">  296</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a961e10f2d22914e41c721971f98670fd" name="a961e10f2d22914e41c721971f98670fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a961e10f2d22914e41c721971f98670fd">&#9670;&#160;</a></span>clip_tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.clip_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Clips the input tensor along the first dimension up to the length.

Args:
  t: the input tensor, assuming the rank is at least 1.
  length: a tensor of shape [1]  or an integer, indicating the first dimension
    of the input tensor t after clipping, assuming length &lt;= t.shape[0].

Returns:
  clipped_t: the clipped tensor, whose first dimension is length. If the
    length is an integer, the first dimension of clipped_t is set to length
    statically.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00085">85</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   85</span><span class="keyword">def </span>clip_tensor(t, length):</div>
<div class="line"><span class="lineno">   86</span>  <span class="stringliteral">&quot;&quot;&quot;Clips the input tensor along the first dimension up to the length.</span></div>
<div class="line"><span class="lineno">   87</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   88</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">   89</span><span class="stringliteral">    t: the input tensor, assuming the rank </span><span class="keywordflow">is</span> at least 1.</div>
<div class="line"><span class="lineno">   90</span>    length: a tensor of shape [1]  <span class="keywordflow">or</span> an integer, indicating the first dimension</div>
<div class="line"><span class="lineno">   91</span>      of the input tensor t after clipping, assuming length &lt;= t.shape[0].</div>
<div class="line"><span class="lineno">   92</span> </div>
<div class="line"><span class="lineno">   93</span>  Returns:</div>
<div class="line"><span class="lineno">   94</span>    clipped_t: the clipped tensor, whose first dimension <span class="keywordflow">is</span> length. If the</div>
<div class="line"><span class="lineno">   95</span>      length <span class="keywordflow">is</span> an integer, the first dimension of clipped_t <span class="keywordflow">is</span> set to length</div>
<div class="line"><span class="lineno">   96</span>      statically.</div>
<div class="line"><span class="lineno">   97</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   98</span><span class="stringliteral">  clipped_t = tf.gather(t, tf.range(length))</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral">  </span><span class="keywordflow">if</span> <span class="keywordflow">not</span> _is_tensor(length):</div>
<div class="line"><span class="lineno">  100</span>    clipped_t = _set_dim_0(clipped_t, length)</div>
<div class="line"><span class="lineno">  101</span>  <span class="keywordflow">return</span> clipped_t</div>
<div class="line"><span class="lineno">  102</span> </div>
<div class="line"><span class="lineno">  103</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a961e10f2d22914e41c721971f98670fd_cgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a961e10f2d22914e41c721971f98670fd_cgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a961e10f2d22914e41c721971f98670fd_cgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a961e10f2d22914e41c721971f98670fd_cgraph">
<area shape="rect" title=" " alt="" coords="5,37,179,77"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a40cccc95c5977459bd034bc0a18ddf28" title=" " alt="" coords="227,5,400,45"/>
<area shape="poly" title=" " alt="" coords="179,42,213,37,214,42,180,47"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a9495102c38b0c97f6e5ef53f4e8948c9" title=" " alt="" coords="227,69,400,109"/>
<area shape="poly" title=" " alt="" coords="180,67,214,72,213,78,179,73"/>
</map>
</div>

</div>
</div>
<a id="a2716d6d75b6e5d892f11298d31dbd226" name="a2716d6d75b6e5d892f11298d31dbd226"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2716d6d75b6e5d892f11298d31dbd226">&#9670;&#160;</a></span>combined_static_and_dynamic_shape()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.combined_static_and_dynamic_shape </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a list containing static and dynamic values for the dimensions.

Returns a list of static and dynamic values for shape dimensions. This is
useful to preserve static shapes when available in reshape operation.

Args:
  tensor: A tensor of any type.

Returns:
  A list of size tensor.shape.ndims containing integers or a scalar tensor.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00162">162</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  162</span><span class="keyword">def </span>combined_static_and_dynamic_shape(tensor):</div>
<div class="line"><span class="lineno">  163</span>  <span class="stringliteral">&quot;&quot;&quot;Returns a list containing static and dynamic values for the dimensions.</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">  Returns a list of static </span><span class="keywordflow">and</span> dynamic values <span class="keywordflow">for</span> shape dimensions. This <span class="keywordflow">is</span></div>
<div class="line"><span class="lineno">  166</span>  useful to preserve static shapes when available <span class="keywordflow">in</span> reshape operation.</div>
<div class="line"><span class="lineno">  167</span> </div>
<div class="line"><span class="lineno">  168</span>  Args:</div>
<div class="line"><span class="lineno">  169</span>    tensor: A tensor of any type.</div>
<div class="line"><span class="lineno">  170</span> </div>
<div class="line"><span class="lineno">  171</span>  Returns:</div>
<div class="line"><span class="lineno">  172</span>    A list of size tensor.shape.ndims containing integers <span class="keywordflow">or</span> a scalar tensor.</div>
<div class="line"><span class="lineno">  173</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  174</span><span class="stringliteral">  static_tensor_shape = tensor.shape.as_list()</span></div>
<div class="line"><span class="lineno">  175</span><span class="stringliteral">  dynamic_tensor_shape = tf.shape(tensor)</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral">  combined_shape = []</span></div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">  </span><span class="keywordflow">for</span> index, dim <span class="keywordflow">in</span> enumerate(static_tensor_shape):</div>
<div class="line"><span class="lineno">  178</span>    <span class="keywordflow">if</span> dim <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  179</span>      combined_shape.append(dim)</div>
<div class="line"><span class="lineno">  180</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  181</span>      combined_shape.append(dynamic_tensor_shape[index])</div>
<div class="line"><span class="lineno">  182</span>  <span class="keywordflow">return</span> combined_shape</div>
<div class="line"><span class="lineno">  183</span> </div>
<div class="line"><span class="lineno">  184</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a2716d6d75b6e5d892f11298d31dbd226_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a2716d6d75b6e5d892f11298d31dbd226_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a2716d6d75b6e5d892f11298d31dbd226_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a2716d6d75b6e5d892f11298d31dbd226_icgraph">
<area shape="rect" title=" " alt="" coords="501,66,681,121"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ae9b0d9bf4014378f0008105db0fc066b" title=" " alt="" coords="260,29,453,69"/>
<area shape="poly" title=" " alt="" coords="487,77,453,70,454,65,488,71"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a5ef07eddf0a0dff4b0c84c4ff23426e7" title=" " alt="" coords="270,117,443,157"/>
<area shape="poly" title=" " alt="" coords="488,115,444,124,443,119,487,110"/>
<area shape="poly" title=" " alt="" coords="397,18,383,11,357,8,334,10,320,15,315,21,318,28,313,30,310,20,317,10,333,5,357,3,384,6,399,13"/>
<area shape="poly" title=" " alt="" coords="397,106,383,99,357,96,334,98,320,103,315,109,318,116,313,118,310,108,317,98,333,93,357,91,384,94,399,101"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ad2d28655bc7c097813412148740044f5" title=" " alt="" coords="5,117,212,157"/>
<area shape="poly" title=" " alt="" coords="256,140,212,140,212,135,256,135"/>
<area shape="poly" title=" " alt="" coords="151,106,136,99,109,96,85,98,70,103,65,109,68,116,63,118,60,108,67,98,84,93,109,91,137,94,153,101"/>
</map>
</div>

</div>
</div>
<a id="ae9b0d9bf4014378f0008105db0fc066b" name="ae9b0d9bf4014378f0008105db0fc066b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae9b0d9bf4014378f0008105db0fc066b">&#9670;&#160;</a></span>expand_first_dimension()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.expand_first_dimension </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dims</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Expands `K-d` tensor along first dimension to be a `(K+n-1)-d` tensor.

Converts `inputs` with shape [D0, D1, ..., D(K-1)] into a tensor of shape
[dims[0], dims[1], ..., dims[-1], D1, ..., D(k-1)].

Example:
`inputs` is a tensor with shape [50, 20, 20, 3].
new_tensor = expand_first_dimension(inputs, [10, 5]).
new_tensor.shape -&gt; [10, 5, 20, 20, 3].

Args:
  inputs: a tensor with shape [D0, D1, ..., D(K-1)].
  dims: List with new dimensions to expand first axis into. The length of
    `dims` is typically 2 or larger.

Returns:
  a tensor with shape [dims[0], dims[1], ..., dims[-1], D1, ..., D(k-1)].
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00436">436</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  436</span><span class="keyword">def </span>expand_first_dimension(inputs, dims):</div>
<div class="line"><span class="lineno">  437</span>  <span class="stringliteral">&quot;&quot;&quot;Expands `K-d` tensor along first dimension to be a `(K+n-1)-d` tensor.</span></div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">  Converts `inputs` </span><span class="keyword">with</span> shape [D0, D1, ..., D(K-1)] into a tensor of shape</div>
<div class="line"><span class="lineno">  440</span>  [dims[0], dims[1], ..., dims[-1], D1, ..., D(k-1)].</div>
<div class="line"><span class="lineno">  441</span> </div>
<div class="line"><span class="lineno">  442</span>  Example:</div>
<div class="line"><span class="lineno">  443</span>  `inputs` <span class="keywordflow">is</span> a tensor <span class="keyword">with</span> shape [50, 20, 20, 3].</div>
<div class="line"><span class="lineno">  444</span>  new_tensor = expand_first_dimension(inputs, [10, 5]).</div>
<div class="line"><span class="lineno">  445</span>  new_tensor.shape -&gt; [10, 5, 20, 20, 3].</div>
<div class="line"><span class="lineno">  446</span> </div>
<div class="line"><span class="lineno">  447</span>  Args:</div>
<div class="line"><span class="lineno">  448</span>    inputs: a tensor <span class="keyword">with</span> shape [D0, D1, ..., D(K-1)].</div>
<div class="line"><span class="lineno">  449</span>    dims: List <span class="keyword">with</span> new dimensions to expand first axis into. The length of</div>
<div class="line"><span class="lineno">  450</span>      `dims` <span class="keywordflow">is</span> typically 2 <span class="keywordflow">or</span> larger.</div>
<div class="line"><span class="lineno">  451</span> </div>
<div class="line"><span class="lineno">  452</span>  Returns:</div>
<div class="line"><span class="lineno">  453</span>    a tensor <span class="keyword">with</span> shape [dims[0], dims[1], ..., dims[-1], D1, ..., D(k-1)].</div>
<div class="line"><span class="lineno">  454</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  455</span><span class="stringliteral">  inputs_shape = combined_static_and_dynamic_shape(inputs)</span></div>
<div class="line"><span class="lineno">  456</span><span class="stringliteral">  expanded_shape = tf.stack(dims + inputs_shape[1:])</span></div>
<div class="line"><span class="lineno">  457</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  458</span><span class="stringliteral">  </span><span class="comment"># Verify that it is possible to expand the first axis of inputs.</span></div>
<div class="line"><span class="lineno">  459</span>  assert_op = tf.assert_equal(</div>
<div class="line"><span class="lineno">  460</span>      inputs_shape[0], tf.reduce_prod(tf.stack(dims)),</div>
<div class="line"><span class="lineno">  461</span>      message=(<span class="stringliteral">&#39;First dimension of `inputs` cannot be expanded into provided &#39;</span></div>
<div class="line"><span class="lineno">  462</span>               <span class="stringliteral">&#39;`dims`&#39;</span>))</div>
<div class="line"><span class="lineno">  463</span> </div>
<div class="line"><span class="lineno">  464</span>  <span class="keyword">with</span> tf.control_dependencies([assert_op]):</div>
<div class="line"><span class="lineno">  465</span>    inputs_reshaped = tf.reshape(inputs, expanded_shape)</div>
<div class="line"><span class="lineno">  466</span> </div>
<div class="line"><span class="lineno">  467</span>  <span class="keywordflow">return</span> inputs_reshaped</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_cgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_cgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_cgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_cgraph">
<area shape="rect" title=" " alt="" coords="5,29,199,69"/>
<area shape="poly" title=" " alt="" coords="58,30,56,20,63,10,78,5,102,3,129,6,144,13,142,18,128,11,102,8,79,10,66,15,61,21,63,28"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a2716d6d75b6e5d892f11298d31dbd226" title=" " alt="" coords="247,22,427,77"/>
<area shape="poly" title=" " alt="" coords="199,47,233,47,233,52,199,52"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae9b0d9bf4014378f0008105db0fc066b_icgraph">
<area shape="rect" title=" " alt="" coords="5,29,199,69"/>
<area shape="poly" title=" " alt="" coords="134,17,123,11,102,8,84,10,73,15,69,21,71,28,66,30,64,20,69,11,82,5,102,3,125,6,137,13"/>
</map>
</div>

</div>
</div>
<a id="a5ef07eddf0a0dff4b0c84c4ff23426e7" name="a5ef07eddf0a0dff4b0c84c4ff23426e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5ef07eddf0a0dff4b0c84c4ff23426e7">&#9670;&#160;</a></span>flatten_dimensions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.flatten_dimensions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>first</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>last</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Flattens `K-d` tensor along [first, last) dimensions.

Converts `inputs` with shape [D0, D1, ..., D(K-1)] into a tensor of shape
[D0, D1, ..., D(first) * D(first+1) * ... * D(last-1), D(last), ..., D(K-1)].

Example:
`inputs` is a tensor with initial shape [10, 5, 20, 20, 3].
new_tensor = flatten_dimensions(inputs, last=4, first=2)
new_tensor.shape -&gt; [10, 100, 20, 3].

Args:
  inputs: a tensor with shape [D0, D1, ..., D(K-1)].
  first: first value for the range of dimensions to flatten.
  last: last value for the range of dimensions to flatten. Note that the last
    dimension itself is excluded.

Returns:
  a tensor with shape
  [D0, D1, ..., D(first) * D(first + 1) * ... * D(last - 1), D(last), ...,
   D(K-1)].

Raises:
  ValueError: if first and last arguments are incorrect.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00378">378</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  378</span><span class="keyword">def </span>flatten_dimensions(inputs, first, last):</div>
<div class="line"><span class="lineno">  379</span>  <span class="stringliteral">&quot;&quot;&quot;Flattens `K-d` tensor along [first, last) dimensions.</span></div>
<div class="line"><span class="lineno">  380</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  381</span><span class="stringliteral">  Converts `inputs` </span><span class="keyword">with</span> shape [D0, D1, ..., D(K-1)] into a tensor of shape</div>
<div class="line"><span class="lineno">  382</span>  [D0, D1, ..., D(first) * D(first+1) * ... * D(last-1), D(last), ..., D(K-1)].</div>
<div class="line"><span class="lineno">  383</span> </div>
<div class="line"><span class="lineno">  384</span>  Example:</div>
<div class="line"><span class="lineno">  385</span>  `inputs` <span class="keywordflow">is</span> a tensor <span class="keyword">with</span> initial shape [10, 5, 20, 20, 3].</div>
<div class="line"><span class="lineno">  386</span>  new_tensor = flatten_dimensions(inputs, last=4, first=2)</div>
<div class="line"><span class="lineno">  387</span>  new_tensor.shape -&gt; [10, 100, 20, 3].</div>
<div class="line"><span class="lineno">  388</span> </div>
<div class="line"><span class="lineno">  389</span>  Args:</div>
<div class="line"><span class="lineno">  390</span>    inputs: a tensor <span class="keyword">with</span> shape [D0, D1, ..., D(K-1)].</div>
<div class="line"><span class="lineno">  391</span>    first: first value <span class="keywordflow">for</span> the range of dimensions to flatten.</div>
<div class="line"><span class="lineno">  392</span>    last: last value <span class="keywordflow">for</span> the range of dimensions to flatten. Note that the last</div>
<div class="line"><span class="lineno">  393</span>      dimension itself <span class="keywordflow">is</span> excluded.</div>
<div class="line"><span class="lineno">  394</span> </div>
<div class="line"><span class="lineno">  395</span>  Returns:</div>
<div class="line"><span class="lineno">  396</span>    a tensor <span class="keyword">with</span> shape</div>
<div class="line"><span class="lineno">  397</span>    [D0, D1, ..., D(first) * D(first + 1) * ... * D(last - 1), D(last), ...,</div>
<div class="line"><span class="lineno">  398</span>     D(K-1)].</div>
<div class="line"><span class="lineno">  399</span> </div>
<div class="line"><span class="lineno">  400</span>  Raises:</div>
<div class="line"><span class="lineno">  401</span>    ValueError: <span class="keywordflow">if</span> first <span class="keywordflow">and</span> last arguments are incorrect.</div>
<div class="line"><span class="lineno">  402</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  403</span><span class="stringliteral">  </span><span class="keywordflow">if</span> first &gt;= inputs.shape.ndims <span class="keywordflow">or</span> last &gt; inputs.shape.ndims:</div>
<div class="line"><span class="lineno">  404</span>    <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`first` and `last` must be less than inputs.shape.ndims. &#39;</span></div>
<div class="line"><span class="lineno">  405</span>                     <span class="stringliteral">&#39;found {} and {} respectively while ndims is {}&#39;</span>.format(</div>
<div class="line"><span class="lineno">  406</span>                         first, last, inputs.shape.ndims))</div>
<div class="line"><span class="lineno">  407</span>  shape = combined_static_and_dynamic_shape(inputs)</div>
<div class="line"><span class="lineno">  408</span>  flattened_dim_prod = tf.reduce_prod(shape[first:last],</div>
<div class="line"><span class="lineno">  409</span>                                      keepdims=<span class="keyword">True</span>)</div>
<div class="line"><span class="lineno">  410</span>  new_shape = tf.concat([shape[:first], flattened_dim_prod,</div>
<div class="line"><span class="lineno">  411</span>                         shape[last:]], axis=0)</div>
<div class="line"><span class="lineno">  412</span>  <span class="keywordflow">return</span> tf.reshape(inputs, new_shape)</div>
<div class="line"><span class="lineno">  413</span> </div>
<div class="line"><span class="lineno">  414</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_cgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_cgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_cgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_cgraph">
<area shape="rect" title=" " alt="" coords="5,29,179,69"/>
<area shape="poly" title=" " alt="" coords="50,30,48,20,54,10,69,5,92,3,118,6,132,13,130,18,117,11,92,8,70,10,58,15,53,21,55,28"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a2716d6d75b6e5d892f11298d31dbd226" title=" " alt="" coords="227,22,407,77"/>
<area shape="poly" title=" " alt="" coords="179,47,213,47,213,52,179,52"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a5ef07eddf0a0dff4b0c84c4ff23426e7_icgraph">
<area shape="rect" title=" " alt="" coords="260,29,433,69"/>
<area shape="poly" title=" " alt="" coords="387,18,373,11,347,8,324,10,310,15,305,21,308,28,302,30,300,20,307,10,323,5,347,3,374,6,389,13"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ad2d28655bc7c097813412148740044f5" title=" " alt="" coords="5,29,212,69"/>
<area shape="poly" title=" " alt="" coords="246,52,212,52,212,47,246,47"/>
<area shape="poly" title=" " alt="" coords="149,18,135,11,109,8,86,10,72,15,67,21,70,28,64,30,62,20,69,10,85,5,109,3,136,6,151,13"/>
</map>
</div>

</div>
</div>
<a id="ad2d28655bc7c097813412148740044f5" name="ad2d28655bc7c097813412148740044f5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad2d28655bc7c097813412148740044f5">&#9670;&#160;</a></span>flatten_first_n_dimensions()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.flatten_first_n_dimensions </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>n</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Flattens `K-d` tensor along first n dimension to be a `(K-n+1)-d` tensor.

Converts `inputs` with shape [D0, D1, ..., D(K-1)] into a tensor of shape
[D0 * D1 * ... * D(n-1), D(n), ... D(K-1)].

Example:
`inputs` is a tensor with initial shape [10, 5, 20, 20, 3].
new_tensor = flatten_first_n_dimensions(inputs, 2)
new_tensor.shape -&gt; [50, 20, 20, 3].

Args:
  inputs: a tensor with shape [D0, D1, ..., D(K-1)].
  n: The number of dimensions to flatten.

Returns:
  a tensor with shape [D0 * D1 * ... * D(n-1), D(n), ... D(K-1)].
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00415">415</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  415</span><span class="keyword">def </span>flatten_first_n_dimensions(inputs, n):</div>
<div class="line"><span class="lineno">  416</span>  <span class="stringliteral">&quot;&quot;&quot;Flattens `K-d` tensor along first n dimension to be a `(K-n+1)-d` tensor.</span></div>
<div class="line"><span class="lineno">  417</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  418</span><span class="stringliteral">  Converts `inputs` </span><span class="keyword">with</span> shape [D0, D1, ..., D(K-1)] into a tensor of shape</div>
<div class="line"><span class="lineno">  419</span>  [D0 * D1 * ... * D(n-1), D(n), ... D(K-1)].</div>
<div class="line"><span class="lineno">  420</span> </div>
<div class="line"><span class="lineno">  421</span>  Example:</div>
<div class="line"><span class="lineno">  422</span>  `inputs` <span class="keywordflow">is</span> a tensor <span class="keyword">with</span> initial shape [10, 5, 20, 20, 3].</div>
<div class="line"><span class="lineno">  423</span>  new_tensor = flatten_first_n_dimensions(inputs, 2)</div>
<div class="line"><span class="lineno">  424</span>  new_tensor.shape -&gt; [50, 20, 20, 3].</div>
<div class="line"><span class="lineno">  425</span> </div>
<div class="line"><span class="lineno">  426</span>  Args:</div>
<div class="line"><span class="lineno">  427</span>    inputs: a tensor <span class="keyword">with</span> shape [D0, D1, ..., D(K-1)].</div>
<div class="line"><span class="lineno">  428</span>    n: The number of dimensions to flatten.</div>
<div class="line"><span class="lineno">  429</span> </div>
<div class="line"><span class="lineno">  430</span>  Returns:</div>
<div class="line"><span class="lineno">  431</span>    a tensor <span class="keyword">with</span> shape [D0 * D1 * ... * D(n-1), D(n), ... D(K-1)].</div>
<div class="line"><span class="lineno">  432</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  433</span><span class="stringliteral">  </span><span class="keywordflow">return</span> flatten_dimensions(inputs, first=0, last=n)</div>
<div class="line"><span class="lineno">  434</span> </div>
<div class="line"><span class="lineno">  435</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_cgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_cgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_cgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_cgraph">
<area shape="rect" title=" " alt="" coords="5,29,212,69"/>
<area shape="poly" title=" " alt="" coords="64,30,62,20,69,10,85,5,109,3,136,6,151,13,149,18,135,11,109,8,86,10,72,15,67,21,70,28"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a5ef07eddf0a0dff4b0c84c4ff23426e7" title=" " alt="" coords="260,29,433,69"/>
<area shape="poly" title=" " alt="" coords="212,47,246,47,246,52,212,52"/>
<area shape="poly" title=" " alt="" coords="305,30,302,20,309,10,324,5,347,3,373,6,387,13,385,18,371,11,347,8,325,10,312,15,307,21,310,28"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a2716d6d75b6e5d892f11298d31dbd226" title=" " alt="" coords="481,22,661,77"/>
<area shape="poly" title=" " alt="" coords="434,47,467,47,467,52,434,52"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ad2d28655bc7c097813412148740044f5_icgraph">
<area shape="rect" title=" " alt="" coords="5,29,212,69"/>
<area shape="poly" title=" " alt="" coords="143,18,131,11,109,8,89,10,77,15,73,21,75,28,70,30,68,20,74,11,88,5,109,3,133,6,146,13"/>
</map>
</div>

</div>
</div>
<a id="a972697b6b4ab2bfdd42fe3013a28fa47" name="a972697b6b4ab2bfdd42fe3013a28fa47"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a972697b6b4ab2bfdd42fe3013a28fa47">&#9670;&#160;</a></span>pad_or_clip_nd()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.pad_or_clip_nd </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>tensor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_shape</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pad or Clip given tensor to the output shape.

Args:
  tensor: Input tensor to pad or clip.
  output_shape: A list of integers / scalar tensors (or None for dynamic dim)
    representing the size to pad or clip each dimension of the input tensor.

Returns:
  Input tensor padded and clipped to the output shape.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00120">120</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  120</span><span class="keyword">def </span>pad_or_clip_nd(tensor, output_shape):</div>
<div class="line"><span class="lineno">  121</span>  <span class="stringliteral">&quot;&quot;&quot;Pad or Clip given tensor to the output shape.</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  123</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  124</span><span class="stringliteral">    tensor: Input tensor to pad </span><span class="keywordflow">or</span> clip.</div>
<div class="line"><span class="lineno">  125</span>    output_shape: A list of integers / scalar tensors (<span class="keywordflow">or</span> <span class="keywordtype">None</span> <span class="keywordflow">for</span> dynamic dim)</div>
<div class="line"><span class="lineno">  126</span>      representing the size to pad <span class="keywordflow">or</span> clip each dimension of the input tensor.</div>
<div class="line"><span class="lineno">  127</span> </div>
<div class="line"><span class="lineno">  128</span>  Returns:</div>
<div class="line"><span class="lineno">  129</span>    Input tensor padded <span class="keywordflow">and</span> clipped to the output shape.</div>
<div class="line"><span class="lineno">  130</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  131</span><span class="stringliteral">  tensor_shape = tf.shape(tensor)</span></div>
<div class="line"><span class="lineno">  132</span><span class="stringliteral">  clip_size = [</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral">      tf.where(tensor_shape[i] - shape &gt; 0, shape, -1)</span></div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">      </span><span class="keywordflow">if</span> shape <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> -1 <span class="keywordflow">for</span> i, shape <span class="keywordflow">in</span> enumerate(output_shape)</div>
<div class="line"><span class="lineno">  135</span>  ]</div>
<div class="line"><span class="lineno">  136</span>  clipped_tensor = tf.slice(</div>
<div class="line"><span class="lineno">  137</span>      tensor,</div>
<div class="line"><span class="lineno">  138</span>      begin=tf.zeros(len(clip_size), dtype=tf.int32),</div>
<div class="line"><span class="lineno">  139</span>      size=clip_size)</div>
<div class="line"><span class="lineno">  140</span> </div>
<div class="line"><span class="lineno">  141</span>  <span class="comment"># Pad tensor if the shape of clipped tensor is smaller than the expected</span></div>
<div class="line"><span class="lineno">  142</span>  <span class="comment"># shape.</span></div>
<div class="line"><span class="lineno">  143</span>  clipped_tensor_shape = tf.shape(clipped_tensor)</div>
<div class="line"><span class="lineno">  144</span>  trailing_paddings = [</div>
<div class="line"><span class="lineno">  145</span>      shape - clipped_tensor_shape[i] <span class="keywordflow">if</span> shape <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span> <span class="keywordflow">else</span> 0</div>
<div class="line"><span class="lineno">  146</span>      <span class="keywordflow">for</span> i, shape <span class="keywordflow">in</span> enumerate(output_shape)</div>
<div class="line"><span class="lineno">  147</span>  ]</div>
<div class="line"><span class="lineno">  148</span>  paddings = tf.stack(</div>
<div class="line"><span class="lineno">  149</span>      [</div>
<div class="line"><span class="lineno">  150</span>          tf.zeros(len(trailing_paddings), dtype=tf.int32),</div>
<div class="line"><span class="lineno">  151</span>          trailing_paddings</div>
<div class="line"><span class="lineno">  152</span>      ],</div>
<div class="line"><span class="lineno">  153</span>      axis=1)</div>
<div class="line"><span class="lineno">  154</span>  padded_tensor = tf.pad(clipped_tensor, paddings=paddings)</div>
<div class="line"><span class="lineno">  155</span>  output_static_shape = [</div>
<div class="line"><span class="lineno">  156</span>      dim <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(dim, tf.Tensor) <span class="keywordflow">else</span> <span class="keywordtype">None</span> <span class="keywordflow">for</span> dim <span class="keywordflow">in</span> output_shape</div>
<div class="line"><span class="lineno">  157</span>  ]</div>
<div class="line"><span class="lineno">  158</span>  padded_tensor.set_shape(output_static_shape)</div>
<div class="line"><span class="lineno">  159</span>  <span class="keywordflow">return</span> padded_tensor</div>
<div class="line"><span class="lineno">  160</span> </div>
<div class="line"><span class="lineno">  161</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a972697b6b4ab2bfdd42fe3013a28fa47_icgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a972697b6b4ab2bfdd42fe3013a28fa47_icgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a972697b6b4ab2bfdd42fe3013a28fa47_icgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a972697b6b4ab2bfdd42fe3013a28fa47_icgraph">
<area shape="rect" title=" " alt="" coords="227,5,400,45"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#ae0526aa315e20a9497646fcf174bc259" title=" " alt="" coords="5,5,179,45"/>
<area shape="poly" title=" " alt="" coords="213,28,179,28,179,23,213,23"/>
</map>
</div>

</div>
</div>
<a id="ae0526aa315e20a9497646fcf174bc259" name="ae0526aa315e20a9497646fcf174bc259"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae0526aa315e20a9497646fcf174bc259">&#9670;&#160;</a></span>pad_or_clip_tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.pad_or_clip_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pad or clip the input tensor along the first dimension.

Args:
  t: the input tensor, assuming the rank is at least 1.
  length: a tensor of shape [1]  or an integer, indicating the first dimension
    of the input tensor t after processing.

Returns:
  processed_t: the processed tensor, whose first dimension is length. If the
    length is an integer, the first dimension of the processed tensor is set
    to length statically.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00104">104</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  104</span><span class="keyword">def </span>pad_or_clip_tensor(t, length):</div>
<div class="line"><span class="lineno">  105</span>  <span class="stringliteral">&quot;&quot;&quot;Pad or clip the input tensor along the first dimension.</span></div>
<div class="line"><span class="lineno">  106</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  107</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">  108</span><span class="stringliteral">    t: the input tensor, assuming the rank </span><span class="keywordflow">is</span> at least 1.</div>
<div class="line"><span class="lineno">  109</span>    length: a tensor of shape [1]  <span class="keywordflow">or</span> an integer, indicating the first dimension</div>
<div class="line"><span class="lineno">  110</span>      of the input tensor t after processing.</div>
<div class="line"><span class="lineno">  111</span> </div>
<div class="line"><span class="lineno">  112</span>  Returns:</div>
<div class="line"><span class="lineno">  113</span>    processed_t: the processed tensor, whose first dimension <span class="keywordflow">is</span> length. If the</div>
<div class="line"><span class="lineno">  114</span>      length <span class="keywordflow">is</span> an integer, the first dimension of the processed tensor <span class="keywordflow">is</span> set</div>
<div class="line"><span class="lineno">  115</span>      to length statically.</div>
<div class="line"><span class="lineno">  116</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  117</span><span class="stringliteral">  </span><span class="keywordflow">return</span> pad_or_clip_nd(t, [length] + t.shape.as_list()[1:])</div>
<div class="line"><span class="lineno">  118</span> </div>
<div class="line"><span class="lineno">  119</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae0526aa315e20a9497646fcf174bc259_cgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae0526aa315e20a9497646fcf174bc259_cgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae0526aa315e20a9497646fcf174bc259_cgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_ae0526aa315e20a9497646fcf174bc259_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,179,45"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a972697b6b4ab2bfdd42fe3013a28fa47" title=" " alt="" coords="227,5,400,45"/>
<area shape="poly" title=" " alt="" coords="179,23,213,23,213,28,179,28"/>
</map>
</div>

</div>
</div>
<a id="a43f88839ad82816f16c5dfc9a80fde17" name="a43f88839ad82816f16c5dfc9a80fde17"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43f88839ad82816f16c5dfc9a80fde17">&#9670;&#160;</a></span>pad_tensor()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.pad_tensor </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>t</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Pads the input tensor with 0s along the first dimension up to the length.

Args:
  t: the input tensor, assuming the rank is at least 1.
  length: a tensor of shape [1]  or an integer, indicating the first dimension
    of the input tensor t after padding, assuming length &lt;= t.shape[0].

Returns:
  padded_t: the padded tensor, whose first dimension is length. If the length
    is an integer, the first dimension of padded_t is set to length
    statically.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00059">59</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   59</span><span class="keyword">def </span>pad_tensor(t, length):</div>
<div class="line"><span class="lineno">   60</span>  <span class="stringliteral">&quot;&quot;&quot;Pads the input tensor with 0s along the first dimension up to the length.</span></div>
<div class="line"><span class="lineno">   61</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   62</span><span class="stringliteral">  Args:</span></div>
<div class="line"><span class="lineno">   63</span><span class="stringliteral">    t: the input tensor, assuming the rank </span><span class="keywordflow">is</span> at least 1.</div>
<div class="line"><span class="lineno">   64</span>    length: a tensor of shape [1]  <span class="keywordflow">or</span> an integer, indicating the first dimension</div>
<div class="line"><span class="lineno">   65</span>      of the input tensor t after padding, assuming length &lt;= t.shape[0].</div>
<div class="line"><span class="lineno">   66</span> </div>
<div class="line"><span class="lineno">   67</span>  Returns:</div>
<div class="line"><span class="lineno">   68</span>    padded_t: the padded tensor, whose first dimension <span class="keywordflow">is</span> length. If the length</div>
<div class="line"><span class="lineno">   69</span>      <span class="keywordflow">is</span> an integer, the first dimension of padded_t <span class="keywordflow">is</span> set to length</div>
<div class="line"><span class="lineno">   70</span>      statically.</div>
<div class="line"><span class="lineno">   71</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   72</span><span class="stringliteral">  t_rank = tf.rank(t)</span></div>
<div class="line"><span class="lineno">   73</span><span class="stringliteral">  t_shape = tf.shape(t)</span></div>
<div class="line"><span class="lineno">   74</span><span class="stringliteral">  t_d0 = t_shape[0]</span></div>
<div class="line"><span class="lineno">   75</span><span class="stringliteral">  pad_d0 = tf.expand_dims(length - t_d0, 0)</span></div>
<div class="line"><span class="lineno">   76</span><span class="stringliteral">  pad_shape = tf.cond(</span></div>
<div class="line"><span class="lineno">   77</span><span class="stringliteral">      tf.greater(t_rank, 1), </span><span class="keyword">lambda</span>: tf.concat([pad_d0, t_shape[1:]], 0),</div>
<div class="line"><span class="lineno">   78</span>      <span class="keyword">lambda</span>: tf.expand_dims(length - t_d0, 0))</div>
<div class="line"><span class="lineno">   79</span>  padded_t = tf.concat([t, tf.zeros(pad_shape, dtype=t.dtype)], 0)</div>
<div class="line"><span class="lineno">   80</span>  <span class="keywordflow">if</span> <span class="keywordflow">not</span> _is_tensor(length):</div>
<div class="line"><span class="lineno">   81</span>    padded_t = _set_dim_0(padded_t, length)</div>
<div class="line"><span class="lineno">   82</span>  <span class="keywordflow">return</span> padded_t</div>
<div class="line"><span class="lineno">   83</span> </div>
<div class="line"><span class="lineno">   84</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a43f88839ad82816f16c5dfc9a80fde17_cgraph.png" border="0" usemap="#ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a43f88839ad82816f16c5dfc9a80fde17_cgraph" alt=""/></div>
<map name="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a43f88839ad82816f16c5dfc9a80fde17_cgraph" id="ad0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils_a43f88839ad82816f16c5dfc9a80fde17_cgraph">
<area shape="rect" title=" " alt="" coords="5,37,179,77"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a40cccc95c5977459bd034bc0a18ddf28" title=" " alt="" coords="227,5,400,45"/>
<area shape="poly" title=" " alt="" coords="179,42,213,37,214,42,180,47"/>
<area shape="rect" href="../../d0/dcd/namespacedetection__utils_1_1utils_1_1shape__utils.html#a9495102c38b0c97f6e5ef53f4e8948c9" title=" " alt="" coords="227,69,400,109"/>
<area shape="poly" title=" " alt="" coords="180,67,214,72,213,78,179,73"/>
</map>
</div>

</div>
</div>
<a id="adbdc407bf10ad7dc672f5ac1ae2404c1" name="adbdc407bf10ad7dc672f5ac1ae2404c1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adbdc407bf10ad7dc672f5ac1ae2404c1">&#9670;&#160;</a></span>static_or_dynamic_map_fn()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.static_or_dynamic_map_fn </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fn</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>elems</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dtype</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>parallel_iterations</em> = <code>32</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>back_prop</em> = <code>True</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Runs map_fn as a (static) for loop when possible.

This function rewrites the map_fn as an explicit unstack input -&gt; for loop
over function calls -&gt; stack result combination.  This allows our graphs to
be acyclic when the batch size is static.
For comparison, see https://www.tensorflow.org/api_docs/python/tf/map_fn.

Note that `static_or_dynamic_map_fn` currently is not *fully* interchangeable
with the default tf.map_fn function as it does not accept nested inputs (only
Tensors or lists of Tensors).  Likewise, the output of `fn` can only be a
Tensor or list of Tensors.

TODO(jonathanhuang): make this function fully interchangeable with tf.map_fn.

Args:
  fn: The callable to be performed. It accepts one argument, which will have
    the same structure as elems. Its output must have the
    same structure as elems.
  elems: A tensor or list of tensors, each of which will
    be unpacked along their first dimension. The sequence of the
    resulting slices will be applied to fn.
  dtype:  (optional) The output type(s) of fn. If fn returns a structure of
    Tensors differing from the structure of elems, then dtype is not optional
    and must have the same structure as the output of fn.
  parallel_iterations: (optional) number of batch items to process in
    parallel.  This flag is only used if the native tf.map_fn is used
    and defaults to 32 instead of 10 (unlike the standard tf.map_fn default).
  back_prop: (optional) True enables support for back propagation.
    This flag is only used if the native tf.map_fn is used.

Returns:
  A tensor or sequence of tensors. Each tensor packs the
  results of applying fn to tensors unpacked from elems along the first
  dimension, from first to last.
Raises:
  ValueError: if `elems` a Tensor or a list of Tensors.
  ValueError: if `fn` does not return a Tensor or list of Tensors
</pre> 
<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00185">185</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  186</span>                             parallel_iterations=32, back_prop=<span class="keyword">True</span>):</div>
<div class="line"><span class="lineno">  187</span>  <span class="stringliteral">&quot;&quot;&quot;Runs map_fn as a (static) for loop when possible.</span></div>
<div class="line"><span class="lineno">  188</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  189</span><span class="stringliteral">  This function rewrites the map_fn </span><span class="keyword">as</span> an explicit unstack input -&gt; <span class="keywordflow">for</span> loop</div>
<div class="line"><span class="lineno">  190</span>  over function calls -&gt; stack result combination.  This allows our graphs to</div>
<div class="line"><span class="lineno">  191</span>  be acyclic when the batch size <span class="keywordflow">is</span> static.</div>
<div class="line"><span class="lineno">  192</span>  For comparison, see https://www.tensorflow.org/api_docs/python/tf/map_fn.</div>
<div class="line"><span class="lineno">  193</span> </div>
<div class="line"><span class="lineno">  194</span>  Note that `static_or_dynamic_map_fn` currently <span class="keywordflow">is</span> <span class="keywordflow">not</span> *fully* interchangeable</div>
<div class="line"><span class="lineno">  195</span>  <span class="keyword">with</span> the default tf.map_fn function <span class="keyword">as</span> it does <span class="keywordflow">not</span> accept nested inputs (only</div>
<div class="line"><span class="lineno">  196</span>  Tensors <span class="keywordflow">or</span> lists of Tensors).  Likewise, the output of `fn` can only be a</div>
<div class="line"><span class="lineno">  197</span>  Tensor <span class="keywordflow">or</span> list of Tensors.</div>
<div class="line"><span class="lineno">  198</span> </div>
<div class="line"><span class="lineno">  199</span>  TODO(jonathanhuang): make this function fully interchangeable <span class="keyword">with</span> tf.map_fn.</div>
<div class="line"><span class="lineno">  200</span> </div>
<div class="line"><span class="lineno">  201</span>  Args:</div>
<div class="line"><span class="lineno">  202</span>    fn: The callable to be performed. It accepts one argument, which will have</div>
<div class="line"><span class="lineno">  203</span>      the same structure <span class="keyword">as</span> elems. Its output must have the</div>
<div class="line"><span class="lineno">  204</span>      same structure <span class="keyword">as</span> elems.</div>
<div class="line"><span class="lineno">  205</span>    elems: A tensor <span class="keywordflow">or</span> list of tensors, each of which will</div>
<div class="line"><span class="lineno">  206</span>      be unpacked along their first dimension. The sequence of the</div>
<div class="line"><span class="lineno">  207</span>      resulting slices will be applied to fn.</div>
<div class="line"><span class="lineno">  208</span>    dtype:  (optional) The output type(s) of fn. If fn returns a structure of</div>
<div class="line"><span class="lineno">  209</span>      Tensors differing <span class="keyword">from</span> the structure of elems, then dtype <span class="keywordflow">is</span> <span class="keywordflow">not</span> optional</div>
<div class="line"><span class="lineno">  210</span>      <span class="keywordflow">and</span> must have the same structure <span class="keyword">as</span> the output of fn.</div>
<div class="line"><span class="lineno">  211</span>    parallel_iterations: (optional) number of batch items to process <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  212</span>      parallel.  This flag <span class="keywordflow">is</span> only used <span class="keywordflow">if</span> the native tf.map_fn <span class="keywordflow">is</span> used</div>
<div class="line"><span class="lineno">  213</span>      <span class="keywordflow">and</span> defaults to 32 instead of 10 (unlike the standard tf.map_fn default).</div>
<div class="line"><span class="lineno">  214</span>    back_prop: (optional) <span class="keyword">True</span> enables support <span class="keywordflow">for</span> back propagation.</div>
<div class="line"><span class="lineno">  215</span>      This flag <span class="keywordflow">is</span> only used <span class="keywordflow">if</span> the native tf.map_fn <span class="keywordflow">is</span> used.</div>
<div class="line"><span class="lineno">  216</span> </div>
<div class="line"><span class="lineno">  217</span>  Returns:</div>
<div class="line"><span class="lineno">  218</span>    A tensor <span class="keywordflow">or</span> sequence of tensors. Each tensor packs the</div>
<div class="line"><span class="lineno">  219</span>    results of applying fn to tensors unpacked <span class="keyword">from</span> elems along the first</div>
<div class="line"><span class="lineno">  220</span>    dimension, <span class="keyword">from</span> first to last.</div>
<div class="line"><span class="lineno">  221</span>  Raises:</div>
<div class="line"><span class="lineno">  222</span>    ValueError: <span class="keywordflow">if</span> `elems` a Tensor <span class="keywordflow">or</span> a list of Tensors.</div>
<div class="line"><span class="lineno">  223</span>    ValueError: <span class="keywordflow">if</span> `fn` does <span class="keywordflow">not</span> <span class="keywordflow">return</span> a Tensor <span class="keywordflow">or</span> list of Tensors</div>
<div class="line"><span class="lineno">  224</span>  <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  225</span><span class="stringliteral">  </span><span class="keywordflow">if</span> isinstance(elems, list):</div>
<div class="line"><span class="lineno">  226</span>    <span class="keywordflow">for</span> elem <span class="keywordflow">in</span> elems:</div>
<div class="line"><span class="lineno">  227</span>      <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(elem, tf.Tensor):</div>
<div class="line"><span class="lineno">  228</span>        <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`elems` must be a Tensor or list of Tensors.&#39;</span>)</div>
<div class="line"><span class="lineno">  229</span> </div>
<div class="line"><span class="lineno">  230</span>    elem_shapes = [elem.shape.as_list() <span class="keywordflow">for</span> elem <span class="keywordflow">in</span> elems]</div>
<div class="line"><span class="lineno">  231</span>    <span class="comment"># Fall back on tf.map_fn if shapes of each entry of `elems` are None or fail</span></div>
<div class="line"><span class="lineno">  232</span>    <span class="comment"># to all be the same size along the batch dimension.</span></div>
<div class="line"><span class="lineno">  233</span>    <span class="keywordflow">for</span> elem_shape <span class="keywordflow">in</span> elem_shapes:</div>
<div class="line"><span class="lineno">  234</span>      <span class="keywordflow">if</span> (<span class="keywordflow">not</span> elem_shape <span class="keywordflow">or</span> <span class="keywordflow">not</span> elem_shape[0]</div>
<div class="line"><span class="lineno">  235</span>          <span class="keywordflow">or</span> elem_shape[0] != elem_shapes[0][0]):</div>
<div class="line"><span class="lineno">  236</span>        <span class="keywordflow">return</span> tf.map_fn(fn, elems, dtype, parallel_iterations, back_prop)</div>
<div class="line"><span class="lineno">  237</span>    arg_tuples = zip(*[tf.unstack(elem) <span class="keywordflow">for</span> elem <span class="keywordflow">in</span> elems])</div>
<div class="line"><span class="lineno">  238</span>    outputs = [fn(arg_tuple) <span class="keywordflow">for</span> arg_tuple <span class="keywordflow">in</span> arg_tuples]</div>
<div class="line"><span class="lineno">  239</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  240</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> isinstance(elems, tf.Tensor):</div>
<div class="line"><span class="lineno">  241</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`elems` must be a Tensor or list of Tensors.&#39;</span>)</div>
<div class="line"><span class="lineno">  242</span>    elems_shape = elems.shape.as_list()</div>
<div class="line"><span class="lineno">  243</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> elems_shape <span class="keywordflow">or</span> <span class="keywordflow">not</span> elems_shape[0]:</div>
<div class="line"><span class="lineno">  244</span>      <span class="keywordflow">return</span> tf.map_fn(fn, elems, dtype, parallel_iterations, back_prop)</div>
<div class="line"><span class="lineno">  245</span>    outputs = [fn(arg) <span class="keywordflow">for</span> arg <span class="keywordflow">in</span> tf.unstack(elems)]</div>
<div class="line"><span class="lineno">  246</span>  <span class="comment"># Stack `outputs`, which is a list of Tensors or list of lists of Tensors</span></div>
<div class="line"><span class="lineno">  247</span>  <span class="keywordflow">if</span> all([isinstance(output, tf.Tensor) <span class="keywordflow">for</span> output <span class="keywordflow">in</span> outputs]):</div>
<div class="line"><span class="lineno">  248</span>    <span class="keywordflow">return</span> tf.stack(outputs)</div>
<div class="line"><span class="lineno">  249</span>  <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  250</span>    <span class="keywordflow">if</span> all([isinstance(output, list) <span class="keywordflow">for</span> output <span class="keywordflow">in</span> outputs]):</div>
<div class="line"><span class="lineno">  251</span>      <span class="keywordflow">if</span> all([all(</div>
<div class="line"><span class="lineno">  252</span>          [isinstance(entry, tf.Tensor) <span class="keywordflow">for</span> entry <span class="keywordflow">in</span> output_list])</div>
<div class="line"><span class="lineno">  253</span>              <span class="keywordflow">for</span> output_list <span class="keywordflow">in</span> outputs]):</div>
<div class="line"><span class="lineno">  254</span>        <span class="keywordflow">return</span> [tf.stack(output_tuple) <span class="keywordflow">for</span> output_tuple <span class="keywordflow">in</span> zip(*outputs)]</div>
<div class="line"><span class="lineno">  255</span>  <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&#39;`fn` should return a Tensor or a list of Tensors.&#39;</span>)</div>
<div class="line"><span class="lineno">  256</span> </div>
<div class="line"><span class="lineno">  257</span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a id="a4242130317b726719d430d77b294373c" name="a4242130317b726719d430d77b294373c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4242130317b726719d430d77b294373c">&#9670;&#160;</a></span>get_dim_as_int</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.utils.shape_utils.get_dim_as_int = static_shape.get_dim_as_int</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../da/d1b/shape__utils_8py_source.html#l00028">28</a> of file <a class="el" href="../../da/d1b/shape__utils_8py_source.html">shape_utils.py</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
