<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.7"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>RESIIST: detection_utils.core.model.DetectionModel Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">RESIIST
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.7 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d8/d97/namespacedetection__utils.html">detection_utils</a></li><li class="navelem"><a class="el" href="../../de/d5d/namespacedetection__utils_1_1core.html">core</a></li><li class="navelem"><a class="el" href="../../d6/df9/namespacedetection__utils_1_1core_1_1model.html">model</a></li><li class="navelem"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html">DetectionModel</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="../../d9/d4d/classdetection__utils_1_1core_1_1model_1_1_detection_model-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">detection_utils.core.model.DetectionModel Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for detection_utils.core.model.DetectionModel:</div>
<div class="dyncontent">
<div class="center"><img src="../../dc/d63/classdetection__utils_1_1core_1_1model_1_1_detection_model__inherit__graph.png" border="0" usemap="#adetection__utils_8core_8model_8_detection_model_inherit__map" alt="Inheritance graph"/></div>
<map name="adetection__utils_8core_8model_8_detection_model_inherit__map" id="adetection__utils_8core_8model_8_detection_model_inherit__map">
<area shape="rect" title=" " alt="" coords="117,119,288,439"/>
<area shape="rect" title=" " alt="" coords="5,5,131,71"/>
<area shape="poly" title=" " alt="" coords="95,81,120,125,115,128,90,84"/>
<area shape="rect" title=" " alt="" coords="155,5,250,71"/>
<area shape="poly" title=" " alt="" coords="205,84,205,119,200,119,200,84"/>
<area shape="rect" title=" " alt="" coords="274,5,358,71"/>
<area shape="poly" title=" " alt="" coords="298,84,281,120,276,117,293,82"/>
</map>
</div>
<div class="dynheader">
Collaboration diagram for detection_utils.core.model.DetectionModel:</div>
<div class="dyncontent">
<div class="center"><img src="../../dc/d15/classdetection__utils_1_1core_1_1model_1_1_detection_model__coll__graph.png" border="0" usemap="#adetection__utils_8core_8model_8_detection_model_coll__map" alt="Collaboration graph"/></div>
<map name="adetection__utils_8core_8model_8_detection_model_coll__map" id="adetection__utils_8core_8model_8_detection_model_coll__map">
<area shape="rect" title=" " alt="" coords="117,119,288,439"/>
<area shape="rect" title=" " alt="" coords="5,5,131,71"/>
<area shape="poly" title=" " alt="" coords="95,81,120,125,115,128,90,84"/>
<area shape="rect" title=" " alt="" coords="155,5,250,71"/>
<area shape="poly" title=" " alt="" coords="205,84,205,119,200,119,200,84"/>
<area shape="rect" title=" " alt="" coords="274,5,358,71"/>
<area shape="poly" title=" " alt="" coords="298,84,281,120,276,117,293,82"/>
</map>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab10992ad5e898a16d27ddd5b809faee5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#ab10992ad5e898a16d27ddd5b809faee5">__init__</a> (self, <a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#adcde54ff40e213e89fa3995b07e8b81b">num_classes</a>)</td></tr>
<tr class="separator:ab10992ad5e898a16d27ddd5b809faee5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adcde54ff40e213e89fa3995b07e8b81b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#adcde54ff40e213e89fa3995b07e8b81b">num_classes</a> (self)</td></tr>
<tr class="separator:adcde54ff40e213e89fa3995b07e8b81b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a759b5cf4e13319f98ed13aa74f6671a4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a759b5cf4e13319f98ed13aa74f6671a4">groundtruth_lists</a> (self, field)</td></tr>
<tr class="separator:a759b5cf4e13319f98ed13aa74f6671a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac95a060842fa8ce3ccabf7f2d98b54ef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#ac95a060842fa8ce3ccabf7f2d98b54ef">groundtruth_has_field</a> (self, field)</td></tr>
<tr class="separator:ac95a060842fa8ce3ccabf7f2d98b54ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9b65d22e193818e75df46a3a7b264c4"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#aa9b65d22e193818e75df46a3a7b264c4">preprocess</a> (self, inputs)</td></tr>
<tr class="separator:aa9b65d22e193818e75df46a3a7b264c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae647e2a9e493d01d2c54c9aeaa72050c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#ae647e2a9e493d01d2c54c9aeaa72050c">predict</a> (self, preprocessed_inputs, true_image_shapes)</td></tr>
<tr class="separator:ae647e2a9e493d01d2c54c9aeaa72050c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0602750e218163cc6898056ee4666394"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a0602750e218163cc6898056ee4666394">postprocess</a> (self, prediction_dict, true_image_shapes, **params)</td></tr>
<tr class="separator:a0602750e218163cc6898056ee4666394"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a3c58003dcb9dfbbb498cfaaffe1f3a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a4a3c58003dcb9dfbbb498cfaaffe1f3a">loss</a> (self, prediction_dict, true_image_shapes)</td></tr>
<tr class="separator:a4a3c58003dcb9dfbbb498cfaaffe1f3a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a064598d25a6d0deb83e257969f23c9f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a064598d25a6d0deb83e257969f23c9f6">provide_groundtruth</a> (self, groundtruth_boxes_list, groundtruth_classes_list, groundtruth_masks_list=None, groundtruth_keypoints_list=None, groundtruth_weights_list=None, groundtruth_confidences_list=None, groundtruth_is_crowd_list=None, is_annotated_list=None)</td></tr>
<tr class="separator:a064598d25a6d0deb83e257969f23c9f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a85265bb7b71f082a833fefd28a47fe55"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a85265bb7b71f082a833fefd28a47fe55">regularization_losses</a> (self)</td></tr>
<tr class="separator:a85265bb7b71f082a833fefd28a47fe55"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64aba744ec1c5495784e42fe041d71a0"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a64aba744ec1c5495784e42fe041d71a0">restore_map</a> (self, fine_tune_checkpoint_type='detection')</td></tr>
<tr class="separator:a64aba744ec1c5495784e42fe041d71a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a61ccd8a44ce48eb27c970254188f452d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a61ccd8a44ce48eb27c970254188f452d">updates</a> (self)</td></tr>
<tr class="separator:a61ccd8a44ce48eb27c970254188f452d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a869c41a90a24a165b111045373852175"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#a869c41a90a24a165b111045373852175">_num_classes</a></td></tr>
<tr class="separator:a869c41a90a24a165b111045373852175"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac1cc42899a4cf92fa21013b49b306306"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model.html#ac1cc42899a4cf92fa21013b49b306306">_groundtruth_lists</a></td></tr>
<tr class="separator:ac1cc42899a4cf92fa21013b49b306306"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Abstract base class for detection models.

Extends tf.Module to guarantee variable tracking.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00076">76</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ab10992ad5e898a16d27ddd5b809faee5" name="ab10992ad5e898a16d27ddd5b809faee5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab10992ad5e898a16d27ddd5b809faee5">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>num_classes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Constructor.

Args:
  num_classes: number of classes.  Note that num_classes *does not* include
  background categories that might be implicitly predicted in various
  implementations.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00082">82</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   82</span>  <span class="keyword">def </span>__init__(self, num_classes):</div>
<div class="line"><span class="lineno">   83</span>    <span class="stringliteral">&quot;&quot;&quot;Constructor.</span></div>
<div class="line"><span class="lineno">   84</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">   85</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">   86</span><span class="stringliteral">      num_classes: number of classes.  Note that num_classes *does </span><span class="keywordflow">not</span>* include</div>
<div class="line"><span class="lineno">   87</span>      background categories that might be implicitly predicted <span class="keywordflow">in</span> various</div>
<div class="line"><span class="lineno">   88</span>      implementations.</div>
<div class="line"><span class="lineno">   89</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">   90</span><span class="stringliteral">    self._num_classes = num_classes</span></div>
<div class="line"><span class="lineno">   91</span><span class="stringliteral">    self._groundtruth_lists = {}</span></div>
<div class="line"><span class="lineno">   92</span><span class="stringliteral"></span> </div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ac95a060842fa8ce3ccabf7f2d98b54ef" name="ac95a060842fa8ce3ccabf7f2d98b54ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac95a060842fa8ce3ccabf7f2d98b54ef">&#9670;&#160;</a></span>groundtruth_has_field()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.groundtruth_has_field </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>field</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Determines whether the groundtruth includes the given field.

Args:
  field: a string key, options are
    fields.BoxListFields.{boxes,classes,masks,keypoints} or
    fields.InputDataFields.is_annotated.

Returns:
  True if the groundtruth includes the given field, False otherwise.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00117">117</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  117</span>  <span class="keyword">def </span>groundtruth_has_field(self, field):</div>
<div class="line"><span class="lineno">  118</span>    <span class="stringliteral">&quot;&quot;&quot;Determines whether the groundtruth includes the given field.</span></div>
<div class="line"><span class="lineno">  119</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  120</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  121</span><span class="stringliteral">      field: a string key, options are</span></div>
<div class="line"><span class="lineno">  122</span><span class="stringliteral">        fields.BoxListFields.{boxes,classes,masks,keypoints} </span><span class="keywordflow">or</span></div>
<div class="line"><span class="lineno">  123</span>        fields.InputDataFields.is_annotated.</div>
<div class="line"><span class="lineno">  124</span> </div>
<div class="line"><span class="lineno">  125</span>    Returns:</div>
<div class="line"><span class="lineno">  126</span>      <span class="keyword">True</span> <span class="keywordflow">if</span> the groundtruth includes the given field, <span class="keyword">False</span> otherwise.</div>
<div class="line"><span class="lineno">  127</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  128</span><span class="stringliteral">    </span><span class="keywordflow">return</span> field <span class="keywordflow">in</span> self._groundtruth_lists</div>
<div class="line"><span class="lineno">  129</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a759b5cf4e13319f98ed13aa74f6671a4" name="a759b5cf4e13319f98ed13aa74f6671a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a759b5cf4e13319f98ed13aa74f6671a4">&#9670;&#160;</a></span>groundtruth_lists()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.groundtruth_lists </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>field</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Access list of groundtruth tensors.

Args:
  field: a string key, options are
    fields.BoxListFields.{boxes,classes,masks,keypoints} or
    fields.InputDataFields.is_annotated.

Returns:
  a list of tensors holding groundtruth information (see also
  provide_groundtruth function below), with one entry for each image in the
  batch.
Raises:
  RuntimeError: if the field has not been provided via provide_groundtruth.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00097">97</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   97</span>  <span class="keyword">def </span>groundtruth_lists(self, field):</div>
<div class="line"><span class="lineno">   98</span>    <span class="stringliteral">&quot;&quot;&quot;Access list of groundtruth tensors.</span></div>
<div class="line"><span class="lineno">   99</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  100</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  101</span><span class="stringliteral">      field: a string key, options are</span></div>
<div class="line"><span class="lineno">  102</span><span class="stringliteral">        fields.BoxListFields.{boxes,classes,masks,keypoints} </span><span class="keywordflow">or</span></div>
<div class="line"><span class="lineno">  103</span>        fields.InputDataFields.is_annotated.</div>
<div class="line"><span class="lineno">  104</span> </div>
<div class="line"><span class="lineno">  105</span>    Returns:</div>
<div class="line"><span class="lineno">  106</span>      a list of tensors holding groundtruth information (see also</div>
<div class="line"><span class="lineno">  107</span>      provide_groundtruth function below), <span class="keyword">with</span> one entry <span class="keywordflow">for</span> each image <span class="keywordflow">in</span> the</div>
<div class="line"><span class="lineno">  108</span>      batch.</div>
<div class="line"><span class="lineno">  109</span>    Raises:</div>
<div class="line"><span class="lineno">  110</span>      RuntimeError: <span class="keywordflow">if</span> the field has <span class="keywordflow">not</span> been provided via provide_groundtruth.</div>
<div class="line"><span class="lineno">  111</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  112</span><span class="stringliteral">    </span><span class="keywordflow">if</span> field <span class="keywordflow">not</span> <span class="keywordflow">in</span> self._groundtruth_lists:</div>
<div class="line"><span class="lineno">  113</span>      <span class="keywordflow">raise</span> RuntimeError(<span class="stringliteral">&#39;Groundtruth tensor {} has not been provided&#39;</span>.format(</div>
<div class="line"><span class="lineno">  114</span>          field))</div>
<div class="line"><span class="lineno">  115</span>    <span class="keywordflow">return</span> self._groundtruth_lists[field]</div>
<div class="line"><span class="lineno">  116</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a4a3c58003dcb9dfbbb498cfaaffe1f3a" name="a4a3c58003dcb9dfbbb498cfaaffe1f3a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4a3c58003dcb9dfbbb498cfaaffe1f3a">&#9670;&#160;</a></span>loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.loss </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>prediction_dict</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>true_image_shapes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Compute scalar loss tensors with respect to provided groundtruth.

Calling this function requires that groundtruth tensors have been
provided via the provide_groundtruth function.

Args:
  prediction_dict: a dictionary holding predicted tensors
  true_image_shapes: int32 tensor of shape [batch, 3] where each row is
    of the form [height, width, channels] indicating the shapes
    of true images in the resized images, as resized images can be padded
    with zeros.

Returns:
  a dictionary mapping strings (loss names) to scalar tensors representing
    loss values.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00248">248</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  248</span>  <span class="keyword">def </span>loss(self, prediction_dict, true_image_shapes):</div>
<div class="line"><span class="lineno">  249</span>    <span class="stringliteral">&quot;&quot;&quot;Compute scalar loss tensors with respect to provided groundtruth.</span></div>
<div class="line"><span class="lineno">  250</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  251</span><span class="stringliteral">    Calling this function requires that groundtruth tensors have been</span></div>
<div class="line"><span class="lineno">  252</span><span class="stringliteral">    provided via the provide_groundtruth function.</span></div>
<div class="line"><span class="lineno">  253</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  254</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  255</span><span class="stringliteral">      prediction_dict: a dictionary holding predicted tensors</span></div>
<div class="line"><span class="lineno">  256</span><span class="stringliteral">      true_image_shapes: int32 tensor of shape [batch, 3] where each row </span><span class="keywordflow">is</span></div>
<div class="line"><span class="lineno">  257</span>        of the form [height, width, channels] indicating the shapes</div>
<div class="line"><span class="lineno">  258</span>        of true images <span class="keywordflow">in</span> the resized images, <span class="keyword">as</span> resized images can be padded</div>
<div class="line"><span class="lineno">  259</span>        <span class="keyword">with</span> zeros.</div>
<div class="line"><span class="lineno">  260</span> </div>
<div class="line"><span class="lineno">  261</span>    Returns:</div>
<div class="line"><span class="lineno">  262</span>      a dictionary mapping strings (loss names) to scalar tensors representing</div>
<div class="line"><span class="lineno">  263</span>        loss values.</div>
<div class="line"><span class="lineno">  264</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  265</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  266</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="adcde54ff40e213e89fa3995b07e8b81b" name="adcde54ff40e213e89fa3995b07e8b81b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adcde54ff40e213e89fa3995b07e8b81b">&#9670;&#160;</a></span>num_classes()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.num_classes </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00094">94</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">   94</span>  <span class="keyword">def </span>num_classes(self):</div>
<div class="line"><span class="lineno">   95</span>    <span class="keywordflow">return</span> self._num_classes</div>
<div class="line"><span class="lineno">   96</span> </div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../d4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model_adcde54ff40e213e89fa3995b07e8b81b_icgraph.png" border="0" usemap="#ad4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model_adcde54ff40e213e89fa3995b07e8b81b_icgraph" alt=""/></div>
<map name="ad4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model_adcde54ff40e213e89fa3995b07e8b81b_icgraph" id="ad4/df2/classdetection__utils_1_1core_1_1model_1_1_detection_model_adcde54ff40e213e89fa3995b07e8b81b_icgraph">
<area shape="rect" title=" " alt="" coords="520,53,713,93"/>
<area shape="rect" href="../../d4/d03/classdetection__utils_1_1utils_1_1test__utils_1_1_mock_keras_box_predictor.html#a176fd843de45489814c8a1a7833a88b7" title=" " alt="" coords="269,5,472,60"/>
<area shape="poly" title=" " alt="" coords="506,57,472,52,472,46,507,52"/>
<area shape="rect" href="../../d3/d3d/classdetection__utils_1_1utils_1_1test__utils_1_1_mock_box_predictor.html#a2f138336a44d807dd71036578db7c250" title=" " alt="" coords="287,84,455,139"/>
<area shape="poly" title=" " alt="" coords="507,93,455,101,455,96,506,87"/>
<area shape="rect" href="../../dc/daf/classdetection__utils_1_1core_1_1box__predictor_1_1_keras_box_predictor.html#a802afdd72f3c5850b03727af50c88c19" title=" " alt="" coords="5,17,221,57"/>
<area shape="poly" title=" " alt="" coords="255,37,222,38,222,32,255,32"/>
<area shape="rect" href="../../d8/dd6/classdetection__utils_1_1core_1_1box__predictor_1_1_box_predictor.html#a9856aa18532050546fd1b46b2a752485" title=" " alt="" coords="13,85,214,125"/>
<area shape="poly" title=" " alt="" coords="260,66,186,87,185,82,259,61"/>
<area shape="poly" title=" " alt="" coords="273,86,182,59,184,54,274,81"/>
<area shape="poly" title=" " alt="" coords="273,111,214,110,214,105,273,106"/>
</map>
</div>

</div>
</div>
<a id="a0602750e218163cc6898056ee4666394" name="a0602750e218163cc6898056ee4666394"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0602750e218163cc6898056ee4666394">&#9670;&#160;</a></span>postprocess()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.postprocess </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>prediction_dict</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>true_image_shapes</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">**&#160;</td>
          <td class="paramname"><em>params</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Convert predicted output tensors to final detections.

This stage typically performs a few things such as
* Non-Max Suppression to remove overlapping detection boxes.
* Score conversion and background class removal.

Outputs adhere to the following conventions:
* Classes are integers in [0, num_classes); background classes are removed
  and the first non-background class is mapped to 0. If the model produces
  class-agnostic detections, then no output is produced for classes.
* Boxes are to be interpreted as being in [y_min, x_min, y_max, x_max]
  format and normalized relative to the image window.
* `num_detections` is provided for settings where detections are padded to a
  fixed number of boxes.
* We do not specifically assume any kind of probabilistic interpretation
  of the scores --- the only important thing is their relative ordering.
  Thus implementations of the postprocess function are free to output
  logits, probabilities, calibrated probabilities, or anything else.

Args:
  prediction_dict: a dictionary holding prediction tensors.
  true_image_shapes: int32 tensor of shape [batch, 3] where each row is
    of the form [height, width, channels] indicating the shapes
    of true images in the resized images, as resized images can be padded
    with zeros.
  **params: Additional keyword arguments for specific implementations of
    DetectionModel.

Returns:
  detections: a dictionary containing the following fields
    detection_boxes: [batch, max_detections, 4]
    detection_scores: [batch, max_detections]
    detection_classes: [batch, max_detections]
      (If a model is producing class-agnostic detections, this field may be
      missing)
    instance_masks: [batch, max_detections, image_height, image_width]
      (optional)
    keypoints: [batch, max_detections, num_keypoints, 2] (optional)
    num_detections: [batch]

    In addition to the above fields this stage also outputs the following
    raw tensors:

    raw_detection_boxes: [batch, total_detections, 4] tensor containing
      all detection boxes from `prediction_dict` in the format
      [ymin, xmin, ymax, xmax] and normalized co-ordinates.
    raw_detection_scores: [batch, total_detections,
      num_classes_with_background] tensor of class score logits for
      raw detection boxes.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00194">194</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  194</span>  <span class="keyword">def </span>postprocess(self, prediction_dict, true_image_shapes, **params):</div>
<div class="line"><span class="lineno">  195</span>    <span class="stringliteral">&quot;&quot;&quot;Convert predicted output tensors to final detections.</span></div>
<div class="line"><span class="lineno">  196</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  197</span><span class="stringliteral">    This stage typically performs a few things such </span><span class="keyword">as</span></div>
<div class="line"><span class="lineno">  198</span>    * Non-Max Suppression to remove overlapping detection boxes.</div>
<div class="line"><span class="lineno">  199</span>    * Score conversion <span class="keywordflow">and</span> background <span class="keyword">class </span>removal.</div>
<div class="line"><span class="lineno">  200</span> </div>
<div class="line"><span class="lineno">  201</span>    Outputs adhere to the following conventions:</div>
<div class="line"><span class="lineno">  202</span>    * Classes are integers <span class="keywordflow">in</span> [0, num_classes); background classes are removed</div>
<div class="line"><span class="lineno">  203</span>      <span class="keywordflow">and</span> the first non-background <span class="keyword">class </span>is mapped to 0. If the model produces</div>
<div class="line"><span class="lineno">  204</span>      <span class="keyword">class</span>-agnostic detections, then no output <span class="keywordflow">is</span> produced <span class="keywordflow">for</span> classes.</div>
<div class="line"><span class="lineno">  205</span>    * Boxes are to be interpreted <span class="keyword">as</span> being <span class="keywordflow">in</span> [y_min, x_min, y_max, x_max]</div>
<div class="line"><span class="lineno">  206</span>      format <span class="keywordflow">and</span> normalized relative to the image window.</div>
<div class="line"><span class="lineno">  207</span>    * `num_detections` <span class="keywordflow">is</span> provided <span class="keywordflow">for</span> settings where detections are padded to a</div>
<div class="line"><span class="lineno">  208</span>      fixed number of boxes.</div>
<div class="line"><span class="lineno">  209</span>    * We do <span class="keywordflow">not</span> specifically assume any kind of probabilistic interpretation</div>
<div class="line"><span class="lineno">  210</span>      of the scores --- the only important thing <span class="keywordflow">is</span> their relative ordering.</div>
<div class="line"><span class="lineno">  211</span>      Thus implementations of the postprocess function are free to output</div>
<div class="line"><span class="lineno">  212</span>      logits, probabilities, calibrated probabilities, <span class="keywordflow">or</span> anything <span class="keywordflow">else</span>.</div>
<div class="line"><span class="lineno">  213</span> </div>
<div class="line"><span class="lineno">  214</span>    Args:</div>
<div class="line"><span class="lineno">  215</span>      prediction_dict: a dictionary holding prediction tensors.</div>
<div class="line"><span class="lineno">  216</span>      true_image_shapes: int32 tensor of shape [batch, 3] where each row <span class="keywordflow">is</span></div>
<div class="line"><span class="lineno">  217</span>        of the form [height, width, channels] indicating the shapes</div>
<div class="line"><span class="lineno">  218</span>        of true images <span class="keywordflow">in</span> the resized images, <span class="keyword">as</span> resized images can be padded</div>
<div class="line"><span class="lineno">  219</span>        <span class="keyword">with</span> zeros.</div>
<div class="line"><span class="lineno">  220</span>      **params: Additional keyword arguments <span class="keywordflow">for</span> specific implementations of</div>
<div class="line"><span class="lineno">  221</span>        DetectionModel.</div>
<div class="line"><span class="lineno">  222</span> </div>
<div class="line"><span class="lineno">  223</span>    Returns:</div>
<div class="line"><span class="lineno">  224</span>      detections: a dictionary containing the following fields</div>
<div class="line"><span class="lineno">  225</span>        detection_boxes: [batch, max_detections, 4]</div>
<div class="line"><span class="lineno">  226</span>        detection_scores: [batch, max_detections]</div>
<div class="line"><span class="lineno">  227</span>        detection_classes: [batch, max_detections]</div>
<div class="line"><span class="lineno">  228</span>          (If a model <span class="keywordflow">is</span> producing <span class="keyword">class</span>-agnostic detections, this field may be</div>
<div class="line"><span class="lineno">  229</span>          missing)</div>
<div class="line"><span class="lineno">  230</span>        instance_masks: [batch, max_detections, image_height, image_width]</div>
<div class="line"><span class="lineno">  231</span>          (optional)</div>
<div class="line"><span class="lineno">  232</span>        keypoints: [batch, max_detections, num_keypoints, 2] (optional)</div>
<div class="line"><span class="lineno">  233</span>        num_detections: [batch]</div>
<div class="line"><span class="lineno">  234</span> </div>
<div class="line"><span class="lineno">  235</span>        In addition to the above fields this stage also outputs the following</div>
<div class="line"><span class="lineno">  236</span>        raw tensors:</div>
<div class="line"><span class="lineno">  237</span> </div>
<div class="line"><span class="lineno">  238</span>        raw_detection_boxes: [batch, total_detections, 4] tensor containing</div>
<div class="line"><span class="lineno">  239</span>          all detection boxes <span class="keyword">from</span> `prediction_dict` <span class="keywordflow">in</span> the format</div>
<div class="line"><span class="lineno">  240</span>          [ymin, xmin, ymax, xmax] <span class="keywordflow">and</span> normalized co-ordinates.</div>
<div class="line"><span class="lineno">  241</span>        raw_detection_scores: [batch, total_detections,</div>
<div class="line"><span class="lineno">  242</span>          num_classes_with_background] tensor of <span class="keyword">class </span>score logits for</div>
<div class="line"><span class="lineno">  243</span>          raw detection boxes.</div>
<div class="line"><span class="lineno">  244</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  245</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  246</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="ae647e2a9e493d01d2c54c9aeaa72050c" name="ae647e2a9e493d01d2c54c9aeaa72050c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae647e2a9e493d01d2c54c9aeaa72050c">&#9670;&#160;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.predict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>preprocessed_inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>true_image_shapes</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Predict prediction tensors from inputs tensor.

Outputs of this function can be passed to loss or postprocess functions.

Args:
  preprocessed_inputs: a [batch, height, width, channels] float32 tensor
    representing a batch of images.
  true_image_shapes: int32 tensor of shape [batch, 3] where each row is
    of the form [height, width, channels] indicating the shapes
    of true images in the resized images, as resized images can be padded
    with zeros.

Returns:
  prediction_dict: a dictionary holding prediction tensors to be
    passed to the Loss or Postprocess functions.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00174">174</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  174</span>  <span class="keyword">def </span>predict(self, preprocessed_inputs, true_image_shapes):</div>
<div class="line"><span class="lineno">  175</span>    <span class="stringliteral">&quot;&quot;&quot;Predict prediction tensors from inputs tensor.</span></div>
<div class="line"><span class="lineno">  176</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  177</span><span class="stringliteral">    Outputs of this function can be passed to loss </span><span class="keywordflow">or</span> postprocess functions.</div>
<div class="line"><span class="lineno">  178</span> </div>
<div class="line"><span class="lineno">  179</span>    Args:</div>
<div class="line"><span class="lineno">  180</span>      preprocessed_inputs: a [batch, height, width, channels] float32 tensor</div>
<div class="line"><span class="lineno">  181</span>        representing a batch of images.</div>
<div class="line"><span class="lineno">  182</span>      true_image_shapes: int32 tensor of shape [batch, 3] where each row <span class="keywordflow">is</span></div>
<div class="line"><span class="lineno">  183</span>        of the form [height, width, channels] indicating the shapes</div>
<div class="line"><span class="lineno">  184</span>        of true images <span class="keywordflow">in</span> the resized images, <span class="keyword">as</span> resized images can be padded</div>
<div class="line"><span class="lineno">  185</span>        <span class="keyword">with</span> zeros.</div>
<div class="line"><span class="lineno">  186</span> </div>
<div class="line"><span class="lineno">  187</span>    Returns:</div>
<div class="line"><span class="lineno">  188</span>      prediction_dict: a dictionary holding prediction tensors to be</div>
<div class="line"><span class="lineno">  189</span>        passed to the Loss <span class="keywordflow">or</span> Postprocess functions.</div>
<div class="line"><span class="lineno">  190</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  191</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  192</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="aa9b65d22e193818e75df46a3a7b264c4" name="aa9b65d22e193818e75df46a3a7b264c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9b65d22e193818e75df46a3a7b264c4">&#9670;&#160;</a></span>preprocess()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.preprocess </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>inputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Input preprocessing.

To be overridden by implementations.

This function is responsible for any scaling/shifting of input values that
is necessary prior to running the detector on an input image.
It is also responsible for any resizing, padding that might be necessary
as images are assumed to arrive in arbitrary sizes.  While this function
could conceivably be part of the predict method (below), it is often
convenient to keep these separate --- for example, we may want to preprocess
on one device, place onto a queue, and let another device (e.g., the GPU)
handle prediction.

A few important notes about the preprocess function:
+ We assume that this operation does not have any trainable variables nor
does it affect the groundtruth annotations in any way (thus data
augmentation operations such as random cropping should be performed
externally).
+ There is no assumption that the batchsize in this function is the same as
the batch size in the predict function.  In fact, we recommend calling the
preprocess function prior to calling any batching operations (which should
happen outside of the model) and thus assuming that batch sizes are equal
to 1 in the preprocess function.
+ There is also no explicit assumption that the output resolutions
must be fixed across inputs --- this is to support "fully convolutional"
settings in which input images can have different shapes/resolutions.

Args:
  inputs: a [batch, height_in, width_in, channels] float32 tensor
    representing a batch of images with values between 0 and 255.0.

Returns:
  preprocessed_inputs: a [batch, height_out, width_out, channels] float32
    tensor representing a batch of images.
  true_image_shapes: int32 tensor of shape [batch, 3] where each row is
    of the form [height, width, channels] indicating the shapes
    of true images in the resized images, as resized images can be padded
    with zeros.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00131">131</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  131</span>  <span class="keyword">def </span>preprocess(self, inputs):</div>
<div class="line"><span class="lineno">  132</span>    <span class="stringliteral">&quot;&quot;&quot;Input preprocessing.</span></div>
<div class="line"><span class="lineno">  133</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  134</span><span class="stringliteral">    To be overridden by implementations.</span></div>
<div class="line"><span class="lineno">  135</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  136</span><span class="stringliteral">    This function </span><span class="keywordflow">is</span> responsible <span class="keywordflow">for</span> any scaling/shifting of input values that</div>
<div class="line"><span class="lineno">  137</span>    <span class="keywordflow">is</span> necessary prior to running the detector on an input image.</div>
<div class="line"><span class="lineno">  138</span>    It <span class="keywordflow">is</span> also responsible <span class="keywordflow">for</span> any resizing, padding that might be necessary</div>
<div class="line"><span class="lineno">  139</span>    <span class="keyword">as</span> images are assumed to arrive <span class="keywordflow">in</span> arbitrary sizes.  While this function</div>
<div class="line"><span class="lineno">  140</span>    could conceivably be part of the predict method (below), it <span class="keywordflow">is</span> often</div>
<div class="line"><span class="lineno">  141</span>    convenient to keep these separate --- <span class="keywordflow">for</span> example, we may want to preprocess</div>
<div class="line"><span class="lineno">  142</span>    on one device, place onto a queue, <span class="keywordflow">and</span> let another device (e.g., the GPU)</div>
<div class="line"><span class="lineno">  143</span>    handle prediction.</div>
<div class="line"><span class="lineno">  144</span> </div>
<div class="line"><span class="lineno">  145</span>    A few important notes about the preprocess function:</div>
<div class="line"><span class="lineno">  146</span>    + We assume that this operation does <span class="keywordflow">not</span> have any trainable variables nor</div>
<div class="line"><span class="lineno">  147</span>    does it affect the groundtruth annotations <span class="keywordflow">in</span> any way (thus data</div>
<div class="line"><span class="lineno">  148</span>    augmentation operations such <span class="keyword">as</span> random cropping should be performed</div>
<div class="line"><span class="lineno">  149</span>    externally).</div>
<div class="line"><span class="lineno">  150</span>    + There <span class="keywordflow">is</span> no assumption that the batchsize <span class="keywordflow">in</span> this function <span class="keywordflow">is</span> the same <span class="keyword">as</span></div>
<div class="line"><span class="lineno">  151</span>    the batch size <span class="keywordflow">in</span> the predict function.  In fact, we recommend calling the</div>
<div class="line"><span class="lineno">  152</span>    preprocess function prior to calling any batching operations (which should</div>
<div class="line"><span class="lineno">  153</span>    happen outside of the model) <span class="keywordflow">and</span> thus assuming that batch sizes are equal</div>
<div class="line"><span class="lineno">  154</span>    to 1 <span class="keywordflow">in</span> the preprocess function.</div>
<div class="line"><span class="lineno">  155</span>    + There <span class="keywordflow">is</span> also no explicit assumption that the output resolutions</div>
<div class="line"><span class="lineno">  156</span>    must be fixed across inputs --- this <span class="keywordflow">is</span> to support <span class="stringliteral">&quot;fully convolutional&quot;</span></div>
<div class="line"><span class="lineno">  157</span>    settings <span class="keywordflow">in</span> which input images can have different shapes/resolutions.</div>
<div class="line"><span class="lineno">  158</span> </div>
<div class="line"><span class="lineno">  159</span>    Args:</div>
<div class="line"><span class="lineno">  160</span>      inputs: a [batch, height_in, width_in, channels] float32 tensor</div>
<div class="line"><span class="lineno">  161</span>        representing a batch of images <span class="keyword">with</span> values between 0 <span class="keywordflow">and</span> 255.0.</div>
<div class="line"><span class="lineno">  162</span> </div>
<div class="line"><span class="lineno">  163</span>    Returns:</div>
<div class="line"><span class="lineno">  164</span>      preprocessed_inputs: a [batch, height_out, width_out, channels] float32</div>
<div class="line"><span class="lineno">  165</span>        tensor representing a batch of images.</div>
<div class="line"><span class="lineno">  166</span>      true_image_shapes: int32 tensor of shape [batch, 3] where each row <span class="keywordflow">is</span></div>
<div class="line"><span class="lineno">  167</span>        of the form [height, width, channels] indicating the shapes</div>
<div class="line"><span class="lineno">  168</span>        of true images <span class="keywordflow">in</span> the resized images, <span class="keyword">as</span> resized images can be padded</div>
<div class="line"><span class="lineno">  169</span>        <span class="keyword">with</span> zeros.</div>
<div class="line"><span class="lineno">  170</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  171</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  172</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a064598d25a6d0deb83e257969f23c9f6" name="a064598d25a6d0deb83e257969f23c9f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a064598d25a6d0deb83e257969f23c9f6">&#9670;&#160;</a></span>provide_groundtruth()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.provide_groundtruth </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_boxes_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_classes_list</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_masks_list</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_keypoints_list</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_weights_list</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_confidences_list</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>groundtruth_is_crowd_list</em> = <code>None</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>is_annotated_list</em> = <code>None</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Provide groundtruth tensors.

Args:
  groundtruth_boxes_list: a list of 2-D tf.float32 tensors of shape
    [num_boxes, 4] containing coordinates of the groundtruth boxes.
      Groundtruth boxes are provided in [y_min, x_min, y_max, x_max]
      format and assumed to be normalized and clipped
      relative to the image window with y_min &lt;= y_max and x_min &lt;= x_max.
  groundtruth_classes_list: a list of 2-D tf.float32 one-hot (or k-hot)
    tensors of shape [num_boxes, num_classes] containing the class targets
    with the 0th index assumed to map to the first non-background class.
  groundtruth_masks_list: a list of 3-D tf.float32 tensors of
    shape [num_boxes, height_in, width_in] containing instance
    masks with values in {0, 1}.  If None, no masks are provided.
    Mask resolution `height_in`x`width_in` must agree with the resolution
    of the input image tensor provided to the `preprocess` function.
  groundtruth_keypoints_list: a list of 3-D tf.float32 tensors of
    shape [num_boxes, num_keypoints, 2] containing keypoints.
    Keypoints are assumed to be provided in normalized coordinates and
    missing keypoints should be encoded as NaN.
  groundtruth_weights_list: A list of 1-D tf.float32 tensors of shape
    [num_boxes] containing weights for groundtruth boxes.
  groundtruth_confidences_list: A list of 2-D tf.float32 tensors of shape
    [num_boxes, num_classes] containing class confidences for groundtruth
    boxes.
  groundtruth_is_crowd_list: A list of 1-D tf.bool tensors of shape
    [num_boxes] containing is_crowd annotations
  is_annotated_list: A list of scalar tf.bool tensors indicating whether
    images have been labeled or not.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00267">267</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  275</span>                          is_annotated_list=<span class="keywordtype">None</span>):</div>
<div class="line"><span class="lineno">  276</span>    <span class="stringliteral">&quot;&quot;&quot;Provide groundtruth tensors.</span></div>
<div class="line"><span class="lineno">  277</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  278</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  279</span><span class="stringliteral">      groundtruth_boxes_list: a list of 2-D tf.float32 tensors of shape</span></div>
<div class="line"><span class="lineno">  280</span><span class="stringliteral">        [num_boxes, 4] containing coordinates of the groundtruth boxes.</span></div>
<div class="line"><span class="lineno">  281</span><span class="stringliteral">          Groundtruth boxes are provided </span><span class="keywordflow">in</span> [y_min, x_min, y_max, x_max]</div>
<div class="line"><span class="lineno">  282</span>          format <span class="keywordflow">and</span> assumed to be normalized <span class="keywordflow">and</span> clipped</div>
<div class="line"><span class="lineno">  283</span>          relative to the image window <span class="keyword">with</span> y_min &lt;= y_max <span class="keywordflow">and</span> x_min &lt;= x_max.</div>
<div class="line"><span class="lineno">  284</span>      groundtruth_classes_list: a list of 2-D tf.float32 one-hot (<span class="keywordflow">or</span> k-hot)</div>
<div class="line"><span class="lineno">  285</span>        tensors of shape [num_boxes, num_classes] containing the <span class="keyword">class </span>targets</div>
<div class="line"><span class="lineno">  286</span>        <span class="keyword">with</span> the 0th index assumed to map to the first non-background <span class="keyword">class</span>.</div>
<div class="line"><span class="lineno">  287</span>      groundtruth_masks_list: a list of 3-D tf.float32 tensors of</div>
<div class="line"><span class="lineno">  288</span>        shape [num_boxes, height_in, width_in] containing instance</div>
<div class="line"><span class="lineno">  289</span>        masks <span class="keyword">with</span> values <span class="keywordflow">in</span> {0, 1}.  If <span class="keywordtype">None</span>, no masks are provided.</div>
<div class="line"><span class="lineno">  290</span>        Mask resolution `height_in`x`width_in` must agree <span class="keyword">with</span> the resolution</div>
<div class="line"><span class="lineno">  291</span>        of the input image tensor provided to the `preprocess` function.</div>
<div class="line"><span class="lineno">  292</span>      groundtruth_keypoints_list: a list of 3-D tf.float32 tensors of</div>
<div class="line"><span class="lineno">  293</span>        shape [num_boxes, num_keypoints, 2] containing keypoints.</div>
<div class="line"><span class="lineno">  294</span>        Keypoints are assumed to be provided <span class="keywordflow">in</span> normalized coordinates <span class="keywordflow">and</span></div>
<div class="line"><span class="lineno">  295</span>        missing keypoints should be encoded <span class="keyword">as</span> NaN.</div>
<div class="line"><span class="lineno">  296</span>      groundtruth_weights_list: A list of 1-D tf.float32 tensors of shape</div>
<div class="line"><span class="lineno">  297</span>        [num_boxes] containing weights <span class="keywordflow">for</span> groundtruth boxes.</div>
<div class="line"><span class="lineno">  298</span>      groundtruth_confidences_list: A list of 2-D tf.float32 tensors of shape</div>
<div class="line"><span class="lineno">  299</span>        [num_boxes, num_classes] containing <span class="keyword">class </span>confidences for groundtruth</div>
<div class="line"><span class="lineno">  300</span>        boxes.</div>
<div class="line"><span class="lineno">  301</span>      groundtruth_is_crowd_list: A list of 1-D tf.bool tensors of shape</div>
<div class="line"><span class="lineno">  302</span>        [num_boxes] containing is_crowd annotations</div>
<div class="line"><span class="lineno">  303</span>      is_annotated_list: A list of scalar tf.bool tensors indicating whether</div>
<div class="line"><span class="lineno">  304</span>        images have been labeled <span class="keywordflow">or</span> <span class="keywordflow">not</span>.</div>
<div class="line"><span class="lineno">  305</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  306</span><span class="stringliteral">    self._groundtruth_lists[fields.BoxListFields.boxes] = groundtruth_boxes_list</span></div>
<div class="line"><span class="lineno">  307</span><span class="stringliteral">    self._groundtruth_lists[</span></div>
<div class="line"><span class="lineno">  308</span><span class="stringliteral">        fields.BoxListFields.classes] = groundtruth_classes_list</span></div>
<div class="line"><span class="lineno">  309</span><span class="stringliteral">    </span><span class="keywordflow">if</span> groundtruth_weights_list:</div>
<div class="line"><span class="lineno">  310</span>      self._groundtruth_lists[fields.BoxListFields.</div>
<div class="line"><span class="lineno">  311</span>                              weights] = groundtruth_weights_list</div>
<div class="line"><span class="lineno">  312</span>    <span class="keywordflow">if</span> groundtruth_confidences_list:</div>
<div class="line"><span class="lineno">  313</span>      self._groundtruth_lists[fields.BoxListFields.</div>
<div class="line"><span class="lineno">  314</span>                              confidences] = groundtruth_confidences_list</div>
<div class="line"><span class="lineno">  315</span>    <span class="keywordflow">if</span> groundtruth_masks_list:</div>
<div class="line"><span class="lineno">  316</span>      self._groundtruth_lists[</div>
<div class="line"><span class="lineno">  317</span>          fields.BoxListFields.masks] = groundtruth_masks_list</div>
<div class="line"><span class="lineno">  318</span>    <span class="keywordflow">if</span> groundtruth_keypoints_list:</div>
<div class="line"><span class="lineno">  319</span>      self._groundtruth_lists[</div>
<div class="line"><span class="lineno">  320</span>          fields.BoxListFields.keypoints] = groundtruth_keypoints_list</div>
<div class="line"><span class="lineno">  321</span>    <span class="keywordflow">if</span> groundtruth_is_crowd_list:</div>
<div class="line"><span class="lineno">  322</span>      self._groundtruth_lists[</div>
<div class="line"><span class="lineno">  323</span>          fields.BoxListFields.is_crowd] = groundtruth_is_crowd_list</div>
<div class="line"><span class="lineno">  324</span>    <span class="keywordflow">if</span> is_annotated_list:</div>
<div class="line"><span class="lineno">  325</span>      self._groundtruth_lists[</div>
<div class="line"><span class="lineno">  326</span>          fields.InputDataFields.is_annotated] = is_annotated_list</div>
<div class="line"><span class="lineno">  327</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a85265bb7b71f082a833fefd28a47fe55" name="a85265bb7b71f082a833fefd28a47fe55"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a85265bb7b71f082a833fefd28a47fe55">&#9670;&#160;</a></span>regularization_losses()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.regularization_losses </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a list of regularization losses for this model.

Returns a list of regularization losses for this model that the estimator
needs to use during training/optimization.

Returns:
  A list of regularization loss tensors.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00329">329</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  329</span>  <span class="keyword">def </span>regularization_losses(self):</div>
<div class="line"><span class="lineno">  330</span>    <span class="stringliteral">&quot;&quot;&quot;Returns a list of regularization losses for this model.</span></div>
<div class="line"><span class="lineno">  331</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  332</span><span class="stringliteral">    Returns a list of regularization losses </span><span class="keywordflow">for</span> this model that the estimator</div>
<div class="line"><span class="lineno">  333</span>    needs to use during training/optimization.</div>
<div class="line"><span class="lineno">  334</span> </div>
<div class="line"><span class="lineno">  335</span>    Returns:</div>
<div class="line"><span class="lineno">  336</span>      A list of regularization loss tensors.</div>
<div class="line"><span class="lineno">  337</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  338</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  339</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a64aba744ec1c5495784e42fe041d71a0" name="a64aba744ec1c5495784e42fe041d71a0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64aba744ec1c5495784e42fe041d71a0">&#9670;&#160;</a></span>restore_map()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.restore_map </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>fine_tune_checkpoint_type</em> = <code>'detection'</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a map of variables to load from a foreign checkpoint.

Returns a map of variable names to load from a checkpoint to variables in
the model graph. This enables the model to initialize based on weights from
another task. For example, the feature extractor variables from a
classification model can be used to bootstrap training of an object
detector. When loading from an object detection model, the checkpoint model
should have the same parameters as this detection model with exception of
the num_classes parameter.

Args:
  fine_tune_checkpoint_type: whether to restore from a full detection
    checkpoint (with compatible variable names) or to restore from a
    classification checkpoint for initialization prior to training.
    Valid values: `detection`, `classification`. Default 'detection'.

Returns:
  A dict mapping variable names (to load from a checkpoint) to variables in
  the model graph.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00341">341</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  341</span>  <span class="keyword">def </span>restore_map(self, fine_tune_checkpoint_type=&#39;detection&#39;):</div>
<div class="line"><span class="lineno">  342</span>    <span class="stringliteral">&quot;&quot;&quot;Returns a map of variables to load from a foreign checkpoint.</span></div>
<div class="line"><span class="lineno">  343</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  344</span><span class="stringliteral">    Returns a map of variable names to load </span><span class="keyword">from</span> a checkpoint to variables <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  345</span>    the model graph. This enables the model to initialize based on weights <span class="keyword">from</span></div>
<div class="line"><span class="lineno">  346</span>    another task. For example, the feature extractor variables <span class="keyword">from</span> a</div>
<div class="line"><span class="lineno">  347</span>    classification model can be used to bootstrap training of an object</div>
<div class="line"><span class="lineno">  348</span>    detector. When loading <span class="keyword">from</span> an object detection model, the checkpoint model</div>
<div class="line"><span class="lineno">  349</span>    should have the same parameters <span class="keyword">as</span> this detection model <span class="keyword">with</span> exception of</div>
<div class="line"><span class="lineno">  350</span>    the num_classes parameter.</div>
<div class="line"><span class="lineno">  351</span> </div>
<div class="line"><span class="lineno">  352</span>    Args:</div>
<div class="line"><span class="lineno">  353</span>      fine_tune_checkpoint_type: whether to restore <span class="keyword">from</span> a full detection</div>
<div class="line"><span class="lineno">  354</span>        checkpoint (<span class="keyword">with</span> compatible variable names) <span class="keywordflow">or</span> to restore <span class="keyword">from</span> a</div>
<div class="line"><span class="lineno">  355</span>        classification checkpoint <span class="keywordflow">for</span> initialization prior to training.</div>
<div class="line"><span class="lineno">  356</span>        Valid values: `detection`, `classification`. Default <span class="stringliteral">&#39;detection&#39;</span>.</div>
<div class="line"><span class="lineno">  357</span> </div>
<div class="line"><span class="lineno">  358</span>    Returns:</div>
<div class="line"><span class="lineno">  359</span>      A dict mapping variable names (to load <span class="keyword">from</span> a checkpoint) to variables <span class="keywordflow">in</span></div>
<div class="line"><span class="lineno">  360</span>      the model graph.</div>
<div class="line"><span class="lineno">  361</span>    <span class="stringliteral">&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  362</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
<div class="line"><span class="lineno">  363</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a61ccd8a44ce48eb27c970254188f452d" name="a61ccd8a44ce48eb27c970254188f452d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a61ccd8a44ce48eb27c970254188f452d">&#9670;&#160;</a></span>updates()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel.updates </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns a list of update operators for this model.

Returns a list of update operators for this model that must be executed at
each training step. The estimator's train op needs to have a control
dependency on these updates.

Returns:
  A list of update operators.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00365">365</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  365</span>  <span class="keyword">def </span>updates(self):</div>
<div class="line"><span class="lineno">  366</span>    <span class="stringliteral">&quot;&quot;&quot;Returns a list of update operators for this model.</span></div>
<div class="line"><span class="lineno">  367</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  368</span><span class="stringliteral">    Returns a list of update operators </span><span class="keywordflow">for</span> this model that must be executed at</div>
<div class="line"><span class="lineno">  369</span>    each training step. The estimator<span class="stringliteral">&#39;s train op needs to have a control</span></div>
<div class="line"><span class="lineno">  370</span><span class="stringliteral">    dependency on these updates.</span></div>
<div class="line"><span class="lineno">  371</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  372</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  373</span><span class="stringliteral">      A list of update operators.</span></div>
<div class="line"><span class="lineno">  374</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  375</span><span class="stringliteral">    </span><span class="keywordflow">pass</span></div>
</div><!-- fragment -->
</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ac1cc42899a4cf92fa21013b49b306306" name="ac1cc42899a4cf92fa21013b49b306306"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac1cc42899a4cf92fa21013b49b306306">&#9670;&#160;</a></span>_groundtruth_lists</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel._groundtruth_lists</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00091">91</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>

</div>
</div>
<a id="a869c41a90a24a165b111045373852175" name="a869c41a90a24a165b111045373852175"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a869c41a90a24a165b111045373852175">&#9670;&#160;</a></span>_num_classes</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">detection_utils.core.model.DetectionModel._num_classes</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../d4/d0e/model_8py_source.html#l00090">90</a> of file <a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>src/main/resources/processing/video/detections/detection_utils/core/<a class="el" href="../../d4/d0e/model_8py_source.html">model.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.7
</small></address>
</body>
</html>
