\doxysection{detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test Class Reference}
\hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test}{}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test}\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}


Inheritance diagram for detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=292pt]{de/db2/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=292pt]{d8/d5a/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test__coll__graph}
\end{center}
\end{figure}
\doxysubsubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ae9a4ce6c3fc0f98c37c700bb1050abe8}{test\+Easy\+Examples\+Produce\+Small\+Loss\+Compared\+To\+Sigmoid\+XEntropy}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a3e84d4ceb1df343c5514146532c6e84e}{test\+Hard\+Examples\+Produce\+Loss\+Comparable\+To\+Sigmoid\+XEntropy}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ad5a8d702f0018d41af8cdde151106122}{test\+Non\+Anchor\+Wise\+Output\+Comparable\+To\+Sigmoid\+XEntropy}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_af08455865a129beee7439883774aed62}{test\+Ignore\+Negative\+Example\+Loss\+Via\+Alpha\+Multiplier}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a6ae6820f5d92fc4d5bc179f38355fb29}{test\+Ignore\+Positive\+Example\+Loss\+Via\+Alpha\+Multiplier}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a2dbadf7bd284a171ce86771418acff62}{test\+Similar\+To\+Sigmoid\+XEntropy\+With\+Half\+Alpha\+And\+Zero\+Gamma\+Up\+To\+AScale}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a710cdd1f5eeda4e20349bf9a0e909f83}{test\+Same\+As\+Sigmoid\+XEntropy\+With\+No\+Alpha\+And\+Zero\+Gamma}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a50e0d68abaad42e5722bb764f44a0484}{test\+Expected\+Loss\+With\+Alpha\+One\+And\+Zero\+Gamma}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a2a456f83c1b671230fc55caa397f2fba}{test\+Expected\+Loss\+With\+Alpha75\+And\+Zero\+Gamma}} (self)
\item 
\mbox{\hyperlink{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ab551ff2168380a1b680df267a99fd277}{test\+Expected\+Loss\+With\+Losses\+Mask}} (self)
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}


Definition at line \mbox{\hyperlink{losses__test_8py_source_l00365}{365}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.



\doxysubsection{Member Function Documentation}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ae9a4ce6c3fc0f98c37c700bb1050abe8}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ae9a4ce6c3fc0f98c37c700bb1050abe8} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy@{testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy}}
\index{testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy@{testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy()}{testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Easy\+Examples\+Produce\+Small\+Loss\+Compared\+To\+Sigmoid\+XEntropy (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00367}{367}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00367\ \ \ \textcolor{keyword}{def\ }testEasyExamplesProduceSmallLossComparedToSigmoidXEntropy(self):}
\DoxyCodeLine{00368\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[\_logit(0.97)],}
\DoxyCodeLine{00369\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.91)],}
\DoxyCodeLine{00370\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.73)],}
\DoxyCodeLine{00371\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.27)],}
\DoxyCodeLine{00372\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.09)],}
\DoxyCodeLine{00373\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.03)]]],\ tf.float32)}
\DoxyCodeLine{00374\ \ \ \ \ target\_tensor\ =\ tf.constant([[[1],}
\DoxyCodeLine{00375\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00376\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00377\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0],}
\DoxyCodeLine{00378\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0],}
\DoxyCodeLine{00379\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0]]],\ tf.float32)}
\DoxyCodeLine{00380\ \ \ \ \ weights\ =\ tf.constant([[[1],\ [1],\ [1],\ [1],\ [1],\ [1]]],\ tf.float32)}
\DoxyCodeLine{00381\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(gamma=2.0,\ alpha=\textcolor{keywordtype}{None})}
\DoxyCodeLine{00382\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00383\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00384\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00385\ \ \ \ \ sigmoid\_loss\ =\ tf.reduce\_sum(sigmoid\_loss\_op(prediction\_tensor,}
\DoxyCodeLine{00386\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ target\_tensor,}
\DoxyCodeLine{00387\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00388\ }
\DoxyCodeLine{00389\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00390\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00391\ \ \ \ \ \ \ order\_of\_ratio\ =\ np.power(10,}
\DoxyCodeLine{00392\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.floor(np.log10(sigmoid\_loss\ /\ focal\_loss)))}
\DoxyCodeLine{00393\ \ \ \ \ \ \ self.assertAllClose(order\_of\_ratio,\ [[1000,\ 100,\ 10,\ 10,\ 100,\ 1000]])}
\DoxyCodeLine{00394\ }

\end{DoxyCode}
Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/de5/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ae9a4ce6c3fc0f98c37c700bb1050abe8_cgraph}
\end{center}
\end{figure}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a2a456f83c1b671230fc55caa397f2fba}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a2a456f83c1b671230fc55caa397f2fba} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testExpectedLossWithAlpha75AndZeroGamma@{testExpectedLossWithAlpha75AndZeroGamma}}
\index{testExpectedLossWithAlpha75AndZeroGamma@{testExpectedLossWithAlpha75AndZeroGamma}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testExpectedLossWithAlpha75AndZeroGamma()}{testExpectedLossWithAlpha75AndZeroGamma()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Expected\+Loss\+With\+Alpha75\+And\+Zero\+Gamma (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00613}{613}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00613\ \ \ \textcolor{keyword}{def\ }testExpectedLossWithAlpha75AndZeroGamma(self):}
\DoxyCodeLine{00614\ \ \ \ \ \textcolor{comment}{\#\ All\ zeros\ correspond\ to\ 0.5\ probability.}}
\DoxyCodeLine{00615\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[0,\ 0,\ 0],}
\DoxyCodeLine{00616\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00617\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00618\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]],}
\DoxyCodeLine{00619\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 0],}
\DoxyCodeLine{00620\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00621\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00622\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00623\ \ \ \ \ target\_tensor\ =\ tf.constant([[[0,\ 1,\ 0],}
\DoxyCodeLine{00624\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00625\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00626\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 1]],}
\DoxyCodeLine{00627\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 1],}
\DoxyCodeLine{00628\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 1,\ 0],}
\DoxyCodeLine{00629\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00630\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00631\ \ \ \ \ weights\ =\ tf.constant([[[1,\ 1,\ 1],}
\DoxyCodeLine{00632\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00633\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00634\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]],}
\DoxyCodeLine{00635\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 1,\ 1],}
\DoxyCodeLine{00636\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00637\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00638\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]]],\ tf.float32)}
\DoxyCodeLine{00639\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(alpha=0.75,\ gamma=0.0)}
\DoxyCodeLine{00640\ }
\DoxyCodeLine{00641\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00642\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights))}
\DoxyCodeLine{00643\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00644\ \ \ \ \ \ \ focal\_loss\ =\ sess.run(focal\_loss)}
\DoxyCodeLine{00645\ \ \ \ \ \ \ self.assertAllClose(}
\DoxyCodeLine{00646\ \ \ \ \ \ \ \ \ \ \ (-\/math.log(.5)\ *\ \ \textcolor{comment}{\#\ x-\/entropy\ per\ class\ per\ anchor.}}
\DoxyCodeLine{00647\ \ \ \ \ \ \ \ \ \ \ \ ((0.75\ *\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ alpha\ for\ positives.}}
\DoxyCodeLine{00648\ \ \ \ \ \ \ \ \ \ \ \ \ \ 8)\ +\ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ positives\ from\ 8\ anchors.}}
\DoxyCodeLine{00649\ \ \ \ \ \ \ \ \ \ \ \ \ (0.25\ *\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ alpha\ for\ negatives.}}
\DoxyCodeLine{00650\ \ \ \ \ \ \ \ \ \ \ \ \ \ 8\ *\ 2))),\ \ \ \ \ \ \textcolor{comment}{\#\ negatives\ from\ 8\ anchors\ for\ two\ classes.}}
\DoxyCodeLine{00651\ \ \ \ \ \ \ \ \ \ \ focal\_loss)}
\DoxyCodeLine{00652\ }

\end{DoxyCode}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a50e0d68abaad42e5722bb764f44a0484}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a50e0d68abaad42e5722bb764f44a0484} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testExpectedLossWithAlphaOneAndZeroGamma@{testExpectedLossWithAlphaOneAndZeroGamma}}
\index{testExpectedLossWithAlphaOneAndZeroGamma@{testExpectedLossWithAlphaOneAndZeroGamma}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testExpectedLossWithAlphaOneAndZeroGamma()}{testExpectedLossWithAlphaOneAndZeroGamma()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Expected\+Loss\+With\+Alpha\+One\+And\+Zero\+Gamma (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00575}{575}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00575\ \ \ \textcolor{keyword}{def\ }testExpectedLossWithAlphaOneAndZeroGamma(self):}
\DoxyCodeLine{00576\ \ \ \ \ \textcolor{comment}{\#\ All\ zeros\ correspond\ to\ 0.5\ probability.}}
\DoxyCodeLine{00577\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[0,\ 0,\ 0],}
\DoxyCodeLine{00578\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00579\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00580\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]],}
\DoxyCodeLine{00581\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 0],}
\DoxyCodeLine{00582\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00583\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00584\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00585\ \ \ \ \ target\_tensor\ =\ tf.constant([[[0,\ 1,\ 0],}
\DoxyCodeLine{00586\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00587\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00588\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 1]],}
\DoxyCodeLine{00589\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 1],}
\DoxyCodeLine{00590\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 1,\ 0],}
\DoxyCodeLine{00591\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00592\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00593\ \ \ \ \ weights\ =\ tf.constant([[[1,\ 1,\ 1],}
\DoxyCodeLine{00594\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00595\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00596\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]],}
\DoxyCodeLine{00597\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 1,\ 1],}
\DoxyCodeLine{00598\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00599\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00600\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]]],\ tf.float32)}
\DoxyCodeLine{00601\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(alpha=1.0,\ gamma=0.0)}
\DoxyCodeLine{00602\ }
\DoxyCodeLine{00603\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00604\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights))}
\DoxyCodeLine{00605\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00606\ \ \ \ \ \ \ focal\_loss\ =\ sess.run(focal\_loss)}
\DoxyCodeLine{00607\ \ \ \ \ \ \ self.assertAllClose(}
\DoxyCodeLine{00608\ \ \ \ \ \ \ \ \ \ \ (-\/math.log(.5)\ *\ \ \textcolor{comment}{\#\ x-\/entropy\ per\ class\ per\ anchor}}
\DoxyCodeLine{00609\ \ \ \ \ \ \ \ \ \ \ \ 1.0\ *\ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ alpha}}
\DoxyCodeLine{00610\ \ \ \ \ \ \ \ \ \ \ \ 8),\ \ \ \ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ positives\ from\ 8\ anchors}}
\DoxyCodeLine{00611\ \ \ \ \ \ \ \ \ \ \ focal\_loss)}
\DoxyCodeLine{00612\ }

\end{DoxyCode}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ab551ff2168380a1b680df267a99fd277}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ab551ff2168380a1b680df267a99fd277} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testExpectedLossWithLossesMask@{testExpectedLossWithLossesMask}}
\index{testExpectedLossWithLossesMask@{testExpectedLossWithLossesMask}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testExpectedLossWithLossesMask()}{testExpectedLossWithLossesMask()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Expected\+Loss\+With\+Losses\+Mask (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00653}{653}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00653\ \ \ \textcolor{keyword}{def\ }testExpectedLossWithLossesMask(self):}
\DoxyCodeLine{00654\ \ \ \ \ \textcolor{comment}{\#\ All\ zeros\ correspond\ to\ 0.5\ probability.}}
\DoxyCodeLine{00655\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[0,\ 0,\ 0],}
\DoxyCodeLine{00656\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00657\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00658\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]],}
\DoxyCodeLine{00659\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 0],}
\DoxyCodeLine{00660\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00661\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00662\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]],}
\DoxyCodeLine{00663\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 0],}
\DoxyCodeLine{00664\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00665\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0],}
\DoxyCodeLine{00666\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00667\ \ \ \ \ target\_tensor\ =\ tf.constant([[[0,\ 1,\ 0],}
\DoxyCodeLine{00668\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00669\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00670\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 1]],}
\DoxyCodeLine{00671\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 1],}
\DoxyCodeLine{00672\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 1,\ 0],}
\DoxyCodeLine{00673\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00674\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0]],}
\DoxyCodeLine{00675\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 0,\ 0],}
\DoxyCodeLine{00676\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00677\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00678\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00679\ \ \ \ \ weights\ =\ tf.constant([[[1,\ 1,\ 1],}
\DoxyCodeLine{00680\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00681\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00682\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]],}
\DoxyCodeLine{00683\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 1,\ 1],}
\DoxyCodeLine{00684\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00685\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00686\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]],}
\DoxyCodeLine{00687\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 1,\ 1],}
\DoxyCodeLine{00688\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00689\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00690\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]]],\ tf.float32)}
\DoxyCodeLine{00691\ \ \ \ \ losses\_mask\ =\ tf.constant([\textcolor{keyword}{True},\ \textcolor{keyword}{True},\ \textcolor{keyword}{False}],\ tf.bool)}
\DoxyCodeLine{00692\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(alpha=0.75,\ gamma=0.0)}
\DoxyCodeLine{00693\ }
\DoxyCodeLine{00694\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00695\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights,}
\DoxyCodeLine{00696\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ losses\_mask=losses\_mask))}
\DoxyCodeLine{00697\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00698\ \ \ \ \ \ \ focal\_loss\ =\ sess.run(focal\_loss)}
\DoxyCodeLine{00699\ \ \ \ \ \ \ self.assertAllClose(}
\DoxyCodeLine{00700\ \ \ \ \ \ \ \ \ \ \ (-\/math.log(.5)\ *\ \ \textcolor{comment}{\#\ x-\/entropy\ per\ class\ per\ anchor.}}
\DoxyCodeLine{00701\ \ \ \ \ \ \ \ \ \ \ \ ((0.75\ *\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ alpha\ for\ positives.}}
\DoxyCodeLine{00702\ \ \ \ \ \ \ \ \ \ \ \ \ \ 8)\ +\ \ \ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ positives\ from\ 8\ anchors.}}
\DoxyCodeLine{00703\ \ \ \ \ \ \ \ \ \ \ \ \ (0.25\ *\ \ \ \ \ \ \ \ \ \textcolor{comment}{\#\ alpha\ for\ negatives.}}
\DoxyCodeLine{00704\ \ \ \ \ \ \ \ \ \ \ \ \ \ 8\ *\ 2))),\ \ \ \ \ \ \textcolor{comment}{\#\ negatives\ from\ 8\ anchors\ for\ two\ classes.}}
\DoxyCodeLine{00705\ \ \ \ \ \ \ \ \ \ \ focal\_loss)}
\DoxyCodeLine{00706\ }
\DoxyCodeLine{00707\ }

\end{DoxyCode}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a3e84d4ceb1df343c5514146532c6e84e}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a3e84d4ceb1df343c5514146532c6e84e} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testHardExamplesProduceLossComparableToSigmoidXEntropy@{testHardExamplesProduceLossComparableToSigmoidXEntropy}}
\index{testHardExamplesProduceLossComparableToSigmoidXEntropy@{testHardExamplesProduceLossComparableToSigmoidXEntropy}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testHardExamplesProduceLossComparableToSigmoidXEntropy()}{testHardExamplesProduceLossComparableToSigmoidXEntropy()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Hard\+Examples\+Produce\+Loss\+Comparable\+To\+Sigmoid\+XEntropy (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00395}{395}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00395\ \ \ \textcolor{keyword}{def\ }testHardExamplesProduceLossComparableToSigmoidXEntropy(self):}
\DoxyCodeLine{00396\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[\_logit(0.55)],}
\DoxyCodeLine{00397\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.52)],}
\DoxyCodeLine{00398\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.50)],}
\DoxyCodeLine{00399\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.48)],}
\DoxyCodeLine{00400\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.45)]]],\ tf.float32)}
\DoxyCodeLine{00401\ \ \ \ \ target\_tensor\ =\ tf.constant([[[1],}
\DoxyCodeLine{00402\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00403\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00404\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0],}
\DoxyCodeLine{00405\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0]]],\ tf.float32)}
\DoxyCodeLine{00406\ \ \ \ \ weights\ =\ tf.constant([[[1],\ [1],\ [1],\ [1],\ [1]]],\ tf.float32)}
\DoxyCodeLine{00407\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(gamma=2.0,\ alpha=\textcolor{keywordtype}{None})}
\DoxyCodeLine{00408\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00409\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00410\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00411\ \ \ \ \ sigmoid\_loss\ =\ tf.reduce\_sum(sigmoid\_loss\_op(prediction\_tensor,}
\DoxyCodeLine{00412\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ target\_tensor,}
\DoxyCodeLine{00413\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00414\ }
\DoxyCodeLine{00415\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00416\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00417\ \ \ \ \ \ \ order\_of\_ratio\ =\ np.power(10,}
\DoxyCodeLine{00418\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.floor(np.log10(sigmoid\_loss\ /\ focal\_loss)))}
\DoxyCodeLine{00419\ \ \ \ \ \ \ self.assertAllClose(order\_of\_ratio,\ [[1.,\ 1.,\ 1.,\ 1.,\ 1.]])}
\DoxyCodeLine{00420\ }

\end{DoxyCode}
Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/de5/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a3e84d4ceb1df343c5514146532c6e84e_cgraph}
\end{center}
\end{figure}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_af08455865a129beee7439883774aed62}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_af08455865a129beee7439883774aed62} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testIgnoreNegativeExampleLossViaAlphaMultiplier@{testIgnoreNegativeExampleLossViaAlphaMultiplier}}
\index{testIgnoreNegativeExampleLossViaAlphaMultiplier@{testIgnoreNegativeExampleLossViaAlphaMultiplier}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testIgnoreNegativeExampleLossViaAlphaMultiplier()}{testIgnoreNegativeExampleLossViaAlphaMultiplier()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Ignore\+Negative\+Example\+Loss\+Via\+Alpha\+Multiplier (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00447}{447}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00447\ \ \ \textcolor{keyword}{def\ }testIgnoreNegativeExampleLossViaAlphaMultiplier(self):}
\DoxyCodeLine{00448\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[\_logit(0.55)],}
\DoxyCodeLine{00449\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.52)],}
\DoxyCodeLine{00450\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.50)],}
\DoxyCodeLine{00451\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.48)],}
\DoxyCodeLine{00452\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.45)]]],\ tf.float32)}
\DoxyCodeLine{00453\ \ \ \ \ target\_tensor\ =\ tf.constant([[[1],}
\DoxyCodeLine{00454\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00455\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00456\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0],}
\DoxyCodeLine{00457\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0]]],\ tf.float32)}
\DoxyCodeLine{00458\ \ \ \ \ weights\ =\ tf.constant([[[1],\ [1],\ [1],\ [1],\ [1]]],\ tf.float32)}
\DoxyCodeLine{00459\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(gamma=2.0,\ alpha=1.0)}
\DoxyCodeLine{00460\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00461\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00462\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00463\ \ \ \ \ sigmoid\_loss\ =\ tf.reduce\_sum(sigmoid\_loss\_op(prediction\_tensor,}
\DoxyCodeLine{00464\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ target\_tensor,}
\DoxyCodeLine{00465\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00466\ }
\DoxyCodeLine{00467\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00468\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00469\ \ \ \ \ \ \ self.assertAllClose(focal\_loss[0][3:],\ [0.,\ 0.])}
\DoxyCodeLine{00470\ \ \ \ \ \ \ order\_of\_ratio\ =\ np.power(10,}
\DoxyCodeLine{00471\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.floor(np.log10(sigmoid\_loss[0][:3]\ /}
\DoxyCodeLine{00472\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ focal\_loss[0][:3])))}
\DoxyCodeLine{00473\ \ \ \ \ \ \ self.assertAllClose(order\_of\_ratio,\ [1.,\ 1.,\ 1.])}
\DoxyCodeLine{00474\ }

\end{DoxyCode}
Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/de5/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_af08455865a129beee7439883774aed62_cgraph}
\end{center}
\end{figure}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a6ae6820f5d92fc4d5bc179f38355fb29}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a6ae6820f5d92fc4d5bc179f38355fb29} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testIgnorePositiveExampleLossViaAlphaMultiplier@{testIgnorePositiveExampleLossViaAlphaMultiplier}}
\index{testIgnorePositiveExampleLossViaAlphaMultiplier@{testIgnorePositiveExampleLossViaAlphaMultiplier}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testIgnorePositiveExampleLossViaAlphaMultiplier()}{testIgnorePositiveExampleLossViaAlphaMultiplier()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Ignore\+Positive\+Example\+Loss\+Via\+Alpha\+Multiplier (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00475}{475}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00475\ \ \ \textcolor{keyword}{def\ }testIgnorePositiveExampleLossViaAlphaMultiplier(self):}
\DoxyCodeLine{00476\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[\_logit(0.55)],}
\DoxyCodeLine{00477\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.52)],}
\DoxyCodeLine{00478\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.50)],}
\DoxyCodeLine{00479\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.48)],}
\DoxyCodeLine{00480\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.45)]]],\ tf.float32)}
\DoxyCodeLine{00481\ \ \ \ \ target\_tensor\ =\ tf.constant([[[1],}
\DoxyCodeLine{00482\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00483\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00484\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0],}
\DoxyCodeLine{00485\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0]]],\ tf.float32)}
\DoxyCodeLine{00486\ \ \ \ \ weights\ =\ tf.constant([[[1],\ [1],\ [1],\ [1],\ [1]]],\ tf.float32)}
\DoxyCodeLine{00487\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(gamma=2.0,\ alpha=0.0)}
\DoxyCodeLine{00488\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00489\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00490\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00491\ \ \ \ \ sigmoid\_loss\ =\ tf.reduce\_sum(sigmoid\_loss\_op(prediction\_tensor,}
\DoxyCodeLine{00492\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ target\_tensor,}
\DoxyCodeLine{00493\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights),\ axis=2)}
\DoxyCodeLine{00494\ }
\DoxyCodeLine{00495\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00496\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00497\ \ \ \ \ \ \ self.assertAllClose(focal\_loss[0][:3],\ [0.,\ 0.,\ 0.])}
\DoxyCodeLine{00498\ \ \ \ \ \ \ order\_of\_ratio\ =\ np.power(10,}
\DoxyCodeLine{00499\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.floor(np.log10(sigmoid\_loss[0][3:]\ /}
\DoxyCodeLine{00500\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ focal\_loss[0][3:])))}
\DoxyCodeLine{00501\ \ \ \ \ \ \ self.assertAllClose(order\_of\_ratio,\ [1.,\ 1.])}
\DoxyCodeLine{00502\ }

\end{DoxyCode}
Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/de5/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a6ae6820f5d92fc4d5bc179f38355fb29_cgraph}
\end{center}
\end{figure}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ad5a8d702f0018d41af8cdde151106122}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ad5a8d702f0018d41af8cdde151106122} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testNonAnchorWiseOutputComparableToSigmoidXEntropy@{testNonAnchorWiseOutputComparableToSigmoidXEntropy}}
\index{testNonAnchorWiseOutputComparableToSigmoidXEntropy@{testNonAnchorWiseOutputComparableToSigmoidXEntropy}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testNonAnchorWiseOutputComparableToSigmoidXEntropy()}{testNonAnchorWiseOutputComparableToSigmoidXEntropy()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Non\+Anchor\+Wise\+Output\+Comparable\+To\+Sigmoid\+XEntropy (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00421}{421}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00421\ \ \ \textcolor{keyword}{def\ }testNonAnchorWiseOutputComparableToSigmoidXEntropy(self):}
\DoxyCodeLine{00422\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[\_logit(0.55)],}
\DoxyCodeLine{00423\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.52)],}
\DoxyCodeLine{00424\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.50)],}
\DoxyCodeLine{00425\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.48)],}
\DoxyCodeLine{00426\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [\_logit(0.45)]]],\ tf.float32)}
\DoxyCodeLine{00427\ \ \ \ \ target\_tensor\ =\ tf.constant([[[1],}
\DoxyCodeLine{00428\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00429\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1],}
\DoxyCodeLine{00430\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0],}
\DoxyCodeLine{00431\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0]]],\ tf.float32)}
\DoxyCodeLine{00432\ \ \ \ \ weights\ =\ tf.constant([[[1],\ [1],\ [1],\ [1],\ [1]]],\ tf.float32)}
\DoxyCodeLine{00433\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(gamma=2.0,\ alpha=\textcolor{keywordtype}{None})}
\DoxyCodeLine{00434\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00435\ \ \ \ \ focal\_loss\ =\ tf.reduce\_sum(focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00436\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights))}
\DoxyCodeLine{00437\ \ \ \ \ sigmoid\_loss\ =\ tf.reduce\_sum(sigmoid\_loss\_op(prediction\_tensor,}
\DoxyCodeLine{00438\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ target\_tensor,}
\DoxyCodeLine{00439\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights))}
\DoxyCodeLine{00440\ }
\DoxyCodeLine{00441\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00442\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00443\ \ \ \ \ \ \ order\_of\_ratio\ =\ np.power(10,}
\DoxyCodeLine{00444\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ np.floor(np.log10(sigmoid\_loss\ /\ focal\_loss)))}
\DoxyCodeLine{00445\ \ \ \ \ \ \ self.assertAlmostEqual(order\_of\_ratio,\ 1.)}
\DoxyCodeLine{00446\ }

\end{DoxyCode}
Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{d0/de5/classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_ad5a8d702f0018d41af8cdde151106122_cgraph}
\end{center}
\end{figure}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a710cdd1f5eeda4e20349bf9a0e909f83}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a710cdd1f5eeda4e20349bf9a0e909f83} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma@{testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma}}
\index{testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma@{testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma()}{testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Same\+As\+Sigmoid\+XEntropy\+With\+No\+Alpha\+And\+Zero\+Gamma (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00539}{539}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00539\ \ \ \textcolor{keyword}{def\ }testSameAsSigmoidXEntropyWithNoAlphaAndZeroGamma(self):}
\DoxyCodeLine{00540\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[-\/100,\ 100,\ -\/100],}
\DoxyCodeLine{00541\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [100,\ -\/100,\ -\/100],}
\DoxyCodeLine{00542\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [100,\ 0,\ -\/100],}
\DoxyCodeLine{00543\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [-\/100,\ -\/100,\ 100]],}
\DoxyCodeLine{00544\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[-\/100,\ 0,\ 100],}
\DoxyCodeLine{00545\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [-\/100,\ 100,\ -\/100],}
\DoxyCodeLine{00546\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [100,\ 100,\ 100],}
\DoxyCodeLine{00547\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ -\/1]]],\ tf.float32)}
\DoxyCodeLine{00548\ \ \ \ \ target\_tensor\ =\ tf.constant([[[0,\ 1,\ 0],}
\DoxyCodeLine{00549\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00550\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00551\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 1]],}
\DoxyCodeLine{00552\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 1],}
\DoxyCodeLine{00553\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 1,\ 0],}
\DoxyCodeLine{00554\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00555\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00556\ \ \ \ \ weights\ =\ tf.constant([[[1,\ 1,\ 1],}
\DoxyCodeLine{00557\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00558\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00559\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]],}
\DoxyCodeLine{00560\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 1,\ 1],}
\DoxyCodeLine{00561\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00562\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00563\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00564\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(alpha=\textcolor{keywordtype}{None},\ gamma=0.0)}
\DoxyCodeLine{00565\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00566\ \ \ \ \ focal\_loss\ =\ focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00567\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights)}
\DoxyCodeLine{00568\ \ \ \ \ sigmoid\_loss\ =\ sigmoid\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00569\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights)}
\DoxyCodeLine{00570\ }
\DoxyCodeLine{00571\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00572\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00573\ \ \ \ \ \ \ self.assertAllClose(sigmoid\_loss,\ focal\_loss)}
\DoxyCodeLine{00574\ }

\end{DoxyCode}
\Hypertarget{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a2dbadf7bd284a171ce86771418acff62}\label{classdetection__utils_1_1core_1_1losses__test_1_1_sigmoid_focal_classification_loss_test_a2dbadf7bd284a171ce86771418acff62} 
\index{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}!testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale@{testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale}}
\index{testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale@{testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale}!detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest@{detection\_utils.core.losses\_test.SigmoidFocalClassificationLossTest}}
\doxysubsubsection{\texorpdfstring{testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale()}{testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale()}}
{\footnotesize\ttfamily detection\+\_\+utils.\+core.\+losses\+\_\+test.\+Sigmoid\+Focal\+Classification\+Loss\+Test.\+test\+Similar\+To\+Sigmoid\+XEntropy\+With\+Half\+Alpha\+And\+Zero\+Gamma\+Up\+To\+AScale (\begin{DoxyParamCaption}\item[{}]{self }\end{DoxyParamCaption})}



Definition at line \mbox{\hyperlink{losses__test_8py_source_l00503}{503}} of file \mbox{\hyperlink{losses__test_8py_source}{losses\+\_\+test.\+py}}.


\begin{DoxyCode}{0}
\DoxyCodeLine{00503\ \ \ \textcolor{keyword}{def\ }testSimilarToSigmoidXEntropyWithHalfAlphaAndZeroGammaUpToAScale(self):}
\DoxyCodeLine{00504\ \ \ \ \ prediction\_tensor\ =\ tf.constant([[[-\/100,\ 100,\ -\/100],}
\DoxyCodeLine{00505\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [100,\ -\/100,\ -\/100],}
\DoxyCodeLine{00506\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [100,\ 0,\ -\/100],}
\DoxyCodeLine{00507\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [-\/100,\ -\/100,\ 100]],}
\DoxyCodeLine{00508\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[-\/100,\ 0,\ 100],}
\DoxyCodeLine{00509\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [-\/100,\ 100,\ -\/100],}
\DoxyCodeLine{00510\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [100,\ 100,\ 100],}
\DoxyCodeLine{00511\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ -\/1]]],\ tf.float32)}
\DoxyCodeLine{00512\ \ \ \ \ target\_tensor\ =\ tf.constant([[[0,\ 1,\ 0],}
\DoxyCodeLine{00513\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00514\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0],}
\DoxyCodeLine{00515\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 1]],}
\DoxyCodeLine{00516\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[0,\ 0,\ 1],}
\DoxyCodeLine{00517\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 1,\ 0],}
\DoxyCodeLine{00518\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00519\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00520\ \ \ \ \ weights\ =\ tf.constant([[[1,\ 1,\ 1],}
\DoxyCodeLine{00521\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00522\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00523\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1]],}
\DoxyCodeLine{00524\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [[1,\ 1,\ 1],}
\DoxyCodeLine{00525\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00526\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [1,\ 1,\ 1],}
\DoxyCodeLine{00527\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ [0,\ 0,\ 0]]],\ tf.float32)}
\DoxyCodeLine{00528\ \ \ \ \ focal\_loss\_op\ =\ losses.SigmoidFocalClassificationLoss(alpha=0.5,\ gamma=0.0)}
\DoxyCodeLine{00529\ \ \ \ \ sigmoid\_loss\_op\ =\ losses.WeightedSigmoidClassificationLoss()}
\DoxyCodeLine{00530\ \ \ \ \ focal\_loss\ =\ focal\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00531\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights)}
\DoxyCodeLine{00532\ \ \ \ \ sigmoid\_loss\ =\ sigmoid\_loss\_op(prediction\_tensor,\ target\_tensor,}
\DoxyCodeLine{00533\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ weights=weights)}
\DoxyCodeLine{00534\ }
\DoxyCodeLine{00535\ \ \ \ \ \textcolor{keyword}{with}\ self.test\_session()\ \textcolor{keyword}{as}\ sess:}
\DoxyCodeLine{00536\ \ \ \ \ \ \ sigmoid\_loss,\ focal\_loss\ =\ sess.run([sigmoid\_loss,\ focal\_loss])}
\DoxyCodeLine{00537\ \ \ \ \ \ \ self.assertAllClose(sigmoid\_loss,\ focal\_loss\ *\ 2)}
\DoxyCodeLine{00538\ }

\end{DoxyCode}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
src/main/resources/processing/video/detections/detection\+\_\+utils/core/\mbox{\hyperlink{losses__test_8py}{losses\+\_\+test.\+py}}\end{DoxyCompactItemize}
